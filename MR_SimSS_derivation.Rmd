---
title: "Removing Winner's Curse bias in two-sample Mendelian randomisation with summary
  data"
author: "Amanda Forde"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook:
    toc: yes
  html_document:
    toc: yes
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

Source:
<https://github.com/amandaforde/winnerscurse_MR/MR_SimSS_derivation.Rmd>

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(dplyr)
library(TwoSampleMR)
library(ggplot2)
library(patchwork)
library(ggpubr)
library(gridExtra)
library(tidyr)
library(RColorBrewer)
col <- brewer.pal(8,"Dark2")
```

<br>

## Proposed Method Derivation

If we randomly split the full data set into two fractions $\pi$ and
$1-\pi$, conditional on the full $\beta_{X1}$ and $\beta_{Y1}$
estimators, $\hat\beta_{X1}$ and $\hat\beta_{Y1}$, it is possible to
simulate values for $\hat \beta_{X1_\pi}$ and $\hat \beta_{Y1_\pi}$, the
estimators in the first fraction of the full sample. Thus, we have
$\hat\beta_{X1} = \pi\hat \beta_{X1_\pi} + (1-\pi)\hat \beta_{X1_{1-\pi}}$
and similarly,
$\hat\beta_{Y1} = \pi\hat \beta_{Y1_\pi} + (1-\pi)\hat \beta_{Y1_{1-\pi}}$,
in which $\hat \beta_{X1_{1-\pi}}$ and $\hat \beta_{Y1_{1-\pi}}$ are the
estimators in the second fraction of the sample. With the simulated
values for $\hat \beta_{X1_\pi}$ and $\hat \beta_{Y1_\pi}$, values for
$\hat \beta_{X1_{1-\pi}}$ and $\hat \beta_{Y1_{1-\pi}}$ can be easily
obtained using the equations above. This provides us with an alternative
method which removes the problem of *Winner's Curse* using repeated
randomisation and selection of SNPs using $\hat \beta_{X1_\pi}$. The IVW
method, or indeed, any MR method of choice, is then fitted using
$\hat \beta_{X1_{1-\pi}}$ and $\hat \beta_{Y1_{1-\pi}}$ and these IVW
estimators are averaged over differing repeated runs.

Therefore, in order to perform this method, we must first establish the
(asymptotic) conditional distribution of:
$$\begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} \Bigl \lvert \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix}$$

[$\star$]{style="color: blue;"} **Note:** We have referred to our
estimators of interest as $\hat\beta_{X1}$ and $\hat\beta_{Y1}$, instead
of simply $\hat\beta_{X}$ and $\hat\beta_{Y}$, to ensure clarity in our
proof below. In the proof, we will be dealing with linear regression in
matrix form and $\hat\beta_X$ will refer to a vector of length 2 in
which the first entry will be $\hat\beta_{X0}$ and the second entry will
be $\hat\beta_{X1}$, our estimator of interest.

[$\star$]{style="color: blue;"} **Note:** It is important to mention
that the relationships,
$\hat\beta_{X1} = \pi\hat \beta_{X1_\pi} + (1-\pi)\hat \beta_{X1_{1-\pi}}$
and
$\hat\beta_{Y1} = \pi\hat \beta_{Y1_\pi} + (1-\pi)\hat \beta_{Y1_{1-\pi}}$,
mentioned above, are in fact only ***approximate***, to order
$\frac{1}{N_X}$ and $\frac{1}{N_Y}$ respectively where $N_X$ and $N_Y$
are the sample sizes of the exposure and outcome data sets, and hold
because maximum likelihood estimates are ***asymptotically linear***.

<br>

**PROOF:**

***Useful property:*** Suppose that we have a random vector $\bf Z$ that
is partitioned into components $\bf X$ and $\bf Y$ that is realized from
a multivariate normal distribution with mean vector with corresponding
components $\bf \mu_X$ and $\bf \mu_Y$, and variance-covariance matrix
which has been partitioned into four parts as shown below:

$$\bf Z = \begin{pmatrix} \bf X \\ \bf Y \end{pmatrix} \sim N\left( \begin{pmatrix} \bf \mu_X \\ \bf \mu_Y \end{pmatrix}, \begin{pmatrix} \bf \sum_X & \bf \sum_{XY} \\ \bf \sum_{YX} & \bf \sum_{Y} \end{pmatrix} \right)$$

Here, $\bf \sum_{X}$ is the variance-covariance matrix for the random
vector $\bf X$. $\bf \sum_{Y}$ is the variance-covariance matrix for the
random vector $\bf Y$ and $\bf \sum_{YX}$ contains the covariances
between the elements of $\bf X$ and the corresponding elements of
$\bf Y$.

Then, the conditional distribution of $\bf Y$ given that $\bf X$ takes a
particular value $\bf x$ is also going to be a multivariate normal with
conditional expectation:

$$E(\bf Y | \bf X = \bf x) = \bf \mu_Y + \bf \sum_{YX} \bf \left(\sum_X\right)^{-1}(\bf x - \bf \mu_X)$$
The conditional variance-covariance matrix of $\bf Y$ given that
$\bf X = \bf x$ is equal to the variance-covariance matrix for $\bf Y$
minus the term that involves the covariances between $\bf X$ and $\bf Y$
and the variance-covariance matrix for $\bf X$:

$$\bf{var}(\bf Y | \bf X = \bf x) = \bf \sum_Y - \sum_{YX}\left(\sum_X\right)^{-1}\sum_{XY}$$

Therefore, if we let
$\bf X = \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix}$
and
$\bf Y = \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix}$,
we can then use the above to obtain
$$E\left(\begin{pmatrix} \hat \beta_{X1_\pi}  \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1}  \\ \hat\beta_{Y1} \end{pmatrix} \right) \text{ and    }\bf{var}\left(\begin{pmatrix} \hat \beta_{X1_\pi}  \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1}  \\ \hat\beta_{Y1} \end{pmatrix} \right).$$

Thus, we now merely have to work out the values for the following:

i)  ${\bf \mu_Y} = E \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix}$

ii) ${\bf \mu_X} = E \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix}$

iii) ${\bf \sum_X} = \begin{pmatrix} \text{var}\left(\hat \beta_{X1}\right) & \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1}\right)\\ \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1}\right) & \text{var}\left(\hat \beta_{Y1}\right) \end{pmatrix}$

iv) ${\bf \sum_{XY}} = \begin{pmatrix} \text{cov}\left(\hat \beta_{X1}, \hat \beta_{X1_\pi}\right) & \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1_\pi}\right)\\ \text{cov}\left(\hat \beta_{Y1}, \hat\beta_{X1_\pi}\right) & \text{cov}\left(\hat\beta_{Y1}, \hat \beta_{Y1_\pi}\right) \end{pmatrix}$

v)  ${\bf \sum_{YX}} = \begin{pmatrix} \text{cov}\left(\hat \beta_{X1_\pi}, \hat \beta_{X1}\right) & \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1}\right)\\ \text{cov}\left(\hat \beta_{Y1_\pi}, \hat\beta_{X1}\right) & \text{cov}\left(\hat\beta_{Y1_\pi}, \hat \beta_{Y1}\right) \end{pmatrix}$

vi) ${\bf \sum_{Y}} = \begin{pmatrix} \text{var}\left(\hat \beta_{X1_\pi}\right) & \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1_\pi}\right)\\ \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1_\pi}\right) & \text{var}\left(\hat \beta_{Y1_\pi}\right) \end{pmatrix}$

<br>

[$\star \; E(\hat\beta_{X1})$ and
$\text{var}(\hat\beta_{X1})$:]{style="color: purple;"}

We will first work out ${\bf \mu_X}$ and ${\bf \sum_X}$. Let us assume
the following structural equations model linking genotype at a given
SNP, $G$, a continuous exposure, $X$ and a continuous outcome, $Y$.
Thus, for a randomly selected individual in the population, genotype,
exposure and outcome are causally linked via the following equations.

$$X = \beta_X G + \varepsilon_X + \delta_{u,x}U$$
$$Y = \beta X + \varepsilon_Y + \delta_{u,y}U$$ Here, the terms
$\varepsilon_X$, $\varepsilon_Y$ and $U$ are zero mean error terms with
finite variance. It can be shown that
$\text{cov}(X,Y) = \beta \cdot \text{var}(X) + \delta_{u,x}\delta_{u,y}\cdot\text{var}(U)$
and thus, the slope coefficient for the regression of $Y$ on $X$ is only
unbiased for $\beta$ when there is no confounding, i.e.
$\delta_{u,x}\delta_{u,y}\cdot\text{var}(U) = 0$.

<br>

***Note:*** Consider linear regression in matrix form in which we have
$\bf{X} = \bf{G_X}\beta_X + \epsilon$. Then, it is well known that the
least squares solution for
${\bf \hat \beta_X} = \begin{pmatrix} \hat \beta_{X0} \\ \hat \beta_{X1} \\ \end{pmatrix}$
is ${\bf \hat \beta_X} = (\bf{G_X}^T\bf{G_X})^{-1}\bf{G_X}^T\bf{X}$.
This vector ${\bf \hat \beta_X}$ is normally distributed with mean
$(\bf{G_X}^T\bf{G_X})^{-1}(\bf{G_X}^T\bf{G_X})\beta = \beta$ and
covariance matrix $\sigma_X^2(\bf{G_X}^T\bf{G_X})^{-1}$ =
$(\bf{G_X}^T\bf{G_X})^{-1}$ if $\sigma_X^2$ is assumed to equal 1.
Similarly, if we have $\bf{Y} = \bf{G_Y}\beta_Y + \epsilon$, then the
vector $\bf \hat \beta_Y$ is normally distributed with mean
$(\bf{G_Y}^T\bf{G_Y})^{-1}(\bf{G_Y}^T\bf{G_Y})\beta_Y = \beta_Y$ and
covariance matrix $\sigma_Y^2(\bf{G_Y}^T\bf{G_Y})^{-1}$ =
$(\bf{G_Y}^T\bf{G_Y})^{-1}$ if $\sigma_Y^2 = 1$.

<br>

Now, bearing in mind the above, suppose for each randomly sampled
individual in our large data set, we have measured their genotype for a
given SNP $i$. As well as genotype information, we have exposure values
for $N_X$ of these individuals and outcome data has been collected for
$N_Y$ of these individuals. It is possible that there could be
individuals for which we have both exposure and outcome values, i.e.
there may exist an overlap of individuals that are found in both the
exposure and outcome group. We denote the number of individuals that are
found in both as $N_{\text{overlap}}$. Clearly,
$N_{\text{overlap}} \le \text{min}\{N_X,N_Y\}$.

Focussing on the sample of $N_X$ individuals with measurements for
genotype and exposure, we denote the genotypes for the given SNP $i$ as
$G_{1},...,G_{N_X}$, with $G_j \in \{0,1,2\}$ referring to the genotype
of individual $j$ at that SNP. These genotypes for the first sample of
$N_X$ individuals can be organized in a matrix:

$$\bf{G_X} =\begin{pmatrix} 1 & G_{1} \\ 1 & G_{2} \\ \vdots & \vdots \\ 1 & G_{N_X} \end{pmatrix} = \begin{pmatrix}  \bf G_{\text{overlap}} \\ \bf G_{X_1} \end{pmatrix}$$
For this SNP $i$, an equation of the form
$\bf{X} = \bf{G_X}\beta_X + \epsilon$ is assumed in which $X_j$ is the
exposure value of individual $j$, $\bf{G_X}$ is defined as above and
$\sigma_X^2 = 1$. In order to obtain $\text{var}(\hat \beta_{X1})$ for
this SNP, we must obtain the covariance matrix of $\bf \hat \beta_X$ as
$\text{var}(\hat \beta_{X1})$ is equal to the bottom right entry of this
matrix. Thus, it follows that:

$$\bf{G_X}^T\bf{G_X} = \begin{pmatrix} N_X & \sum_{j=1}^{N_X} G_j \\ \sum_{j=1}^{N_X} G_j & \sum_{j=1}^{N_X} G_j^2  \end{pmatrix}$$

If we let $\text{maf}_i < 0.5$ denote the allele frequency for the
variant allele of SNP $i$ over the population and assume that the SNP is
in Hardy Weinberg equilibrium, then due to independent sampling, each
$G_j$ is binomially distributed with $E(G_j) = 2\text{maf}_i$ and
$E(G_j^2) = (E(G_j))^2 + \text{var}(G_j) = 4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i)$.
By the law of large numbers, this gives:

$$\bf{G_X}^T\bf{G_X} \sim \begin{pmatrix} N_X & N_X \cdot E(G_j)\\ N_X \cdot E(G_j) & N_X \cdot E(G_j^2)  \end{pmatrix} = \begin{pmatrix} N_X & N_X \cdot 2\text{maf}_i \\ N_X \cdot 2\text{maf}_i & N_X \cdot (4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i))  \end{pmatrix}$$

Now we wish to obtain $(\bf{G_X}^T\bf{G_X})^{-1}$ and extract the bottom
right entry of the resulting matrix. In the above matrix, we let
$a = N_X$, $b = N_X \cdot 2\text{maf}_i$, $c = N_X \cdot 2\text{maf}_i$
and $d = N_X \cdot (4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i))$.
Then, it can easily be shown that for SNP $i$, assuming
$\sigma_X^2 = 1$, we have:
$$\text{var}(\hat \beta_{X1}) \sim \frac{a}{ad-bc} = \frac{N_X}{(N_X)(N_X \cdot (4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i))) - (N_X \cdot 2\text{maf}_i)^2} = \frac{1}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}$$

<br>

[$\star \; E(\hat\beta_{Y1})$ and
$\text{var}(\hat\beta_{Y1})$:]{style="color: purple;"}

In a similar fashion, for a given SNP $i$, if an equation of the form
$\bf{Y} = \bf{G_Y}\beta_Y + \epsilon$ is assumed in which $Y_j$ is the
outcome value of individual $j, j = 1,..., N_Y$, then $\bf{G_Y}$ can be
defined as:
$$\bf{G_Y} =\begin{pmatrix} 1 & G_{1} \\ 1 & G_{2} \\ \vdots & \vdots \\ 1 & G_{N_Y} \end{pmatrix} = \begin{pmatrix}  \bf G_{\text{overlap}} \\ \bf G_{Y_1} \end{pmatrix}$$

***Note:*** In the above matrix $\bf G_Y$, the entries in the second
column from $G_1$ to $G_{N_{\text{overlap}}}$ will be identical to those
in the same positions of the second column of $\bf G_X$ as these entries
represent the genotypes of individuals who have had both their outcome
and exposure values measured. However, we expect the entries in the
second column of $\bf G_Y$ from $G_{N_{\text{overlap}}+1}$ to $G_{N_Y}$
to differ as these entries represent the other individuals who have only
had their value for the outcome measured. These identical parts of
$\bf G_X$ and $\bf G_Y$ are represented by the matrix
$\bf G_{\text{overlap}}$.

With $\sigma_Y^2 = 1$, then $\text{var}(\hat\beta_{Y1})$ is easily
obtained as:
$$\text{var}(\hat \beta_{Y1}) \sim \frac{1}{N_Y\cdot 2\text{maf}_i(1-\text{maf}_i)}$$

<br>

[$\star \; \text{cov}(\hat\beta_{X1}, \hat\beta_{Y1})$:]{style="color: purple;"}

The aim is now to obtain the covariance of these regression coefficients
for each SNP, i.e. $\text{cov}(\hat\beta_{X1}, \hat\beta_{Y1})$. From
above and using the two equations we have constructed
$\bf{X} = \bf{G_X}\beta_X + \epsilon$ and
$\bf{Y} = \bf{G_Y}\beta_Y + \epsilon$, we know that the estimated
regression coefficient vectors corresponding to the SNP-exposure and
SNP-outcome regressions are:
$${\bf \hat \beta_X} = (\bf{G_X}^T\bf{G_X})^{-1}\bf{G_X}^T\bf{X}$$
$${\bf \hat \beta_Y} = (\bf{G_Y}^T\bf{G_Y})^{-1}\bf{G_Y}^T\bf{Y}$$

It can be easily shown that
$N_X({\bf G_X}^T{\bf G_X})^{-1} \sim N_Y(\bf{G_Y}^T\bf{G_Y})^{-1}$ as:
$$({\bf G_X}^T{\bf G_X})^{-1} \sim \frac{1}{N_X} \begin{pmatrix} 1 & 2\text{maf}_i \\  2\text{maf}_i &  4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i)  \end{pmatrix} ^{-1} \text{and } ({\bf G_Y}^T{\bf G_Y})^{-1} \sim \frac{1}{N_Y} \begin{pmatrix} 1 & 2\text{maf}_i \\  2\text{maf}_i &  4\text{maf}_i^2 + 2\text{maf}_i(1-\text{maf}_i)  \end{pmatrix} ^{-1}.$$
Therefore, letting ${\bf C} \sim N_X(\bf{G_X}^T\bf{G_X})^{-1}$ and
${\bf C} \sim N_Y(\bf{G_Y}^T\bf{G_Y})^{-1}$, it follows that:
$${\bf \textbf{cov}(\hat\beta_X, \hat\beta_Y)} \sim \textbf{cov}\left(\frac{\bf{C}}{N_X}{\bf G_X^T}{\bf X}, \frac{\bf C}{N_Y}{\bf G_Y^T}{\bf Y}\right) = \frac{1}{N_X N_Y} \textbf{cov}\left({\bf C} {\bf G}_{\text{overlap}}^T {\bf X}_{\text{overlap}}, {\bf C} {\bf G}_{\text{overlap}}^T {\bf Y}_{\text{overlap}}\right)$$
giving
$${\bf \textbf{cov}(\hat\beta_X, \hat\beta_Y)} \sim \frac{\bf C {\bf G}_{\text{overlap}}^T \text{cov}( {\bf X}_{\text{overlap}},  {\bf Y}_{\text{overlap}}) {\bf G}_{\text{overlap} }{\bf C}^T }{N_X N_Y}$$

Here, ${\bf X}_{\text{overlap}}$ and ${\bf Y}_{\text{overlap}}$ denote
the first $N_{\text{overlap}}$ elements of $\bf X$ and $\bf Y$. Noting
that
$\textbf{cov}( {\bf X}_{\text{overlap}}, {\bf Y}_{\text{overlap}}) = \text{cov}(X,Y) {\bf I}_{N_\text{overlap}}$,
where ${\bf I}_{N_\text{overlap}}$ is the
${N_\text{overlap}} \times {N_\text{overlap}}$ identity matrix,
${\bf G_{\text{overlap}}}^T{\bf G_{\text{overlap}}} \sim N_\text{overlap}{\bf C}^{-1}$
and ${\bf C} = {\bf C}^T$, it follows that:
$${\bf \textbf{cov}(\hat\beta_X, \hat\beta_Y)} \sim \frac{N_{\text{overlap}}\text{cov}(X,Y)}{N_XN_Y} {\bf C}$$

As stated above, we are interested in
$\text{cov}(\hat\beta_{X1}, \hat\beta_{Y1})$ which is the bottom right
entry of the matrix $\bf \textbf{cov}(\hat\beta_X, \hat\beta_Y)$. As the
bottom right entry of $\bf C$ is
$\frac{1}{2\text{maf}_i(1-\text{maf}_i)}$ and letting
$\text{cov}(X,Y) = \text{cor}(X,Y) \sqrt{\text{var}(X)\text{var}(Y)} = \rho$
in which $\text{cor}(X,Y) = \rho$ and
$\text{var}(X) = \text{var}(Y) = 1$, we have:
$$\text{cov}(\hat\beta_{X1}, \hat\beta_{Y1}) \sim \frac{N_{\text{overlap}}\rho}{N_XN_Y \cdot 2\text{maf}_i(1-\text{maf}_i)}$$

Therefore, putting all of the theoretical results together, we have the
following expressions for ${\bf \mu_X}$ and ${\bf \sum_X}$:

ii) ${\bf \mu_X} = E \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix} = \begin{pmatrix} \beta_{X1} \\ \beta_{Y1} \end{pmatrix}$

iii) ${\bf \sum_X} = \begin{pmatrix} \text{var}\left(\hat \beta_{X1}\right) & \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1}\right)\\ \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1}\right) & \text{var}\left(\hat \beta_{Y1}\right) \end{pmatrix} = \frac{1}{2\text{maf}_i(1-\text{maf}_i)} \begin{pmatrix} \frac{1}{N_X} & \frac{N_{\text{overlap}}\rho}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho}{N_XN_Y} & \frac{1}{N_Y} \end{pmatrix}$

<br>

[$\star \; E(\hat\beta_{X1_\pi})$, $\text{var}(\hat\beta_{X1_\pi})$ and
$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{X1})$:]{style="color: purple;"}

Now, suppose we split the full data set into two fractions $\pi$ and
$1-\pi$. Thus, in the first fraction (sub sample), we would have
***approximately*** $\pi N_X$ individuals who have an exposure
measurement, $\pi N_Y$ who have had their outcome measured and
$\pi N_{\text{overlap}}$ individuals who have values available for both
exposure and outcome. We can write the genotype matrix of those that
have had their exposure measured in this first sub sample, denoted by
$G_{X\pi}$, as:
$$\bf G_{X\pi} = \begin{pmatrix} \bf G_{\text{overlap}{\pi}} \\ \bf G_{X_1\pi} \end{pmatrix}$$

Based on this genotype matrix, and denoting the $(\pi N_X) \times 1$
exposure vector of this sub sample by $\bf X_{\pi}$, the estimated
regression coefficient vector corresponding to this SNP-exposure
regression in the sub sample is:
$${\bf \hat \beta_{X_\pi}} = ({\bf G_{X\pi}^T G_{X\pi}})^{-1}{\bf G_{X\pi}^TX_\pi} \sim \frac{\bf C}{\pi N_X}{\bf G_{X\pi}^TX_\pi}$$

We saw above that
$\text{var}\left(\hat \beta_{X1}\right) \sim \frac{1}{N_X \cdot 2\text{maf}_i(1-\text{maf}_i)}$,
and thus, it is clear to see then that we must have
$\text{var}\left(\hat \beta_{X1_{\pi}}\right) \sim \frac{1}{\pi N_X \cdot 2\text{maf}_i(1-\text{maf}_i)}$.

Now, let us consider
$\textbf{cov}\left(\bf \hat\beta_{X_\pi}, \hat\beta_X\right) \sim \textbf{cov}\left(\frac{\bf C}{\pi N_X}{\bf G_{X\pi}^TX_\pi}, \frac{\bf C}{N_X}{\bf G_{X}^TX}\right)$.
As $\bf G_{X\pi}$ and $\bf X_\pi$ are clearly subsets of $\bf G_X$ and
$\bf X$, respectively, then we get:
$$\textbf{cov}\left({\bf \hat\beta_{X_\pi}, \hat\beta_{X}} \right) \sim \textbf{cov}\left(\frac{\bf C}{\pi N_X}{\bf G_{X\pi}^TX_{\pi}}, \frac{\bf C}{N_X}{\bf G_{X\pi}^TX_{\pi}} \right) = \frac{\bf CG_{X \pi}^T \text{var}(\bf X_\pi){\bf G_{X \pi}C^T}}{\pi N_X \cdot N_X}$$
This expression can be simplified in a similar manner to previously,
noting that ${\bf G_{X\pi}^TG_{X\pi}} \sim \pi N_X \cdot {\bf C}^{-1}$:
$$\textbf{cov}({\bf\hat\beta_{X_\pi}, \hat\beta_X}) \sim \frac{\pi N_X \cdot  {\bf C}}{\pi N_X \cdot N_X} = \frac{\bf C}{N_X}$$
We then obtain:
$$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{X1}) \sim \frac{1}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}$$
In addition, from this set-up, we can easily state that
$E(\hat\beta_{X1_\pi}) = \beta_{X1}$.

<br>

[$\star \; E(\hat\beta_{Y1_\pi})$, $\text{var}(\hat\beta_{Y1_\pi})$ and
$\text{cov}(\hat\beta_{Y1_\pi}, \hat\beta_{Y1})$:]{style="color: purple;"}

Now, due to the way we have partitioned the original data set, we can
write the genotype matrix for the outcome-SNP regression in the first
sub sample, denoted by $\bf G_{Y\pi}$, in the form:
$$\bf G_{Y\pi} = \begin{pmatrix}  \bf G_{\text{overlap}{\pi}} \\ \bf G_{Y_1\pi} \end{pmatrix} $$

Similar to when we considered the full data set, $\bf G_{Y\pi}$ and
$\bf G_{X\pi}$ share their first $\pi \times N_{\text{overlap}}$ rows,
represented by the matrix $\bf G_{\text{overlap}\pi}$. This matrix,
$\bf G_{\text{overlap}\pi}$, contains the genotypes of the individuals
who are contained in the first sub sample and have had both their
outcome and exposure values measured. The estimated regression
coefficient vector corresponding to the SNP-outcome regression in the
sub sample is:
$${\bf \hat \beta_{Y_\pi}} = ({\bf G_{Y\pi}^T G_{Y\pi}})^{-1}{\bf G_{Y\pi}^TY_\pi} \sim \frac{\bf C}{\pi N_Y}{\bf G_{Y\pi}^TY_\pi}$$
Therefore, following the same process as we used above in order to
obtain $\text{var}\left(\hat \beta_{X1_{\pi}}\right)$ and
$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{X1})$, it is easy to see that
we should obtain
$\text{var}\left(\hat \beta_{Y1_{\pi}}\right) \sim \frac{1}{\pi N_Y \cdot 2\text{maf}_i(1-\text{maf}_i)}$
and
$\text{cov}(\hat\beta_{Y1_\pi}, \hat\beta_{Y1}) \sim \frac{1}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}$.
Also, we get $E(\hat\beta_{Y1_\pi}) = \beta_{Y1}$.

<br>

[$\star \; \text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{Y1_\pi})$:]{style="color: purple;"}

We next consider $\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{Y1_\pi})$.
We saw that $\bf G_{X\pi}$ can be partitioned as
$\bf G_{X\pi} = \begin{pmatrix} \bf G_{\text{overlap}{\pi}} \\ \bf G_{X_1\pi} \end{pmatrix}$
and similarly, $\bf G_{Y\pi}$ can be partitioned as
$\bf G_{Y\pi} = \begin{pmatrix} \bf G_{\text{overlap}{\pi}} \\ \bf G_{Y_1\pi} \end{pmatrix}$.
Therefore, we get:
$$\textbf{cov}\left({\bf\hat\beta_{X_\pi}, \hat\beta_{Y_\pi} }\right) \sim \textbf{cov}\left(\frac{\bf C}{\pi N_X}{\bf G_{X\pi}^TX_{\pi}}, \frac{\bf C}{\pi N_Y}{\bf G_{Y\pi}^TY_{\pi}} \right) = \frac{\bf CG_{overlap \pi}^T \text{cov}(\bf X_{overlap\pi}, Y_{overlap\pi}){\bf G_{overlap \pi}C^T}}{\pi N_X \cdot \pi N_Y}$$
This simplifies, giving:
$$\textbf{cov}({\bf \hat\beta_{X_\pi}, \hat\beta_{Y_\pi}}) \sim \frac{\pi N_{\text{overlap}}\text{cov}(X,Y)}{\pi N_X \cdot \pi N_Y} {\bf C}$$
and subsequently:
$$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{Y1_\pi}) \sim \frac{N_{\text{overlap}}\rho}{\pi N_XN_Y \cdot 2\text{maf}_i(1-\text{maf}_i)}$$

<br>

[$\star \; \text{cov}(\hat\beta_{X1}, \hat\beta_{Y1_\pi})$ and
$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{Y1})$:]{style="color: purple;"}

Now, let us find $\textbf{cov}({\bf\hat\beta_{X}, \hat\beta_{Y_\pi}})$
and $\textbf{cov}({\bf\hat\beta_{X_\pi}, \hat\beta_{Y}})$. Using our
expressions for $\bf \hat\beta_X$ and $\bf \hat\beta_{Y_\pi}$ detailed
above and knowing that the genotype matrices $\bf G_{X}$ and
$\bf G_{Y_\pi}$ share genotype information of $\pi N_{\text{overlap}}$
individuals which is contained in $G_{\text{overlap}\pi}$, we get:
$$\textbf{cov}\left({\bf \hat\beta_{X}, \hat\beta_{Y_\pi}}\right) \sim \textbf{cov}\left(\frac{\bf C}{N_X}{\bf G_{X}^TX}, \frac{\bf C}{\pi N_Y}{\bf G_{Y\pi}^TY_{\pi}} \right) = \frac{\bf CG_{overlap \pi}^T \text{cov}(\bf X_{overlap\pi}, Y_{overlap\pi}){\bf G_{overlap \pi}C^T}}{ N_X \cdot \pi N_Y}$$

It follows that:
$$\textbf{cov}({\bf\hat\beta_{X}, \hat\beta_{Y_\pi}}) \sim \frac{ \pi N_{\text{overlap}}\text{cov}(X,Y)}{N_X \cdot \pi N_Y} {\bf C}$$
and this gives:
$$\text{cov}(\hat\beta_{X1}, \hat\beta_{Y1_\pi}) \sim \frac{N_{\text{overlap}}\rho}{ N_XN_Y \cdot 2\text{maf}_i(1-\text{maf}_i)}$$

In a very similar fashion, using our expressions for
$\bf \hat\beta_{X_\pi}$ and $\bf \hat\beta_{Y}$ detailed above, we get:
$$\text{cov}(\hat\beta_{X1_\pi}, \hat\beta_{Y1}) \sim \frac{N_{\text{overlap}}\rho}{ N_XN_Y \cdot 2\text{maf}_i(1-\text{maf}_i)}$$

<br>

Therefore, we finally have the following results for $\bf \mu_Y$,
${\bf \sum_{XY}}$, ${\bf \sum_{YX}}$ and ${\bf \sum_{Y}}$:

i)  ${\bf \mu_Y} = E \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} = \begin{pmatrix} \beta_{X1} \\ \beta_{Y1} \end{pmatrix}$

ii) ${\bf \sum_{XY}} = \begin{pmatrix} \text{cov}\left(\hat \beta_{X1}, \hat \beta_{X1_\pi}\right) & \text{cov}\left(\hat \beta_{X1}, \hat\beta_{Y1_\pi}\right)\\ \text{cov}\left(\hat \beta_{Y1}, \hat\beta_{X1_\pi}\right) & \text{cov}\left(\hat\beta_{Y1}, \hat \beta_{Y1_\pi}\right) \end{pmatrix} = \frac{1}{2\text{maf}_i(1-\text{maf}_i)}\begin{pmatrix} \frac{1}{N_X} & \frac{N_{\text{overlap}}\rho}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho}{N_XN_Y} & \frac{1}{N_Y} \end{pmatrix}$

iii) ${\bf \sum_{YX}} = \begin{pmatrix} \text{cov}\left(\hat \beta_{X1_\pi}, \hat \beta_{X1}\right) & \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1}\right)\\ \text{cov}\left(\hat \beta_{Y1_\pi}, \hat\beta_{X1}\right) & \text{cov}\left(\hat\beta_{Y1_\pi}, \hat \beta_{Y1}\right) \end{pmatrix} = \frac{1}{2\text{maf}_i(1-\text{maf}_i)}\begin{pmatrix} \frac{1}{N_X} & \frac{N_{\text{overlap}}\rho}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho}{N_XN_Y} & \frac{1}{N_Y} \end{pmatrix}$

iv) ${\bf \sum_{Y}} = \begin{pmatrix} \text{var}\left(\hat \beta_{X1_\pi}\right) & \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1_\pi}\right)\\ \text{cov}\left(\hat \beta_{X1_\pi}, \hat\beta_{Y1_\pi}\right) & \text{var}\left(\hat \beta_{Y1_\pi}\right) \end{pmatrix} = \frac{1}{\pi} \cdot \frac{1}{2\text{maf}_i(1-\text{maf}_i)}\begin{pmatrix} \frac{1}{N_X} & \frac{N_{\text{overlap}}\rho}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho}{N_XN_Y} & \frac{1}{N_Y} \end{pmatrix}$

Therefore, it is clear to see that
${\bf \sum_{X}} = {\bf \sum_{XY}} = {\bf \sum_{YX}}$ and
$\pi \cdot {\bf \sum_{Y}} = {\bf \sum_{X}}$.

Then, using the identities, we can establish
$E\left(\begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \right)$
and
$\bf{var}\left(\begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \right)$
as follows:

-   $E\left(\begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \right) = \begin{pmatrix} \beta_{X1} \\ \beta_{Y1} \end{pmatrix} + \bf \sum_{X} \bf \left(\sum_X\right)^{-1} \left( \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} - \begin{pmatrix} \beta_{X1} \\ \beta_{Y1} \end{pmatrix} \right) = \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix}$

-   $\bf{var}\left(\begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} | \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \right) = \frac{1}{\pi} {\bf \sum_{X}} - {\bf \sum_{X}} \left( {\bf \sum_{X}} \right)^{-1}{\bf \sum_{X}} = \left( \frac{1-\pi}{\pi}\right) {\bf \sum_{X}} = \left( \frac{1-\pi}{\pi}\right) \cdot \textbf{var}\left( \begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \right)$

Therefore, we finally have obtained the required conditional
distribution:

$$ \left( \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} \Bigl \lvert \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix} \right) \sim N\left( \begin{pmatrix} \hat\beta_{X1}  \\ \hat\beta_{Y1} \end{pmatrix}, \left( \frac{1-\pi}{\pi}\right) \cdot \frac{1}{2\text{maf}_i(1-\text{maf}_i)}\begin{pmatrix} \frac{1}{N_X} & \frac{N_{\text{overlap}}\rho}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho}{N_XN_Y} & \frac{1}{N_Y} \end{pmatrix}\right)$$

<br>

***Note:*** The above expression holds in the case that
$\text{var}(X) = \text{var}(Y) = 1$, as stated above. Let us briefly
consider how we could rewrite this expression if it is ***not*** the
case that $\text{var}(X) = \text{var}(Y) = 1$. Firstly, our expression
would now have to include $\text{var}(X)$ and $\text{var(Y)}$ as
follows:

$$ \left( \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} \Bigl \lvert \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix} \right) \sim N\left( \begin{pmatrix} \hat\beta_{X1}  \\ \hat\beta_{Y1} \end{pmatrix}, \left( \frac{1-\pi}{\pi}\right) \cdot \frac{1}{2\text{maf}_i(1-\text{maf}_i)}\begin{pmatrix} \frac{\text{var}(X)}{N_X} & \frac{N_{\text{overlap}}\rho\sqrt{\text{var}(X)\text{var}(Y)}}{N_XN_Y}\\ \frac{N_{\text{overlap}}\rho\sqrt{\text{var}(X)\text{var}(Y)}}{N_XN_Y} & \frac{\text{var}(Y)}{N_Y} \end{pmatrix}\right)$$

However, it is possible to write this in another form in which we make
use of the fact that we already have estimates for
$\text{se}\left(\hat \beta_{X1}\right)$ and
$\text{se}\left(\hat \beta_{Y1}\right)$. We note the following:

i.  As
    $\text{var}(\hat \beta_{X1}) \sim \frac{\text{var}(X)}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}$,
    then
    $\left(\text{se}(\hat \beta_{X1})\right)^2 \sim \frac{\text{var}(X)}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}$.

ii. As
    $\text{var}(\hat \beta_{Y1}) \sim \frac{\text{var}(Y)}{N_Y\cdot 2\text{maf}_i(1-\text{maf}_i)}$,
    then
    $\left(\text{se}(\hat \beta_{Y1})\right)^2 \sim \frac{\text{var}(Y)}{N_Y\cdot 2\text{maf}_i(1-\text{maf}_i)}$.

iii. $\text{se}\left(\hat \beta_{X1}\right) \cdot \text{se}\left(\hat \beta_{Y1}\right) = \sqrt{\frac{\text{var}(X)}{N_X\cdot 2\text{maf}_i(1-\text{maf}_i)}}\cdot \sqrt{\frac{\text{var}(Y)}{N_Y\cdot 2\text{maf}_i(1-\text{maf}_i)}} = \frac{1}{2\text{maf}_i(1-\text{maf}_i)} \frac{\sqrt{\text{var}(X)\text{var}(Y)}}{\sqrt{N_X N_Y}}$

Putting all of the above together, we obtain an alternative form of the
required conditional distribution:

$$ \left( \begin{pmatrix} \hat \beta_{X1_\pi} \\ \hat \beta_{Y1_\pi} \end{pmatrix} \Bigl \lvert \begin{pmatrix} \hat \beta_{X1} \\ \hat \beta_{Y1} \end{pmatrix} \right) \sim N\left( \begin{pmatrix} \hat\beta_{X1}  \\ \hat\beta_{Y1} \end{pmatrix}, \left( \frac{1-\pi}{\pi}\right) \begin{pmatrix} \left(\text{se}\left(\hat \beta_{X1}\right)\right)^2 & \text{se}\left(\hat \beta_{X1}\right) \text{se}\left(\hat \beta_{Y1}\right) \frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}}\\ \text{se}\left(\hat \beta_{X1}\right) \text{se}\left(\hat \beta_{Y1}\right) \frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}} & \left(\text{se}\left(\hat \beta_{Y1}\right)\right)^2 \end{pmatrix}\right)$$

<br><br>

### Estimating the Causal Effect 

For a given data set, we can
easily simulate $\hat\beta_{X1_\pi}$ and $\hat\beta_{Y1_\pi}$ for each SNP using the above conditional distribution and our known values of $\hat\beta_{X1}$ and $\hat\beta_{Y1}$. We
then obtain $\widehat{\text{se}(\hat\beta_{X1_\pi})}$ by approximating
it with
$\sqrt{\text{var}(\hat\beta_{X1_\pi})} \sim \sqrt{\frac{1}{\pi}\cdot (\text{se}(\hat\beta_{X1}))^2}$,
and subsequently, obtain the corresponding $p$-value for
$\hat\beta_{X1_\pi}$ for each SNP. Any SNPs who have a $p$-value less
than $5 \times 10^{-8}$, or another threshold of choice, are then **selected**.

Then, as mentioned in the opening paragraph of this document, in order to avoid *Winner's Curse*, we obtain the estimates
corresponding to the other $1-\pi$ fraction of the data set, i.e.
$\hat\beta_{X1_{1-\pi}}$, $\widehat{\text{se}(\hat\beta_{X1_{1-\pi}})}$,
$\hat\beta_{Y1_{1-\pi}}$ and
$\widehat{\text{se}(\hat\beta_{Y1_{1-\pi}})}$, using:

-   $\hat\beta_{X1_{1-\pi}} = \frac{\hat\beta_{X1} - \pi\hat\beta_{X1_\pi}}{1-\pi}$

-   $\hat\beta_{Y1_{1-\pi}} = \frac{\hat\beta_{Y1} - \pi\hat\beta_{Y1_\pi}}{1-\pi}$

-   $\widehat{\text{se}(\hat\beta_{X1_{1-\pi}})} \sim \sqrt{\frac{1}{1-\pi}\cdot (\text{se}(\hat\beta_{X1}))^2}$

-   $\widehat{\text{se}(\hat\beta_{Y1_{1-\pi}})} \sim \sqrt{\frac{1}{1-\pi}\cdot (\text{se}(\hat\beta_{Y1}))^2}$

The MR method of choice can then be applied to these estimates to obtain an estimate for the causal effect. For example, $\hat\beta_{X1_{1-\pi}}$, $\widehat{\text{se}(\hat\beta_{X1_{1-\pi}})}$,
$\hat\beta_{Y1_{1-\pi}}$ and
$\widehat{\text{se}(\hat\beta_{Y1_{1-\pi}})}$, can be inputted into the `mr` function from the R
package `TwoSampleMR`, with a specified MR method, such as `"mr_ivw"` or `"mr_raps"`. The idea is that our method will
incorporate **several iterations** of this described process and then obtain
an **average** of all results in order to provide an estimate for
$\hat\beta$, the causal effect of the exposure on the outcome, which
does not suffer from *Winner's Curse* bias.

[$\star$]{style="color: blue;"} **Note:** If we let $\hat\beta^{(i)}$ be the estimate for the causal
effect obtained at iteration $i$, then our final estimate for the **causal
effect** of the exposure on the outcome is denoted by
$\overline{\hat\beta} = \sum_{i=1}^{N_{\text{iter}}} \hat\beta^{(i)}$, the average of the estimates
obtained at each iteration.

Our next task is to obtain a suitable value for
$\text{se}\left( \overline{\hat\beta} \right)$, the **standard error** of
our causal effect estimate. In order to do so, let us consider
$\sum_{i=1}^{N_{\text{iter}}}\left( \hat\beta^{(i)} - \overline{\hat\beta} \right)^2$
which can be easily computed from our set of results. Now,

$$\sum_{i=1}^{N_{\text{iter}}}\left( \hat\beta^{(i)} - \overline{\hat\beta} \right)^2 \approx E\left[ \sum_{i=1}^{N_{\text{iter}}}\left( \hat\beta^{(i)} - \overline{\hat\beta} \right) ^2 \right] = \sum_{i=1}^{N_{\text{iter}}} \left[E\left( \left(\hat\beta^{(i)} \right)^2 \right)\right] - N_{\text{iter}}\cdot E\left( \left( \overline{\hat\beta}\right)^2 \right)$$
Using the well-known identity $E(X^2) = \text{var}(X) + (E(X))^2$, we
get:
$$\sum_{i=1}^{N_{\text{iter}}}\left( \hat\beta^{(i)} - \overline{\hat\beta} \right) \approx \sum_{i=1}^{N_{\text{iter}}} \left[ \text{var}\left(\hat\beta^{(i)}\right) + \left(E\left(\hat\beta^{(i)}\right)\right)^2 \right] - N_{\text{iter}}\cdot \left[ \text{var}\left(\overline{\hat\beta}\right) + \left(E\left(\overline{\hat\beta}\right)\right)^2\right]$$

As$E\left( \hat\beta^{(i)} \right) = E\left( \overline{\hat\beta} \right)$
for $i=1,...,N_{\text{iter}}$, we have:
$$\sum_{i=1}^{N_{\text{iter}}}\left( \hat\beta^{(i)} - \overline{\hat\beta} \right) \approx \sum_{i=1}^{N_{\text{iter}}} \left[ \text{var}\left(\hat\beta^{(i)}\right)\right] - N_{\text{iter}}\cdot \left[ \text{var}\left(\overline{\hat\beta}\right)\right]$$
This finally gives us an expression for
$\text{se}\left( \overline{\hat\beta} \right)$ as follows:

$$\text{se}\left( \overline{\hat\beta} \right) = \sqrt{\frac{\sum_{i=1}^{N_{\text{iter}}} \left[ \left( \text{se}\left(\hat\beta^{(i)}\right) \right) ^2\right] - \sum_{i=1}^{N_{\text{iter}}}\left[ \hat\beta^{(i)} - \overline{\hat\beta} \right]}{N_{\text{iter}}}}.$$

<br><br>

### Estimating Correlation

Ideally, we would like to be able to use our method when only summary
statistics are available, i.e. we only have information on
$\hat\beta_{X_i}$, $\hat\beta_{Y_i}$, $\text{se}(\hat\beta_{X_i})$ and
$\text{se}(\hat\beta_{Y_i})$ for each SNP $i$. Therefore, in the
equation above, we would need to estimate a value for
$\frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}}$.

[$\star$]{style="color: blue;"} **Note:** From here, we will denote
$\hat\beta_{X1}$ for SNP $i$ simply by $\hat\beta_{X_i}$ and similarly,
$\hat\beta_{Y1}$ for SNP $i$ will be represented by $\hat\beta_{Y_i}$.

In a similar form to the expression above, we assume for each SNP $i$
that $\hat\beta_{X_i}$ and $\hat\beta_{Y_i}$ follow the following
bivariate normal distribution:

$$  \begin{pmatrix} \hat \beta_{X_i} \\ \hat \beta_{Y_i} \end{pmatrix} \sim N\left( \begin{pmatrix} \beta_{X_i}  \\ \beta_{Y_i} \end{pmatrix}, \begin{pmatrix} \left(\text{se}\left(\hat \beta_{X_i}\right)\right)^2 & \text{se}\left(\hat \beta_{X_i}\right) \text{se}\left(\hat \beta_{Y_i}\right) \frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}}\\ \text{se}\left(\hat \beta_{X_i}\right) \text{se}\left(\hat \beta_{Y_i}\right) \frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}} & \left(\text{se}\left(\hat \beta_{Y_i}\right)\right)^2 \end{pmatrix}\right)$$

For convenience, let us represent
$\frac{N_{\text{overlap}}\rho}{\sqrt{N_XN_Y}}$ by $\lambda$ as this is
the value we are interested in estimating. Thus $\lambda$ is essentially
equivalent to the correlation between $\hat\beta_{X_i}$ and
$\hat\beta_{Y_i}$ for each SNP $i$. In addition, we let
$\text{se}(\hat\beta_{X_i}) \approx \sigma_{X_i}$ and
$\text{se}(\hat\beta_{Y_i}) \approx \sigma_{Y_i}$. The bivariate normal
distribution then takes the simpler form of:

$$  \begin{pmatrix} \hat \beta_{X_i} \\ \hat \beta_{Y_i} \end{pmatrix} \sim N\left( \begin{pmatrix} \beta_{X_i}  \\ \beta_{Y_i} \end{pmatrix}, \begin{pmatrix} \left(\sigma_{X_i}\right)^2 & \sigma_{X_i} \sigma_{Y_i} \lambda \\ \sigma_{X_i} \sigma_{Y_i} \lambda & \left(\sigma_{Y_i}\right)^2 \end{pmatrix}\right)$$

Given this, the corresponding ***probability density function*** for
each SNP $i$ can be written as:

$$f\left( \hat \beta_{X_i}, \hat \beta_{Y_i} \right) = \frac{1}{2\pi\sqrt{1-\lambda^2}\sigma_{X_i}\sigma_{Y_i}}e^{ -\frac{1}{2(1-\lambda^2)} \left[ \left( \frac{\hat \beta_{X_i} - \beta_{X_i}}{\sigma_{X_i}}\right)^2 - 2\lambda\left(\frac{\hat \beta_{X_i} - \beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat \beta_{Y_i} - \beta_{Y_i}}{\sigma_{Y_i}}\right) + \left( \frac{\hat \beta_{Y_i} - \beta_{Y_i}}{\sigma_{Y_i}}\right)^2\right]}$$

Thus, we can form a likelihood function for $\lambda$ for a set of $n$
SNPs,
$\left(\hat\beta_{X_i}, \hat\beta_{Y_i}, \sigma_{X_i}, \sigma_{Y_i}\right)$,
$i=1,...,n$:

$$
\begin{aligned}
L\left( \lambda | \bf{\hat\beta_X, \hat\beta_Y, \sigma_X, \sigma_Y} \right) &= \Pi_{i=1}^{n}f\left( \hat \beta_{X_i}, \hat \beta_{Y_i} \right) \\ &= \left( \frac{1}{2\pi\sqrt{1-\lambda^2}} \right)^n \cdot\Pi_{i=1}^{n}\left(\frac{1}{\sigma_{X_i}\sigma_{Y_i}}\right)\cdot e^{-\frac{1}{2(1-\lambda^2)}\left[ \sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)^2 -2\lambda\sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] + \sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)^2\right]}
\end{aligned}
$$

where
$\hat\beta_X = (\hat\beta_{X_1},...,\hat\beta_{X_n}), \hat\beta_Y = (\hat\beta_{Y_1},...,\hat\beta_{Y_n}), \sigma_X = (\sigma_{X_1},...,\sigma_{X_n})$
and $\sigma_Y = (\sigma_{Y_1},...,\sigma_{Y_n})$, the observed values
for each SNP.

The ***log-likelihood function*** for $\lambda$,
$\text{log}L(\lambda) = l(\lambda)$ can then be derived as follows:

$$
l\left( \lambda \right) = -n \text{log}(2\pi) - \frac{n}{2}\text{log}(1-\lambda^2) - \text{log}(\Pi_{i=1}^{n}\left(\sigma_{X_i}\sigma_{Y_i}\right)) - \frac{1}{2(1-\lambda^2)}\left[ \sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)^2 -2\lambda\sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] + \sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)^2\right]
$$

[$\star$]{style="color: blue;"} **Assumption:** If assume that
$\beta_{X_i} = 0$ and $\beta_{Y_i} = 0$ for $i=1,...,n$, we can then
denote the following constants by letters to simplify our derivations:

-   $\sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)^2 = \sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)^2 = A$
-   $\sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}-\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] = \sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] = B$
-   $\sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}-\beta_{Y_i}}{\sigma_{Y_i}}\right)^2 = \sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)^2 = C$

In order to find the ***maximum likelihood estimate*** (MLE) for
$\lambda$, we must first obtain an expression for
$\frac{d}{d\lambda}l(\lambda)$ and then solve equal to zero. Using our
defined constants $A$, $B$ and $C$ above, we proceed as follows:

$$
\begin{aligned}
\frac{d}{d\lambda}l\left( \lambda \right) &= 
\frac{d}{d\lambda}\left[ -n \text{log}(2\pi) - \frac{n}{2}\text{log}(1-\lambda^2) - \text{log}\left(\Pi_{i=1}^{n}\left(\sigma_{X_i}\sigma_{Y_i}\right)\right) - \frac{1}{2(1-\lambda^2)}\left(A - 2\lambda B + C\right)\right] \\ &=  - \frac{n}{2}\frac{d}{d\lambda}\left[\text{log}(1-\lambda^2) \right] - \frac{1}{2}\frac{d}{d\lambda}\left[ \frac{A}{1-\lambda^2} - \frac{2\lambda B}{1-\lambda^2} +\frac{C}{1-\lambda^2}\right] \\ &= -\frac{n}{2}\cdot\left[-\frac{2\lambda}{1-\lambda^2}\right] - \frac{1}{2}\cdot\left[ \frac{2\lambda A}{\left(1-\lambda^2\right)^2} - \frac{2\left(1+\lambda^2\right)B}{\left(1-\lambda^2\right)^2} +  \frac{2\lambda C}{\left(1-\lambda^2\right)^2}\right] \\ &= \frac{n\lambda}{\left(1-\lambda^2\right)^2}\cdot \left[ \left(1-\lambda^2\right) - \frac{A}{n} + \frac{1-\lambda^2}{\lambda}\frac{B}{n} - \frac{C}{n}\right] \\ &= \frac{n\lambda}{\left(1-\lambda^2\right)^2}\cdot \left[ \left(1-\lambda^2\right) - \tilde{A} + \frac{1-\lambda^2}{\lambda}\tilde{B} - \tilde{C}\right]
\end{aligned}
$$

in which we have let $\tilde{A} = \frac{A}{n}, \tilde{B} = \frac{B}{n}$
and $\tilde{C} = \frac{C}{n}$.

Solving the above equation equal to zero gives the following:

$$
\begin{aligned}
\frac{d}{d\lambda}l\left( \lambda \right) = 0 &\implies \frac{n\lambda}{\left(1-\lambda^2\right)^2}\cdot \left[ \left(1-\lambda^2\right) - \tilde{A} + \frac{1-\lambda^2}{\lambda}\tilde{B} - \tilde{C}\right] = 0 \\ &\implies \left[ \left(1-\lambda^2\right) - \tilde{A} + \frac{1-\lambda^2}{\lambda}\tilde{B} - \tilde{C}\right] = 0 \\ &\implies \tilde{A} - \frac{1-\lambda^2}{\lambda}\tilde{B} + \tilde{C} = 1 - \lambda^2 \\ &\implies \lambda^3 - \tilde{B}\lambda^2 + \left(\tilde{A} + \tilde{C} - 1\right)\lambda - \tilde{B} = 0
\end{aligned}
$$

[$\star$]{style="color: blue;"} **Cubic equation for** $\lambda$?

In the following example, we will use our work above to obtain an
estimate for $\lambda$ using simulated data. First, we establish a
function to simulate data, `sim_mr_stats`.

```{r}
sim_mr_stats <- function(n_snps, prop_effect, h2, frac_overlap, n_x, n_y, cor_xy, beta_xy){
  n_overlap <- frac_overlap*min(n_x, n_y)
  maf <- runif(n_snps, 0.01, 0.5)
  effect_snps <- n_snps*prop_effect
  index <- sample(1:n_snps, ceiling(effect_snps), replace=FALSE) # random sampling
  beta_gx <- rep(0,n_snps)
  beta_gx[index] <- rnorm(length(index),0,1)
  var_x <- sum(2*maf*(1-maf)*beta_gx^2)/h2
  if(var_x != 0){beta_gx <- beta_gx/sqrt(var_x)} # scaling to represent an exposure with variance 1
  beta_gy <- beta_gx * beta_xy

  var_gx <- 1/(n_x*2*maf*(1-maf)) # var(X)=1
  var_gy <- 1/(n_y*2*maf*(1-maf)) # var(Y)=1
  cov_gx_gy <- ((n_overlap*cor_xy)/(n_x*n_y))*(1/(2*maf*(1-maf)))
  # create covariance matrix for each SNP
  cov_array <- array(dim=c(2, 2, n_snps))
  cov_array[1,1,] <- var_gx
  cov_array[2,1,] <- cov_gx_gy
  cov_array[1,2,] <- cov_array[2,1,]
  cov_array[2,2,] <- var_gy

  summary_stats <- apply(cov_array, 3, function(x){MASS::mvrnorm(n=1, mu=c(0,0), Sigma=x)})
  summary_stats <- t(summary_stats + rbind(beta_gx, beta_gy))

  data <- tibble(
    SNP = 1:n_snps,
    beta.exposure = summary_stats[,1],
    beta.outcome = summary_stats[,2],
    se.exposure = sqrt(var_gx),
    se.outcome = sqrt(var_gy),
    true.exposure = beta_gx,
    true.outcome = beta_gy
  )
  return(data)
}

```

We now use the function, `mr_sim_stats`, to simulate sets of summary
statistics with different proportions of effect SNPs. We anticipate that
solving the above cubic equation for $\lambda$ or alternatively,
optimising the ***log-likelihood function*** for $\lambda$, will become
less accurate at estimating $\lambda$ as the proportion of effect SNPs
increases. This is due to the increased violation of our **assumption**
that $\beta_{X_i} = 0$ and $\beta_{Y_i} = 0$ for $i=1,...,n$. Note that
as the roots of the cubic equation can be both real and imaginary, we
will focus on using the function `optimise` to optimise the
***log-likelihood function*** rather than solving the cubic equation. In
all examples below, the fraction of overlap is 1 between the exposure
and outcome samples and therefore, the true value for $\lambda$ is equal
to the correlation between the exposure, $X$ and outcome, $Y$ which has
been set to 0.6.

```{r}
set.seed(1998)
## prop_effect = 0
data <- sim_mr_stats(10^5,0,0.4,1,50000,50000,0.6,0.3) 
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)
f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
optimize(f,interval=c(-1,1),maximum=TRUE)$maximum

set.seed(1998)
## prop_effect = 0.01
data <- sim_mr_stats(10^5,0.01,0.4,1,50000,50000,0.6,0.3) 
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)
f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
optimize(f,interval=c(-1,1),maximum=TRUE)$maximum

set.seed(1998)
## prop_effect = 0.1
data <- sim_mr_stats(10^5,0.1,0.4,1,50000,50000,0.6,0.3) 
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)
## optimise log-likelihood
f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
optimize(f,interval=c(-1,1),maximum=TRUE)$maximum

set.seed(1998)
## prop_effect = 0.2
data <- sim_mr_stats(10^5,0.2,0.4,1,50000,50000,0.6,0.3) 
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)
## optimise log-likelihood
f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
optimize(f,interval=c(-1,1),maximum=TRUE)$maximum
```

It is clear to see that, as anticipated, as more non-null effect SNPs
are included in our calculations, bias is introduced into our estimate
of $\lambda$. Therefore, in order to counteract this, we must select
SNPs based on their $z$-values and perform our calculations with just
these SNPs. We repeat one of the examples above but just with those SNPs
in which their absolute $z$-values for both exposure and outcome are
less than 0.5. It can be seen below that the correlation estimate is now
extremely upward biased, indicating that our log-likelihood expression
must then take into account this selection process.

```{r}
## prop_effect = 0.1
set.seed(1998)
data <- sim_mr_stats(10^5,0.1,0.4,1,50000,50000,0.6,0.3) 
data <- data[abs(data$beta.exposure/data$se.exposure) < 0.5 & abs(data$beta.outcome/data$se.outcome) < 0.5,]
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)
## optimise log-likelihood
f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
optimize(f,interval=c(-1,1),maximum=TRUE)$maximum
```

[$\star$]{style="color: blue;"} **Question of interest:** Why has the
value here increased towards 1, rather than decreased as we might have
expected by restricting the region?

Therefore, we must now work on establishing this new ***conditional
log-likelihood*** expression. As we have chosen to select SNPs with
absolute $z$-scores for both exposure and outcome that are less than
0.5, we first consider obtaining an expression for the probability of
each SNP having absolute $z$-scores for both exposure and outcome less
than 0.5. Continuing to assume that $\beta_{X_i}$ and $\beta_{Y_i}$ are
both equal to 0 and $\sigma_{X_i}$ and $\sigma_{Y_i}$ are known, this
probability for a single SNP is given by the following cumulative
distribution function:

$$f\left( |z_{X_i}| < 0.5, |z_{Y_i}| < 0.5 \right) = \frac{1}{2\pi\sqrt{1-\lambda^2}\sigma_{X_i}\sigma_{Y_i}} \int^{0.5}_{-0.5} \int^{0.5}_{-0.5} e^{ -\frac{1}{2(1-\lambda^2)} \left[ \left( z_{X_i}\right)^2 - 2\lambda\left(z_{X_i}\right)\left(z_{Y_i}\right) + \left( z_{Y_i}\right)^2\right]} dz_{X_i} dz_{Y_i}$$

Using the above expression, we can then establish our desired
conditional likelihood, i.e. the likelihood of $\lambda$ given that only
SNPs with both absolute $z$-scores less than 0.5 have been selected. We
note the first two terms of the numerator and denominator cancel each
other out in the expression, leaving only the exponential terms.

$$
\begin{aligned}
L\left( \lambda \right) &= \frac{\Pi_{i=1}^{n}f\left( \hat \beta_{X_i}, \hat \beta_{Y_i} \right)}{\left[ f\left( |z_{X_i}| < 0.5, |z_{Y_i}| < 0.5 \right)\right]^n} \\ &=  \frac{e^{-\frac{1}{2(1-\lambda^2)}\left[ \sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)^2 -2\lambda\sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] + \sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)^2\right]}}{\left[ \int^{0.5}_{-0.5} \int^{0.5}_{-0.5} e^{ -\frac{1}{2(1-\lambda^2)} \left[ \left( z_{X_i}\right)^2 - 2\lambda\left(z_{X_i}\right)\left(z_{Y_i}\right) + \left( z_{Y_i}\right)^2\right]} dz_{X_i} dz_{Y_i}\right]^n}
\end{aligned}
$$

The ***conditional log-likelihood*** is then found to be:

$$
l\left( \lambda \right) = {-\frac{1}{2(1-\lambda^2)}\left[ \sum_{i=1}^{n}\left( \frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)^2 -2\lambda\sum_{i=1}^{n}\left[\left(\frac{\hat\beta_{X_i}}{\sigma_{X_i}}\right)\left(\frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)\right] + \sum_{i=1}^{n}\left( \frac{\hat\beta_{Y_i}}{\sigma_{Y_i}}\right)^2\right]}- n \cdot \log \left[ \int^{0.5}_{-0.5} \int^{0.5}_{-0.5} e^{ -\frac{1}{2(1-\lambda^2)} \left[ \left( z_{X_i}\right)^2 - 2\lambda\left(z_{X_i}\right)\left(z_{Y_i}\right) + \left( z_{Y_i}\right)^2\right]} dz_{X_i} dz_{Y_i}\right]
$$

We now simulate data in a similar manner to above and consider
estimating $\lambda$ by optimizing this conditional log-likelihood
function. The inclusion of the integral in this expression makes it much
more complex to work with than the previous function. However, we will
attempt to define the function and subsequently optimize it using the
`pracma` package, as shown below.

```{r}
library(pracma)
set.seed(1998)
data <- sim_mr_stats(10^5,0.1,0.4,1,50000,50000,0.6,0.3) 
data <- data[abs(data$beta.exposure/data$se.exposure) < 0.5 & abs(data$beta.outcome/data$se.outcome) < 0.5,]
n <- nrow(data)
B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
A <- sum((data$beta.exposure/data$se.exposure)^2) 
C <- sum((data$beta.outcome/data$se.outcome)^2)

fun_obj <- function(lambda){
 - ((1)/(2*(1-lambda^2)))*(A-2*lambda*B+C) - n*log((pracma::integral2(function(x,y) 
  exp((-(1)/(2*(1-lambda^2)))*(x^2-2*lambda*x*y+y^2)),
  xmin = -0.5,xmax = 0.5, ymin = -0.5, ymax = 0.5)$Q))
} 

optimize(fun_obj, interval=c(-1,1),maximum=TRUE)$maximum
```

We can see that our approach seems to have performed reasonably well
here. There is a small improvement in the estimate over using all the
SNPs while there is a considerable improvement compared to the instance
in which we selected SNPs and used the original non-conditional
expression.

#### Simulations

However, the above is only one example and thus, in order to test our
estimation approach properly, we will perform a brief simulation study.
The following code was run:

```{r, eval=FALSE}
library(parallel)
## Total number of simulations:
tot_sim <- 10
## Set of parameters:
sim_params <- expand.grid(
  sim = c(1:tot_sim),
  h2 = c(0.2,0.4,0.6),
  prop_effect = c(0.01,0.05,0.1),
  cor_xy = c(-0.1,0.1,0.3,0.5)
)

set.seed(1998)
run_sim <- function(h2,prop_effect,cor_xy,sim){
  data_full <- sim_mr_stats(n_snps=10^6, prop_effect, h2, frac_overlap=1, n_x=50000, n_y=50000, cor_xy, beta_xy=0.3)
  n <- nrow(data_full)
  B <- sum((data_full$beta.exposure/data_full$se.exposure)*(data_full$beta.outcome/data_full$se.outcome))
  A <- sum((data_full$beta.exposure/data_full$se.exposure)^2) 
  C <- sum((data_full$beta.outcome/data_full$se.outcome)^2)
  ## optimise log-likelihood
  f <-function(x){-(n/2)*(log(1-x^2)) - ((1)/(2*(1-x^2)))*(A-2*x*B+C)}
  est_cor_full <- optimize(f,interval=c(-1,1),maximum=TRUE)$maximum
  
  data <- data_full[abs(data_full$beta.exposure/data_full$se.exposure) < 0.5 & abs(data_full$beta.outcome/data_full$se.outcome) < 0.5,]
  n <- nrow(data)
  B <- sum((data$beta.exposure/data$se.exposure)*(data$beta.outcome/data$se.outcome))
  A <- sum((data$beta.exposure/data$se.exposure)^2)
  C <- sum((data$beta.outcome/data$se.outcome)^2)
  ## optimise conditional log-likelihood
  fun_obj <- function(lambda){
    - ((1)/(2*(1-lambda^2)))*(A-2*lambda*B+C) - n*log((pracma::integral2(function(x,y)
      exp((-(1)/(2*(1-lambda^2)))*(x^2-2*lambda*x*y+y^2)),
      xmin = -0.5,xmax = 0.5, ymin = -0.5, ymax = 0.5)$Q))
  }
  est_cor <- optimize(fun_obj, interval=c(-1,1),maximum=TRUE)$maximum
  
  results <- list(params = c(h2,prop_effect,cor_xy), est_cor=c(est_cor,est_cor_full), data = data_full)
  return(results)
}

res <- mclapply(1:nrow(sim_params), function(i){
  do.call(run_sim, args=as.list(sim_params[i,]))}, mc.cores=1)
```

```{r,include=FALSE}
res <- read.csv("cor_deriv_sims.csv")

res$sim_cor <- c(rep(c(1:90),4))
res_new <- rbind(res,res)
res_new$true_cor <- res_new$actual_cor
res_new$est_cor <- c(res$est_cor,res$est_cor_full)
res_new$fun <- c(rep("CL",360),rep("L",360))
res <- res_new
```

The number of SNPs is fixed at 1,000,000 and the sample size is fixed at
50,000 with full sample overlap. The causal effect of the exposure on
the outcome remains at **0.3** for each simulation. The heritability
takes values $h^2 \in \{0.2,0.4,0.6\}$, the proportion of effect SNPs
takes values $\pi \in \{0.01,0.05,0.1\}$ and the true correlation
between the exposure and outcome is varied as follows:
$\text{cor}_{XY} \in \{-0.1,0.1,0.3,0.5\}$. This factorial design study
is repeated **10** times. In this small set of simulations, we consider
two options for estimating the correlation:

i)  `fun: L`: optimizing the *log-likelihood* function with the full set
    of SNPs

ii) `fun: CL`: optimizing the *conditional log-likelihood* function with
    a selected subset of SNPs in which both absolute $z$-scores of every
    SNP in the subset are less than 0.5

The above results are organised in a dataframe and we attempt to
illustrate as follows:

```{r, fig.width=10}
library("RColorBrewer")
col <- brewer.pal(8,"GnBu")
ggplot(res, aes(x=sim_cor, y=est_cor,color=as.factor(h2),shape=as.factor(prop_effect))) + geom_point(size=2) + facet_grid(fun~true_cor, labeller="label_both")+ ylab("Estimated Correlation") + xlab("Simulation") + scale_color_manual(values=c(col[4],col[6],col[8])) +
  geom_hline(aes(yintercept = true_cor), linetype=1, size=0.5) + 
  guides(color = guide_legend(title = "Heritability"), shape= guide_legend(title = "Polygenicity")) 
```

[$\star$]{style="color: blue;"} **Note:** In the above grid, `true_cor`
represents the true correlation value. Furthermore, the bottom half of
the grid, `fun: L`, depicts the estimates obtained by optimizing the
*log-likelihood* function with the full set of SNPs while the top half,
`fun: CL`, depicts the estimated values computed by optimizing the
*conditional log-likelihood* function with a selected subset of SNPs in
which both absolute $z$-scores of every SNP in the subset are less than
0.5.

In addition to this illustration, we also compute the average estimated
correlation, `mean` as well as the root mean square error, `rmse`, for
each true correlation value.

```{r,include=FALSE}
res <-res_new[1:360,]
```

```{r}
rmse.L <- function(cor){sqrt(sum((res[res$true_cor==cor,]$est_cor_full - res[res$true_cor==cor,]$true_cor)^2)/nrow(res[res$true_cor==cor,]))}
rmse.CL <- function(cor){sqrt(sum((res[res$true_cor==cor,]$est_cor - res[res$true_cor==cor,]$true_cor)^2)/nrow(res[res$true_cor==cor,]))}
mean.L <- function(cor){sum(res[res$true_cor==cor,]$est_cor_full)/nrow(res[res$true_cor==cor,])}
mean.CL <- function(cor){sum(res[res$true_cor==cor,]$est_cor)/nrow(res[res$true_cor==cor,])}
rmse <- data.frame(true_cor = c(-0.1,0.1,0.3,0.5),
                   mean.L = c(mean.L(-0.1),mean.L(0.1),mean.L(0.3),mean.L(0.5)),
                   mean.CL = c(mean.CL(-0.1),mean.CL(0.1),mean.CL(0.3),mean.CL(0.5)),
                   rmse.L = c(rmse.L(-0.1),rmse.L(0.1),rmse.L(0.3),rmse.L(0.5)),
                   rmse.CL = c(rmse.CL(-0.1),rmse.CL(0.1),rmse.CL(0.3),rmse.CL(0.5)))
rmse
```

The above results give us an indication that both methods seem to be
largely *unbiased* as the averages for each are very close to the
corresponding true correlation values. However, the much larger `rmse`
values for the second approach suggest that it has a much greater
variance. This large variance is also evident in the above plot.

The above simulation study is repeated with the exact same parameters but with the **sample size increased to 1,000,000**. The results can be illustrated as follows.


```{r,include=FALSE}
res <- read.csv("cor_deriv_sims_2.csv")

res$sim_cor <- c(rep(c(1:90),4))
res_new <- rbind(res,res)
res_new$true_cor <- res_new$actual_cor
res_new$est_cor <- c(res$est_cor,res$est_cor_full)
res_new$fun <- c(rep("CL",360),rep("L",360))
res <- res_new
```

```{r, fig.width=10}
library("RColorBrewer")
col <- brewer.pal(8,"GnBu")
ggplot(res, aes(x=sim_cor, y=est_cor,color=as.factor(h2),shape=as.factor(prop_effect))) + geom_point(size=2) + facet_grid(fun~true_cor, labeller="label_both")+ ylab("Estimated Correlation") + xlab("Simulation") + scale_color_manual(values=c(col[4],col[6],col[8])) +
  geom_hline(aes(yintercept = true_cor), linetype=1, size=0.5) + 
  guides(color = guide_legend(title = "Heritability"), shape= guide_legend(title = "Polygenicity")) 
```
```{r,include=FALSE}
res <-res_new[1:360,]
```


In addition, we compute the average estimated correlation as well as the root mean square error for each true correlation value. 

```{r}
rmse.L <- function(cor){sqrt(sum((res[res$true_cor==cor,]$est_cor_full - res[res$true_cor==cor,]$true_cor)^2)/nrow(res[res$true_cor==cor,]))}
rmse.CL <- function(cor){sqrt(sum((res[res$true_cor==cor,]$est_cor - res[res$true_cor==cor,]$true_cor)^2)/nrow(res[res$true_cor==cor,]))}
mean.L <- function(cor){sum(res[res$true_cor==cor,]$est_cor_full)/nrow(res[res$true_cor==cor,])}
mean.CL <- function(cor){sum(res[res$true_cor==cor,]$est_cor)/nrow(res[res$true_cor==cor,])}
rmse <- data.frame(true_cor = c(-0.1,0.1,0.3,0.5),
                   mean.L = c(mean.L(-0.1),mean.L(0.1),mean.L(0.3),mean.L(0.5)),
                   mean.CL = c(mean.CL(-0.1),mean.CL(0.1),mean.CL(0.3),mean.CL(0.5)),
                   rmse.L = c(rmse.L(-0.1),rmse.L(0.1),rmse.L(0.3),rmse.L(0.5)),
                   rmse.CL = c(rmse.CL(-0.1),rmse.CL(0.1),rmse.CL(0.3),rmse.CL(0.5)))
rmse
```

[$\star$]{style="color: blue;"} **Note:** These new set of results in which we have increased the sample size show us that the *log-likelihood* approach is clearly ***biased*** while the *conditional log-likelihood* remains ***unbiased*** with a high degree of variance.


[$\star$]{style="color: blue;"} **Conclusions?**


<br>

#### Real Data

We also decided to test our approach for estimating the correlation, or
$\lambda$, on real data. The steps followed are provided in detail
below. As it is estimating $\lambda$ that is of interest here, rather
than estimating the causal effect, we simply considered two quantitative
traits, BMI and height. We first randomly obtained a subset of 100,000
individuals which were common to both BMI and height UKBB datasets. This
provided us with fully overlapping datasets, which means that
$\hat \lambda = \hat \rho_{XY}$, in which $\rho_{XY}$ is the correlation
between the exposure and the outcome. Therefore, the individual level
data for these 100,000 individuals allow us to obtain $\hat\rho_{XY}$.
Then, by carrying out GWASs for both datasets and obtaining summary
statistics, we can use these summary statistics to obtain $\hat \lambda$
and test our approach. We note that we must use our approach on
independent SNPs and therefore, we will also consider pruning our full
set of SNPs to obtain a smaller set of approximately independent SNPs.
It is then the summary statistics of this smaller set of SNPs that will
be used to estimate $\lambda$.

[$\star$]{style="color: blue;"} **Note:** We had considered clumping the
SNPs as opposed to pruning, as it is clumping that seems to be more
often used in MR practices. However, clumping functionality is not
available on PLINK 2.0 and thus, pruning was deemed the quicker easier
choice.

**Step 1: Obtain fully overlapping sample data set**

*Code:*
`Rscript sample_HB.R height4plink.txt bmi4plink.txt height_cor.txt bmi_cor.txt cor_HB.txt`

-   *Inputs:* height4plink.txt, bmi4plink.txt
-   *Outputs:* height_cor.txt, bmi_cor.txt, cor_HB.txt

***R scripts:***

-   [**sample_HB.R**](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/R/sample_HB.R)
    reads in both height4plink.txt and bmi4plink.txt. It first removes
    any individuals which do not have available information for both
    traits and then, obtains a set of individuals which are common to
    both datasets. From this set, using `set.seed(1998)`, a random set
    of 100,000 individuals are chosen. The outputted data sets,
    height_cor.txt and bmi_cor.txt contain height and BMI information,
    respectively, of the same 100,000 individuals, ordered by ID number.
    Using the function `cor()`, the correlation between height and BMI
    for these individuals is obtained and can be found in cor_HB.txt.

[$\star$]{style="color: blue;"} **Note:** The estimate for $\rho_{XY}$,
which was obtained using the sample of 100,000 UKBB individuals, was
found to be **-0.0168766255879653**.

**Step 2: Performing two GWASs**

*Code:* `sbatch parallel_height_cor.sh` `sbatch parallel_bmi_cor.sh`

-   *Inputs:* height_cor.txt, bmi_cor.txt, height_cor.sh, bmi_cor.sh,
    height_cor.txt, bmi_cor.txt, \*\_qcd.pgen, \*\_qcd.psam,
    \*\_qcd.pvar
-   *Outputs:* height_res\_\*.PHENO1.glm.linear,
    bmi_res\_\*.PHENO1.glm.linear for each chromosome

***Shell scripts:***

-   [height_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/height_cor.sh)
    and
    [bmi_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/bmi_cor.sh)
    first combine the genotype information, \*\_qcd.pgen, \*\_qcd.psam,
    \*\_qcd.pvar, with the height/BMI data sets,
    height_cor.txt/bmi_cor.txt, to make \*\_qcd_height.bed,
    \*\_qcd_height.bim, \*\_qcd_height.fam and \*\_qcd_bmi.bed,
    \*qcd_bmi.bim, \*qcd_bmi.fam files for the specified chromosome.
    They then use these files and perform an association analysis with
    the results outputted in height_res\*.PHENO1.glm.linear and
    bmi_res\*.PHENO1.glm.linear for the chromsome.

-   [parallel_height_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/parallel_height_cor_prune.sh)
    and
    [parallel_bmi_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/parallel_bmi_cor_prune.sh)
    run height_cor.sh and bmi_cor.sh, respectively, on each chromosome
    from 1 to 22 in parallel.

**Step 3: Combining results**

*Code:* `sbatch summary_stats_height_cor.sh`
`sbatch summary_stats_bmi_cor.sh`

-   *Inputs:* summary_stats_height_cor.R, summary_stats_bmi_cor.R,
    height_res\_\*.PHENO1.glm.linear, bmi_res\_\*.PHENO1.glm.linear for
    each chromosome
-   *Outputs:* summary_stats_height_cor.txt, summary_stats_bmi_cor.txt

***R scripts:***

-   [summary_stats_height_cor.R](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/R/summary_stats_height_cor.R)
    and
    [summary_stats_bmi_cor.R](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/R/summary_stats_bmi_cor.R)
    combine together the summary statistics obtained from performing an
    association analysis on each chromosome, with respect to height/BMI,
    and output data sets with 5 columns: chromosome, position, rsID,
    estimated effect size, standard error of estimated effect size.

***Shell scripts:***

-   [summary_stats_height_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/summary_stats_height_cor.sh)
    and
    [summary_stats_bmi_cor.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/summary_stats_bmi_cor.sh)
    run the R scripts summary_stats_height_cor.R and
    summary_stats_bmi_cor.R, inputting height_res\_\*.PHENO1.glm.linear
    and bmi_res\_\*.PHENO1.glm.linear of each chromsome and outputting
    summary_stats_height_cor.txt and summary_stats_bmi_cor.txt.

**Step 4: Obtaining pruned set of SNPs**

*Code:* `sbatch parallel_bmi_cor_prune.sh`
`sbatch parallel_height_cor_prune.sh` `sbatch join_pruned_bmi.sh`
`sbatch join_pruned_height.sh` `sbatch summary_stats_prune.sh`

-   *Inputs:* bmi_cor_prune.sh, height_cor_prune.sh, bmi_cor.txt,
    height_cor.txt, \*\_qcd.pgen, \*\_qcd.psam, \*\_qcd.pvar,
    prune_join.R, summary_stats_prune.R, summary_stats_height_cor.txt,
    summary_stats_bmi_cor.txt
-   *Outputs:* summary_stats_height_prune.txt,
    summary_stats_bmi_prune.txt

***R scripts:***

-   [prune_join.R](https://github.com/amandaforde/winnerscurse_MR/tree/main/real_data_scripts/R/prune_join.R)
    combines the lists of pruned SNPs together from the 22 chromosomes
    to form a single list.

-   [summary_stats_prune.R](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/R/summary_stats_prune.R)
    reads in the list of pruned SNPs and a data set of summary
    statistics, i.e. summary_stats_height_cor.txt or
    summary_stats_bmi_cor.txt. It then creates a subset of this summary
    statistics data set which contains summary statistics of only those
    SNPs contained in the list of pruned SNPs.

***Shell scripts:***

-   [bmi_cor_prune.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/bmi_cor_prune.sh)
    and
    [height_cor_prune.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/height_cor_prune.sh)
    first combine the genotype information, \*\_qcd.pgen, \*\_qcd.psam,
    \*\_qcd.pvar, with the BMI/height data set,
    bmi_cor.txt/height_cor.txt, to make \*\_qcd_bmi.bed,
    \*\_qcd_bmi.bim, \*\_qcd_bmi.fam and \*\_qcd_height.bed,
    \*qcd_height.bim, \*qcd_height.fam files for the specified
    chromosome. They then use these files and employ the command
    `--indep-pairwise 50 5 0.5` for pruning. This means that pruning
    occurs by first calculating LD between each pair of SNPs in a window
    of 50 SNPs. If an LD value greater than 0.5 is observed, then one
    SNP out of this pair is removed. The window is shifted 5 SNPs
    forward and the process is repeated. A set of pruned SNPs are
    outputted and contained in the files bmi_prune\*.prune.in and
    height_prune\*.prune.in for each chromosome.

-   [parallel_bmi_cor_prune.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/parallel_bmi_cor_prune.sh)
    and
    [parallel_height_cor_prune.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/parallel_height_cor_prune.sh)
    run bmi_cor_prune.sh and height_cor_prune.sh, respectively, on each
    chromosome from 1 to 22 in parallel.

-   [join_pruned_bmi.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/join_pruned_bmi.sh)
    and
    [join_pruned_height.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/join_pruned_height.sh)
    run the R script prune_join.R, inputting bmi_prune\_\*.prune.in and
    height_prune\_\*.prune.in of each chromosome and outputting
    pruned_SNPS_bmi.txt and pruned_SNPS_height.txt, which both contain a
    list of 1,590,043 SNPs.

-   [summary_stats_prune.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/summary_stats_prune.sh)
    runs the R script summary_stats_prune.R twice, first inputting
    pruned_SNPs_bmi.txt and summary_stats_bmi_cor.txt and outputting
    summary_stats_bmi_prune.txt. The second time, pruned_SNPs_height.txt
    and summary_stats_height_cor.txt are inputted, and
    summary_stats_height_prune.txt is outputted.

**Step 5: Estimating correlation**

*Code:* `sbatch cor_check.sh`

-   *Inputs:* cor_check.R, summary_stats_bmi_prune.txt,
    summary_stats_height_prune.txt
-   *Outputs:* est_cor.txt

***R scripts:***

-   [**cor_check.R**](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/shell/cor_check.R) first reads in the summary statistics for the pruned set of SNPs for both height and BMI, summary_stats_height_prune.txt and summary_stats_bmi_prune.txt. It then ensures that any rows with missing information for the estimated effect size are removed from each data set and that both data sets contain summary statistics for the exact same SNPs. Following this, our first approach for estimating the correlation, or $\lambda$, using summary statistics is considered. The entire set of SNPs is used and the *log-likelihood* function is optimized to obtain an estimate. Second, a subset of SNPs is obtained which all have absolute $z$-scores for both height and BMI less than 0.5. The *conditional log-likelihood* function is then optimized to obtain a second estimate. The two estimates are outputted in est_cor.txt.

***Shell scripts:***

-   [cor_check.sh](https://github.com/amandaforde/winnerscurse_MR/blob/main/real_data_scripts/R/cor_check.sh)
    runs the R script cor_check.R, inputting summary_stats_bmi_prune.txt
    and summary_stats_height_prune.txt and outputting est_cor.txt.

[$\star$]{style="color: blue;"} **Note:** The estimate for $\lambda$
obtained using the first version of our approach, in which the
*log-likelihood* function is optimized using the full set of SNPs, was
**-0.086906563122001**, while the estimate obtained by optimizing the
*conditional log-likelihood* function with a selected subset of SNPs, in
which both absolute $z$-scores of every SNP in the subset are less than
0.5, was **-0.093659068071487**.


**Step 5a: Estimating correlation with unpruned SNPs**

*Code:* `sbatch cor_check.sh`

-   *Inputs:* cor_check.R, summary_stats_bmi_cor.txt,
    summary_stats_height_cor.txt
-   *Outputs:* est_cor_full.txt

Here, we use the same R script as above but now apply it to our original unpruned sets of summary statistics.

[$\star$]{style="color: blue;"} **Note:** The estimate for $\lambda$
obtained using the first version of our approach, in which the
*log-likelihood* function is optimized using the full set of SNPs, was
**-0.0861423439755467**, while the estimate obtained by optimizing the
*conditional log-likelihood* function with a selected subset of SNPs, in
which both absolute $z$-scores of every SNP in the subset are less than
0.5, was [**-0.0352981656737371**]{style="color: darkred;"}.

Even though the SNPs used here are no longer independent, we can see that we have potentially stabilised the *conditional log-likelihood* estimate further as it has moved closer to the expected value while the *log-likelihood* remains at a similar value as before.


**Step 5b: Estimating correlation with increased $z$-statistic threshold**

*Code:* `sbatch cor_check.sh`

-   *Inputs:* cor_check.R, summary_stats_bmi_prune.txt,
    summary_stats_height_prune.txt
-   *Outputs:* est_cor_1_prune.txt

Here, we use the same R script as above applied to the pruned set of SNPs, but in which the subset of SNPs used by the *conditional log-likelihood* function all have absolute $z$-scores for both height and BMI less than **1**.

[$\star$]{style="color: blue;"} **Note:** The estimate for $\lambda$
obtained using the first version of our approach, in which the
*log-likelihood* function is optimized using the full set of SNPs, was
**-0.0869065653122001**, while the estimate obtained by optimizing the
*conditional log-likelihood* function with a selected subset of SNPs, in
which both absolute $z$-scores of every SNP in the subset are less than
1, was **-0.0836582509286098**.

*Code:* `sbatch cor_check.sh`

-   *Inputs:* cor_check.R, summary_stats_bmi_cor.txt,
    summary_stats_height_cor.txt
-   *Outputs:* est_cor_1_unprune.txt

Again, we use the same R script as above applied to the original unpruned set of SNPs, but in which the subset of SNPs used by the *conditional log-likelihood* function all have absolute $z$-scores for both height and BMI less than **1**.

[$\star$]{style="color: blue;"} **Note:** The estimate for $\lambda$
obtained using the first version of our approach, in which the
*log-likelihood* function is optimized using the full set of SNPs, was
**-0.0861423439755467**, while the estimate obtained by optimizing the
*conditional log-likelihood* function with a selected subset of SNPs, in
which both absolute $z$-scores of every SNP in the subset are less than
1, was **-0.077674560083575**.


[$\star$]{style="color: blue;"} **Conclusions?**

<br>


### Reducing SNP numbers 

It is mentioned in our section regarding estimating the causal effect that our proposed method involves repeatedly simulating values for $\hat\beta_{X_{\pi}}$ and $\hat\beta_{Y_{\pi}}$ and then selecting SNPs using $\hat\beta_{X_{\pi}}$. In order to reduce the standard error of our causal effect estimate, this repeated simulation of $\hat\beta_{X_{\pi}}$ and $\hat\beta_{Y_{\pi}}$ values occurs several times, ideally at the very minimum $N_{\text{iter}} = 100$ times. Naturally, with a large data set of SNPs, this repeated simulation process is very **computationally intensive**. Of course, there are many SNPs that will never be selected across the $N_{\text{iter}}$ iterations. 

Thus, in order to improve the computational intensity of our approach, we propose that a **subset of SNPs** should be first obtained from the large data set of SNPs and it is just then the SNPs in this subset that will be used in our method. We suggest that selection of a SNP into this subset will be based on its probability to be selected on a given iteration, i.e. the probability that the simulated value $\left| \hat{z}_{X_{\pi}} \right| = \left| \frac{\hat\beta_{X_{\pi}}}{\widehat{\text{se}(\hat\beta_{X_{\pi}})}} \right|$ is less than `qnorm((5e-8)/2, lower.tail=FALSE)` $\approx 5.45$, in which we have chosen that selection at each iteration is based on the $p$-value threshold of $5 \times 10^{-8}$. Therefore, we must now derive an expression for the probability of a SNP to be selected on a given iteration. 

Firstly, let us note that from our work detailed above, we know that $\sqrt{\text{var}\left( \hat\beta_{X_\pi}\right)} \sim \sqrt{\frac{1}{\pi}\cdot \text{var}\left( \hat\beta_{X}\right)}$ which allows us to approximate $\widehat{\text{se}\left( \hat\beta_{X_\pi}\right)} \sim \sqrt{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2}$. We can then define $\hat{z}_{X_{\pi}}$ as $\hat{z}_{X_{\pi}}=\frac{\hat\beta_{X_{\pi}}}{\sqrt{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2}}$.

Now, from above, we also have the following $E(\hat\beta_{X_\pi} | \hat\beta_{X}) = \hat\beta_{X}$ and $\text{var}\left( \hat\beta_{X_\pi} | \hat\beta_{X} \right) \sim \frac{1-\pi}{\pi}\cdot \text{var}\left( \hat\beta_{X}\right)$ which gives $\left(\text{se}\left( \hat\beta_{X_\pi} | \hat\beta_{X}\right)\right)^2 \sim \frac{1-\pi}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2$. Therefore, we can write the following: 

$$\left( \hat\beta_{X_\pi} | \hat\beta_{X} \right) \sim N \left( \hat\beta_X, \left(\frac{1-\pi}{\pi}\right)\cdot(\text{se}(\hat\beta_{X}))^2 \right)$$


We are in fact interested in the distribution of $\hat{z}_{X_{\pi}}$. However, as this is simply equal to $\hat\beta_{X_\pi}$ multiplied by the scalar $\frac{1}{\sqrt{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2}}$, we can use the distribution above to form the following:

$$\left( \frac{\hat\beta_{X_\pi}}{\sqrt{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2}} \middle| \hat\beta_{X} \right) = \left( \hat{z}_{X_{\pi}} | \hat\beta_{X} \right) \sim N \left( \frac{\hat\beta_X}{\sqrt{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2}}, \frac{\left(\frac{1-\pi}{\pi}\right)\cdot(\text{se}(\hat\beta_{X}))^2}{\frac{1}{\pi}\cdot \left(\text{se}\left( \hat\beta_{X}\right)\right)^2} \right)$$

Tidying the above up and defining $\hat{z}_{X} = \frac{\hat\beta_{X}}{\sqrt{\left(\frac{1}{\pi}\right)\cdot(\text{se}(\hat\beta_{X}))^2}}$, we get:

$$\left( \hat{z}_{X_{\pi}} | \hat\beta_{X} \right) \sim N \left( \hat{z}_{X}, 1-\pi \right)$$

Therefore, using this result, the probability of a SNP to be selected on a given iteration, $f(\left| \hat{z}_{X_{\pi}} \right| > 5.45)$ can be easily derived as follows, in which $\Phi$ is the cumulative distribution function of a standard normal: 

$$f(\left| \hat{z}_{X_{\pi}} \right| > 5.45 ) = \Phi\left(\frac{- 5.45 + \hat{z}_{X}}{\sqrt{1-\pi}}\right) + \Phi\left(\frac{- 5.45 - \hat{z}_{X}}{\sqrt{1-\pi}}\right)$$

[$\star$]{style="color: blue;"} **Note:** Recall that the value of $\hat{z}_X$ is known for each SNP. Thus, $f(\left| \hat{z}_{X_{\pi}} \right| > 5.45)$ can be quickly worked out for each SNP using the above. 

Now that we have shown that we can easily work out the probability of each SNP to be selected on a given iteration, the question of interest turns to how might we use these probabilities to choose which SNPs to contain in the subset of SNPs that will be used in our method. We first considered that perhaps we could simply choose those SNPs in which this probability is greater than a chosen value. For example, choosing this value to be 0.01, SNPs which have $f(\left| \hat{z}_{X_{\pi}} \right| > 5.45) \ge 0.01$, would then be selected into the subset and used in our method. However, this approach could prove to be potentially problematic if we were presented with a data set which, for some reason, had thousands of SNPs with a probability of selection just below 1%. In the case where we use the entire set of SNPs in our method, many of these SNPs would actually turn out to be instruments while in this restricted version concerning only a subset of SNPs, these SNPs would all be excluded. 

Given the above, we consider a different approach in which we lower bound the probability that the restricted version and the full version will result in the same instruments, i.e. the same SNPs being selected. Upon working out $f(\left| \hat{z}_{X_{\pi}} \right| > 5.45)$ for each SNP, we then order all SNPs by these probabilities from smallest to largest. Following this ordering, we obtain the cumulative sum of these probabilities. Note that in this case, the largest cumulative sum is then equivalent to the expected number of instruments when the full set of SNPs is used in our method. We could then choose all SNPs for which the **cumulative probability is greater than 0.05** for our subset. This process should ensure that for a single iteration of our method, the number of instruments if the full set of SNPs is used and the number of instruments if merely the subset is used will be equal with probability at least 95%. The point where we subset the SNPs, i.e. 0.05 here, can also be interpreted as the expected difference in the number of instruments if the full set of SNPs is used and the number of instruments if the subset is used. Thus, this cumulative probability approach gives an extra probabilistic guarantee that the results obtained using the full set of SNPs and those obtained using the subset will be very similar in terms of the number of, and actual, instruments included.


[$\star$]{style="color: blue;"} **Example:** For example, if our data set of interest originally had 100,000 SNPs such as the example data set, `data`, below, applying our proposed method would result in simulating values for $\hat\beta_{X_\pi}$ and  $\hat\beta_{Y_\pi}$ for all of those SNPs a total of $N_{\text{iter}}$ times. Assuming that $\pi =0.5$ and the $p$-value threshold for selection is $5 \times 10^{-8}$, we could obtain the probability of selection for each SNP using our derivation above, namely `p.exposure1`. Following, this we can easily compute the cumulative sums by first ordering the SNPs and then using the function `cumsum`. Finally, all SNPs for which this cumulative sum is less than 0.05 are removed. It can be seen below that we are left 436 SNPs, which is clearly a great reduction in SNP numbers compared to the original 100,000. This means that computation time would be greatly reduced, allowing us to then increase the value of $N_{\text{iter}}$.


```{r}
## Simulate entire data set:
set.seed(1998)
data <- sim_mr_stats(n_snps=10^5,prop_effect=0.01,h2=0.4,frac_overlap=1,n_x=100000,n_y=100000,cor_xy=0.6,beta_xy=0.3) 

## Obtain probabilities of selection:
pi <- 0.5
thresh1 <- stats::qnorm((5e-8)/2, lower.tail=FALSE)
data$mu.exposure1 <- data$beta.exposure/sqrt(((1)/(pi))*(data$se.exposure)^2)
data$p.exposure1 <- pnorm((-thresh1 + data$mu.exposure1)/(sqrt(1-pi))) + pnorm((-thresh1 - data$mu.exposure1)/(sqrt(1-pi)))

## Obtain cumulative sum of probabilities:
data1 <- data[order(data$p.exposure1,decreasing=FALSE),]
data1$cumul.sum <- cumsum(data1$p.exposure1)

## Remove SNPs with cumulative sum less than 0.05:
data1 <- data1[-which(data1$cumul.sum < 0.05),]
nrow(data1) 
```


<br><br>

## Using `mr.simss`

We have created an R package, `mr.simss`, which allows us to implement the approach that we have proposed in this document. `mr.simss` can be installed as follows: 

```{r}
remotes::install_github("amandaforde/mr.simss")
library(mr.simss)
```


We can now briefly demonstrate how the functions in this package may be used in order to obtain MR causal effect estimates using GWAS summary statistics. Firstly, we will consider a fully overlapping toy data set in which the causal effect of the exposure on the outcome is **0.3**. We use the function created above, `sim_mr_stats` to do so and view the first six rows of our simulated data set.

```{r}
set.seed(1998)
data <- sim_mr_stats(n_snps=10^5,prop_effect=0.01,h2=0.4,frac_overlap=1,n_x=100000,n_y=100000,cor_xy=0.6,beta_xy=0.3) 
head(data)
```


Before we implement our method from `mr.simss`, we consider first using the `mr` function from the `TwoSampleMR` R package which applies the following well-known method, IVW, and obtains the MR causal effect estimate: 

```{r}
data_mr <- tibble::tibble(
      SNP = data$SNP,
      id.exposure="X",
      id.outcome="Y",
      exposure="X",
      outcome="Y",
      beta.exposure = data$beta.exposure,
      beta.outcome = data$beta.outcome,
      se.exposure = data$se.exposure,
      se.outcome = data$se.outcome,
      mr_keep=TRUE
    )

data_sig <- data_mr %>% dplyr::filter(2*(stats::pnorm(abs(data_mr$beta.exposure/data_mr$se.exposure), lower.tail=FALSE)) < 5e-8)
TwoSampleMR::mr(data_sig,method_list=c("mr_ivw"))[,5:9]
```

We also consider applying the MR-RAPS method to this data set as follows:

```{r}
library(mr.raps)
results <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
data.frame(method="mr_raps", nsnp=nrow(data_sig), b=results$beta.hat, se=results$beta.se, pval=results$beta.p.value)
```

<br>

The **main function** in the package is `mr_simss` which executes the method, **MR-SimSS**. We can apply `mr_simss` directly to our simulated data set, assuming that we have knowledge of the number of samples in both outcome and exposure GWASs, the number of overlapping samples between the two GWASs, and the correlation between the exposure and the outcome. As the default setting of the parameter `n.iter`, `n.iter=1000` can be quite computationally intensive, we will use `n.iter=100` for demonstration purposes. Also, note that as we are aware that we are dealing with fully overlapping samples, it is advisable to use the 3 split approach. Therefore, we set `splits=3`.

```{r}
mr.simss::mr_simss(data,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=100,splits=3,parallel=TRUE)$summary
```


As mentioned above, for large values of `n.iter`, applying our proposed approach to the entire data set can be quite computationally intensive. We have discussed this in the section *"Reducing SNP numbers"* and described a way in which we could obtain a subset of SNPs and simply apply our method to just the SNPs in that subset, resulting in a great reduction in computational time. Changing the parameter `subset` in the `mr_simss` function from its default setting `subset=FALSE` to `subset=TRUE` allows us to use the **MR-SimSS** method with a smaller subset of SNPs. Note that the value for `sub.cut` determines a cut-off point for inclusion of SNPs into the subset based on cumulative probabilities. The default value is `sub.cut=0.05`. Further details regarding the manner in which SNPs are selected into the subset are provided in the section above. Due to the reduction in computational time by using `subset=TRUE`, this then allows us to increase `n.iter`.

```{r}
mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=1000,splits=3,parallel=TRUE)$summary
```

Now, let us explicitly examine how much we save in computational time by using the subset approach for this example. We also note that our full data set here has only 100,000 SNPs. It is quite likely that a real data set would have more than this, meaning much greater computational time for only $N_{\text{iter}} = 100$ iterations of the method. Firstly, using the full data set of 100,000 SNPs with our method and carrying out 100 iterations takes under 3 minutes.

```{r}
start.time <- Sys.time()
full <- mr.simss::mr_simss(data,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=100,splits=3,parallel=TRUE)
end.time <- Sys.time()
round(end.time - start.time,2)
```

Following this, we can see that using the subset approach for 1000 iterations takes only 19.11 seconds, which is a reduction in computational time of approximately 88%, while the number of iterations have been increased 10-fold.  

```{r}
start.time <- Sys.time()
sub <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=1000,splits=3,parallel=TRUE)
end.time <- Sys.time()
round(end.time - start.time,2)
```


In addition, we could have used the function `est_lambda` to first estimate *lambda* and then use this value with `mr_simss`. We demonstrate this as follows:

```{r}
lambda <- est_lambda(data)
mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=lambda,n.iter=1000,splits=3,parallel=TRUE)$summary
```


Note that in all our examples so far we have used the default MR method, IVW, with our approach. We now have a look at using MR-RAPS with our approach. MR-RAPS has the additional benefit that it also assists in eliminating weak instrument bias. 

```{r}
mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=lambda,n.iter=1000,splits=3,mr_method="mr_raps",parallel=TRUE)$summary
```

Now we will examine how long it takes use the full data set of 100,000 SNPs with our method and apply MR-RAPS. It can be seen below that it takes a similar amount of time as using the IVW method. 

```{r}
start.time <- Sys.time()
full <- mr.simss::mr_simss(data,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=100,splits=3,mr_method="mr_raps",parallel=TRUE)
end.time <- Sys.time()
round(end.time - start.time,2)
```

We can also see that using the subset approach for 1000 iterations using MR-RAPS also sees a great reduction in computational time.  

```{r}
start.time <- Sys.time()
sub <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=100000,n.outcome=100000,n.overlap=100000,cor.xy=0.6,n.iter=1000,splits=3,mr_method="mr_raps",parallel=TRUE)
end.time <- Sys.time()
round(end.time - start.time,2)
```


As our method works in combination with other MR methods, as shown here with IVW and MR-RAPS, it is also possible to use `mr_simss` with other pleiotropy robust approaches, such as weighted median and weighted mode. We demonstrate this below. However, in this instance, these two methods do not seem to perform as well MR-RAPS and IVW. 

```{r}
mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=lambda,n.iter=100,splits=3,mr_method="mr_weighted_median",parallel=TRUE)$summary
```

```{r}
mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=lambda,n.iter=100,splits=3,mr_method="mr_weighted_mode",parallel=TRUE)$summary
```

<br>

[$\star$]{style="color: blue;"} **Note:** Naturally, it is difficult to see if our approach,  **MR-SimSS**, is in fact performing well and obtaining *bias-reduced* causal effect estimates by illustrating its implementation with just one simulated data set. Therefore, the next step is thus to consider performing a **simulation study** which would incorporate simulating many different data sets and comparing our approach with other currently published methods. 


<br><br>

## Simulation study design

When designing our simulation study, there are several things to consider and keep in mind:

i) Firstly, we must decide on what **other methods** should we include in our study and thus, compare our proposed method against. 

ii) We must consider what **simulation parameters** should we adjust, e.g. sample size, fraction of overlap, true causal effect, heritability and polygenicity of exposure, correlation between exposure and outcome, and the total number of SNPs, and what values they should take.

iii) In addition, the current way in which we are creating our simulated data sets does not take into account any balanced or directional **pleiotropy**, a characteristic that is regularly seen in real data scenarios. 

[$\star$]{style="color: blue;"} **Note:** Above, we have discussed several variations of our method. Thus, when designing our simulation study, this gives rise to the following key considerations:

- [**Question:**]{style="color: Purple;"} *Should we use the full data set of SNPs with our method or obtain a* ***subset***, *as described above, and use only that smaller set of SNPs with the method? If we choose the subset approach, is the value of 0.05 most appropriate for `sub.cut`?* 

   - [**Discussion:**]{style="color: Purple;"} The benefit of using the smaller set of SNPs is that it will *significantly* reduce computation time and thus, allow us to increase the number of iterations, `n.iter`, to 1000, which has been seen, in brief experimentation, to produce a more stable estimate than `n.iter=100`. Furthermore, it is anticipated that an approach with a much smaller computational time would be of more interest to researchers. From above, 0.05 seems appropriate for `sub.cut` and further reduction of this value to 0.01, say, does not seem necessary, especially given that this value is equal to the expected difference in the number of instruments if the full set of SNPs is used and the number of instruments if the subset is used. Indeed, this is perhaps an area for further investigation in which there could be other variants of the approach which differ in the means of obtaining a suitable cut-off point.  
   - [**Solution:**]{style="color: Purple;"} In our simulation study, we will **use `subset=TRUE` and `sub.cut=0.05`** as the default setting of our method. 
   
<br>

- [**Question:**]{style="color: Purple;"} *Should we* ***estimate*** ***lambda*** *using `est_lambda()` or will we assume that the values of `n.exposure`, `n.outcome`, `n.overlap` and `cor.xy` are all known?* 
  - [**Discussion:**]{style="color: Purple;"} Of course, this is only of interest to use when the fraction of overlap is greater than 0, i.e. when we don't have two fully independent outcome and exposure GWAS data sets. The hesitation of using `est_lambda()` is due to the fact that the estimate of *lambda* it provides has been shown to have a high degree of variance, even if it is unbiased. We currently do not know how using a highly variable estimate of *lambda* in our method may affect our causal effect estimate. Perhaps the key question is 'do we generally expect researchers to know the number of samples in each GWAS, the number of overlapping samples and the correlation between the exposure and the outcome, or at least be able to estimate these values very well?' If the researcher has access to the individual-level data, these values would be very easily obtainable. Therefore, it is perhaps reasonable to test our approach using the default setting of `est.lambda=FALSE` with *known* values of `n.exposure`, `n.outcome`, `n.overlap` and `cor.xy`. That said, a certain avenue for further research would be to see how sensitive our method is to variable estimates of *lambda*. 
  - [**Solution:**]{style="color: Purple;"} In our study, we will **use `est.lambda=FALSE` and provide** ***known*** **values of `n.exposure`, `n.outcome`, `n.overlap` and `cor.xy`**. We aim to also run a brief sensitivity study to compare method performance in terms of `est.lambda=FALSE` and `est.lambda=TRUE`.
  
<br>

- [**Question:**]{style="color: Purple;"} *For all fractions of overlap, should we test both `splits=2` and `splits=3`?* 
   - [**Discussion:**]{style="color: Purple;"} An alternative here would be to suggest using `splits=2` only when the outcome and exposure GWASs have employed two independent non-overlapping samples. Otherwise, for any degree of overlap, `splits=3` may be considered as the safer option in order to avoid weak instrument bias in the direction of the observational association. However, it could be interesting to see in simulations how `splits=2` and `splits=3` perform in each overlap scenario.
  - [**Solution:**]{style="color: Purple;"} In our study, we will **test both forms** of our method, i.e. **`splits=2` and `splits=3`**, as it will be interesting to see which form works best in terms of bias and variance for different degrees of overlap. 
  
<br>

- [**Question:**]{style="color: Purple;"} *Is it okay to simply leave the* ***splitting fractions at 50%***, *i.e. `pi=0.5` and `pi2=0.5`, or will further theoretical justification for the reason for choosing these fractions be required?*     
  - [**Discussion:**]{style="color: Purple;"} Again, this question presents another avenue for further work and exploration. However, it could be potentially difficult to come up with a single theoretical rule for these splitting fractions as it is likely that optimal fractions will change based on the genetic architectures of the exposure and outcome. We feel that it is perhaps more important to present our initial proposal of the method and demonstrate its effectiveness rather than obtaining optimal values for each parameter of our method. In practice, with individual-level data, in order to avoid *Winner's Curse*, it has been seen that researchers tend to split their entire data set in two and use half of the samples for selecting/discovering the instrument SNPs and the other half for estimating the SNP-exposure effect sizes. In fact, this idea of optimising discovery/replication sample splits for MR analysis is mentioned in the work of [Sadreev et al. (2021)](https://www.medrxiv.org/content/10.1101/2021.06.28.21259622v1) where they state that they "determined that splitting the UK Biobank sample into two sets of 50% each would provide the most flexibility". Therefore, this gives us at least some justification for choosing `pi=0.5`, which means that at each iteration, simulated values corresponding to half of the entire data set will be used for the purpose of SNP selection. Naturally, this does mean that as the sample size for selection is decreased compared to that of the full data set, we do expect less SNPs to be selected as instruments on a given iteration than if we were to use the full data set for selection. In the three split approach, we have chosen to continue to use half of the data set for selection. The reason for this is that we want to ensure that a good quantity of instruments are still being selected at each iteration. Of course, this means that smaller sample sizes are then used in estimating the SNP-exposure and SNP-outcome effect sizes, which can result in an increase in variance of our causal effect estimate. However, as we can increase the number of iterations of our approach as high as potentially $N_{\text{iter}} = 1000$ and our final causal effect estimate is the mean of the estimates at each iteration, this high number of iterations can reverse the increase in variance and allow us to obtain a much more stable final causal effect estimate. 
  
  - [**Solution:**]{style="color: Purple;"} Due to the above reasons, we feel that **simply setting the values `pi=0.5` and `pi2=0.5`** and using these defaults is appropriate for this stage of our work. 

<br>

- [**Question:**]{style="color: Purple;"} *Should we consider using a value greater than $5 \times 10^{-8}$ for the* ***selection threshold*** *or is it appropriate to simply leave it as `threshold=5e-8`?*
  - [**Discussion:**]{style="color: Purple;"} The selection threshold is perhaps another parameter that deserves the same treatment as the splitting fractions above, in the sense that time could be dedicated to investigating if using a less stringent threshold would be more suitable, but for now it is perhaps more sensible to simply remaining using a default value. 
  - [**Solution:**]{style="color: Purple;"} For the above reason, we will continue to simply **use the genome-wide threshold of $5 \times 10^{-8}$ for selection** purposes in our proposed method. 
 
<br>

- [**Question:**]{style="color: Purple;"} *What* ***MR methods*** *should we consider to work in combination with our method?* 

  - [**Discussion:**]{style="color: Purple;"} As mentioned above, our proposed approach requires the use of other MR methods to work in conjunction with it. We first investigate using the IVW method with our approach as this is perhaps the simplest MR method, and much work has been done in the field to suggest improvements to this straightforward approach. However, we have seen that even though *Winner's Curse* bias will be removed from using our approach with IVW, it is possible that a certain amount of weak instrument bias will still exist, especially due to the simulated sample splitting procedure. As MR-RAPS is a well-known method that can alleviate this weak instrument bias, we have also considered using MR-RAPS with our approach. This combination has been seen to work really well in practice, especially in the case where we have a single fully overlapping data set and use `splits=3`. It is possible that other pleiotropy-robust approaches could be considered, however it is perhaps sensible to focus on IVW and MR-RAPS and to dedicate investigating the performance of these other MR methods in conjunction with our approach to another time for similar reasons as those mentioned above, e.g. time constraints etc.  
  - [**Solution:**]{style="color: Purple;"} In our study, we will **focus on applying our proposed approach with only IVW and MR-RAPS.**

<br>

### Other methods

The first point mentioned above regarding the simulation study design suggested that we must decide on what other methods we should include in our study for comparison purposes. The following recently published papers can give us an idea regarding this: [*"Breaking the Winner's Curse in Mendelian Randomization: Rerandomized Inverse Variance Weighted Estimator"*](https://arxiv.org/pdf/2302.10470v1.pdf), [*"Bias correction for inverse variance weighting Mendelian randomization"*](https://onlinelibrary.wiley.com/doi/epdf/10.1002/gepi.22522) and [*"Incorporating discovery and replication GWAS into summary data Mendelian randomization studies: A review of current methods and a simple, general and powerful alternative"*](https://www.biorxiv.org/content/10.1101/2023.01.12.523708v2.full.pdf). 

Naturally, we will compare our method against just simply using **IVW** and **MR-RAPS** on the entire data set and selecting instruments based on this entire data set. 


[$\star$]{style="color: blue;"} **Note:** It is also possible for us to consider returning to our previous work and applying some of the *Winner's Curse* correction methods discussed in [*"Review and further developments in statistical corrections for Winner's Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546), such as the **empirical Bayes method**, and using the resulting adjusted SNP-exposure association estimates in the IVW method. For example, the code for doing so together with an example which uses our above simulated data set is provided as follows.


```{r}
library(winnerscurse)

mr_ivw_EB <- function(data, threshold=5e-8){
	## obtain adjusted estimate
  data.exp <- data.frame(rsid=data$SNP,beta=data$beta.exposure,se=data$se.exposure)
  data.exp.EB <- empirical_bayes(data.exp)
  data.exp.EB <- data.exp.EB[order(data.exp.EB$rsid,decreasing=FALSE),]
  data$beta.exposure.EB <- data.exp.EB$beta_EB
  ## subset data set
  data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < threshold)
  if(nrow(data_sig) < 3){return(NULL)}else{
  ivw.res <- summary(stats::lm(data_sig$beta.outcome ~ -1 + data_sig$beta.exposure.EB, weights = 1/data_sig$se.outcome^2))
	b <- ivw.res$coef[1,1]
	se <- ivw.res$coef[1,2]/min(1,ivw.res$sigma) 
	pval <- 2 * stats::pnorm(abs(b/se), lower.tail=FALSE)
	return(data.frame(method="mr_ivw_EB", nsnp=nrow(data_sig), b=b, se=se, pval=pval))
  }
}
```


```{r}
mr_ivw_EB(data,threshold=5e-8)
```


<br>



Interestingly, the three papers mentioned above are all quite different in their approaches to performing a simulation study. Firstly,
[*"Breaking the Winner's Curse in Mendelian Randomization: Rerandomized Inverse Variance Weighted Estimator"*](https://arxiv.org/pdf/2302.10470v1.pdf) simulates suitable summary statistics and considers the proposed **RIVW** estimator together with classical two-/three-sample IVW, debiased IVW (dIVW) and two/three-sample RAPS estimator. All simulations involve two independent non-overlapping samples. 
In their three-sample MR analyses for IVW and MR-RAPS, they "generate a new independent exposure data with the same sample size for IV selection". 

[$\star$]{style="color: blue;"} **Note:** Code for the RIVW method proposed in this paper does not seem to have been made available. 


Secondly, [*"Bias correction for inverse variance weighting Mendelian randomization"*](https://onlinelibrary.wiley.com/doi/epdf/10.1002/gepi.22522) 
proposed the **MRlap** method and compares it to RAPS, IVW, dIVW, weighted median and weighted mode. However, we note that their simulation approach makes use of genotypic data and thus, differs in our approach where we would just be simulating summary statistics. They essentially simulate individual-level data and subsequently perform a GWAS using BGENIE for each repetition of each simulation scenario. It appears that for most methods, instruments are selected using the same data set with a $p$-value threshold of $5 \times 10^{-8}$. It is mentioned that "using a third sample to select instruments and avoid winner's curse was out of the scope of the paper". We note that in a section of their study they compare "corrected effects obtained using the full (overlapping) sample to IVW-based effects obtained by splitting it into two halves to avoid sample overlap." This is perhaps something we could consider in the case of full overlap in our simulations.  

[$\star$]{style="color: blue;"} **Note:** Code for MRlap is available on GitHub. However, upon looking at the required inputs for the function `mrlap`, it may be difficult for us to include MRlap in our simulation study as we are merely simulating summary statistics. 

Finally, [*"Incorporating discovery and replication GWAS into summary data Mendelian randomization studies: A review of current methods and a simple, general and powerful alternative"*](https://www.biorxiv.org/content/10.1101/2023.01.12.523708v2.full.pdf) considers **regression calibration with IVW** and compares it to naive IVW, 3-sample IVW, 3-sample MR-RAPS, MR-RAPS with ZP and MR-RAPS with UMVCUE. It is noted in this paper that MRlap requires "genome-wide information about SNP-exposure and SNP-outcome associations (not only instruments) to estimate the underlying parameters needed for the correction." However, it is also mentioned that "sample overlap...is not relevant to the scope of this paper". Due to the requirement of genome-wide information MRlap is omitted from the simulation study in this paper and only used with real data. We anticipate that MRlap will receive the same treatment in our work. In this paper, three non-overlapping independent samples are generated in all simulations, i.e. discovery, replication and outcome.

[$\star$]{style="color: blue;"} **Note:** Code for regression calibration is available on GitHub. Similar to our approach, regression calibration is used in collaboration with other MR methods such as IVW, simple/weighted median and simple/weighted mode. However, regression calibration requires independent discovery and replication samples, which we do not intend to simulate in our study. 


In two out of three of the above papers, the debiased IVW method, **dIVW**, is also considered. The authors of this method recommend using all available SNPs to estimate the causal effect. Code is available to implement the dIVW method from the `mr.divw` R package. However, if we use this package as follows and apply `mr.divw` to our previously simulated data set, we get the following result. It can be seen that the result is clearly extremely biased here and thus, further investigation is required here before considering using `mr.divw` in our simulation study. However, if we actually do select SNPs and apply the method to just those SNPs with $p$-values less than $5 \times 10^{-8}$, it can be seen that the result is much closer to what we might expect. That said, this is not the recommended use of the method and if testing the method by means of simulations, it is perhaps better to test it in the form that it is intended to be used. 


```{r}
library(mr.divw)

mr_divw <- function(data,sig_SNPs=FALSE,threshold=5e-8){
  if(sig_SNPs==TRUE){
     data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < threshold)
     res.divw <- mr.divw(data_sig$beta.exposure, data_sig$beta.outcome, data_sig$se.exposure, data_sig$se.outcome, diagnostics=FALSE)
     return(data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE))))
  }else{
     res.divw <- mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
     return(data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE))))
  }
}

mr_divw(data)
```


```{r}
mr_divw(data,sig_SNPs=TRUE)
```
<br>

[$\star$]{style="color: blue;"} **Question:** Should we also consider using two-sample/three-sample forms of IVW and MR-RAPS in our simulations? For example, suppose we simulated two fully independent data sets of summary statistics for exposure and outcome, with a sample size each of 100,000 say. If we were to consider three-sample IVW in this setting, would we then have to use our simulation approach to simulate a sample split of 50,000 and 50,000 and use the first split to select instruments and the second split for the SNP-exposure effect sizes?  

[$\star$]{style="color: blue;"} **Solution:** Firstly, because we are investigating different degrees of overlap which include both zero overlap and full overlap, when IVW and RAPS are applied to samples with zero overlap, we are essentially evaluating their performance in the two-sample setting. In terms of three-sample IVW/RAPS, we note that these methods were only evaluated in two of the papers above in which they simulated another independent exposure data set of the same size to use for selection purposes. In contrast, in the MRlap paper, it is mentioned that "using a third sample to select instruments and avoid winner's curse was out of the scope of the paper".  
 
In addition to this, we take note of the comments regarding the three-sample MR design in [*"An empirical investigation into the impact of
winner’s curse on estimates from Mendelian
randomization"*](https://academic.oup.com/ije/article/52/4/1209/6961569?login=false) in which it is stated that: "...in practice, it is rarely feasible to find three distinct large samples of participants that are sufficiently similar to combine into a single analysis (e.g. same ancestry
group). Even if it is possible, the loss in sample size (and
hence power) from not including the discovery GWAS in
the estimation of genetic associations may be unwelcome.
Additionally, differences in participant characteristics between samples may mean that genetic variants discovered
in one data set are not the most relevant predictors of the
exposure in a second data set." 

For these reasons, we feel that the simulation approach taken by two of these papers in which they simulate a third independent exposure data set of equal size is perhaps not entirely realistic. Therefore, if we were to include comparisons of three-sample IVW/RAPS, the most realistic way of doing so would be to split the exposure data set, as suggested above. In conclusion, in our main study, we believe it is perhaps most sensible to take a similar approach to that of the MRlap paper, in which we do not consider simulating an independent exposure data set to select instruments for three-sample IVW/RAPS. However, we will consider performing a brief study following this in which we compare using our approach on the entire data set against splitting this entire data set into two or three and using a fraction of the data set for instrument selection to avoid *Winner's Curse*.


[**Conclusion:**]{style="color: Purple;"} Following our detailed discussion above, we will include the following methods in our simulation study: 

 - MRSimSS-2-IVW
 - MRSimSS-2-RAPS
 - MRSimSS-3-IVW
 - MRSimSS-3-RAPS
 - IVW 
 - MR-RAPS
 - IVW-EB
 - dIVW


### Simulation parameters

The second point regarding simulation study design above indicates that we must also consider what **simulation parameters** to adjust and what would be suitable values for these parameters to take. As illustrated even by the three papers mentioned previously, parameter values for simulation studies are always quite arbitrary and often it is quite difficult to decide on what would be best. In our first main set of simulations, we intend to simulate data using the `sim_mr_stats` function which directly generates GWAS summary statistics for a set of independent SNPs.


```{r}
sim_mr_stats <- function(n_snps, prop_effect, h2, frac_overlap, n_x, n_y, cor_xy, beta_xy){
  n_overlap <- frac_overlap*min(n_x, n_y)
  maf <- runif(n_snps, 0.01, 0.5)
  effect_snps <- n_snps*prop_effect
  index <- sample(1:n_snps, ceiling(effect_snps), replace=FALSE) # random sampling
  beta_gx <- rep(0,n_snps)
  beta_gx[index] <- rnorm(length(index),0,1)
  var_x <- sum(2*maf*(1-maf)*beta_gx^2)/h2
  if(var_x != 0){beta_gx <- beta_gx/sqrt(var_x)} # scaling to represent an exposure with variance 1
  beta_gy <- beta_gx * beta_xy

  var_gx <- 1/(n_x*2*maf*(1-maf)) # var(X)=1
  var_gy <- 1/(n_y*2*maf*(1-maf)) # var(Y)=1
  cov_gx_gy <- ((n_overlap*cor_xy)/(n_x*n_y))*(1/(2*maf*(1-maf)))
  # create covariance matrix for each SNP
  cov_array <- array(dim=c(2, 2, n_snps))
  cov_array[1,1,] <- var_gx
  cov_array[2,1,] <- cov_gx_gy
  cov_array[1,2,] <- cov_array[2,1,]
  cov_array[2,2,] <- var_gy

  summary_stats <- apply(cov_array, 3, function(x){MASS::mvrnorm(n=1, mu=c(0,0), Sigma=x)})
  summary_stats <- t(summary_stats + rbind(beta_gx, beta_gy))

  data <- tibble(
    SNP = 1:n_snps,
    beta.exposure = summary_stats[,1],
    beta.outcome = summary_stats[,2],
    se.exposure = sqrt(var_gx),
    se.outcome = sqrt(var_gy)
  )
  return(data)
}

```


[$\star$]{style="color: blue;"} **Note:** Simulating summary statistics for `n_snps = 10^6` using this function can be quite computational intensive. For example, we see below that it takes **approx. 2 minutes**. This is something we must take into consideration when designing our simulation study and selecting suitable values for certain parameters, such as `n_snps`.


```{r}
start.time <- Sys.time()
data_1 <- sim_mr_stats(n_snps=10^6, prop_effect=0.01, h2=0.4, frac_overlap=1, n_x=100000, n_y=100000, cor_xy=0.6, beta_xy=0.3)
end.time <- Sys.time()
round(end.time - start.time,2)
```
<br>

Due to the computational time for the above function which is primarily due to the use of `mvrnorm`, we consider adapting our function in order to ensure quicker runtime. We can do so by replacing `mvrnorm()` with matrix multiplication as shown below. It can be seen that this greatly reduces the time taken to simulate summary statistics, by a factor of 10. 


```{r}
sim_mr_stats_2 <- function(n_snps, prop_effect, h2, frac_overlap, n_x, n_y, cor_xy, beta_xy){
  n_overlap <- frac_overlap*min(n_x, n_y)
  maf <- runif(n_snps, 0.01, 0.5)
  effect_snps <- n_snps*prop_effect
  index <- sample(1:n_snps, ceiling(effect_snps), replace=FALSE) # random sampling
  beta_gx <- rep(0,n_snps)
  beta_gx[index] <- rnorm(length(index),0,1)
  var_x <- sum(2*maf*(1-maf)*beta_gx^2)/h2
  if(var_x != 0){beta_gx <- beta_gx/sqrt(var_x)} # scaling to represent an exposure with variance 1
  beta_gy <- beta_gx * beta_xy

  var_gx <- 1/(n_x*2*maf*(1-maf)) # var(X)=1
  var_gy <- 1/(n_y*2*maf*(1-maf)) # var(Y)=1
  cov_gx_gy <- ((n_overlap*cor_xy)/(n_x*n_y))*(1/(2*maf*(1-maf)))
  # create covariance matrix for each SNP
  cov_array <- array(dim=c(2, 2, n_snps))
  cov_array[1,1,] <- var_gx
  cov_array[2,1,] <- cov_gx_gy
  cov_array[1,2,] <- cov_array[2,1,]
  cov_array[2,2,] <- var_gy

  # summary_stats <- apply(cov_array, 3, function(x){MASS::mvrnorm(n=1, mu=c(0,0), Sigma=x)})
  # mvrnorm replaced by the following:
  tr_vec <- apply(cov_array,3,function(x){x[1,1]+x[2,2]})
  s_vec <- apply(cov_array,3,function(x){sqrt(sum(x[1,1]*x[2,2]-x[1,2]*x[2,1]))})
  t_vec <- sqrt(tr_vec+2*s_vec)
  s_vec <- rep(s_vec,times=rep(4,n_snps))
  I_vec <- rep(c(1,0,0,1),times=rep(n_snps))
  t_vec <- rep(t_vec,times=rep(4,n_snps))
  sqrt_array <- array((as.vector(cov_array)+s_vec*I_vec)/t_vec,dim=c(2,2,n_snps))

  Z_array <- array(rnorm(2*n_snps),dim=c(1,2,n_snps))
  Z_array <- abind::abind(Z_array,Z_array,along=1)
  sqrt_array_normal <- sqrt_array*Z_array
  # rearrange array so to use matrix multiplication
  sqrt_array_normal <- aperm(a=sqrt_array_normal,perm=c(3,1,2))
  dim1 <- sqrt_array_normal[,1,] %*% matrix(c(1,1),nrow=2)
  dim2 <- sqrt_array_normal[,2,] %*% matrix(c(1,1),nrow=2)
  summary_stats <- cbind(dim1,dim2)

  summary_stats <- (summary_stats + cbind(beta_gx, beta_gy))

  data <- tibble(
    SNP = 1:n_snps,
    beta.exposure = summary_stats[,1],
    beta.outcome = summary_stats[,2],
    se.exposure = sqrt(var_gx),
    se.outcome = sqrt(var_gy)
  )
  return(data)
}
```


```{r}
start.time <- Sys.time()
data_1 <- sim_mr_stats_2(n_snps=10^6, prop_effect=0.01, h2=0.4, frac_overlap=1, n_x=100000, n_y=100000, cor_xy=0.6, beta_xy=0.3)
end.time <- Sys.time()
round(end.time - start.time,2)
```
<br>

#### Data-generating model

In this section, we will briefly outline the simple data-generating model used in our function above, `sim_mr_stats`. In essence, there are three individual steps that are involved in the simulation process of `sim_mr_stats`:

- **Step 1:** Simulating $\beta_{X1}$ or `beta_gx` for each SNP
- **Step 2:** Obtaining $\beta_{Y1}$ using the assumption that $\beta_{Y1} = \beta_{XY} \cdot \beta_{X1}$, `beta_gy <- beta_gx * beta_xy`, in which $\beta$ is the true causal effect of the exposure on the outcome
- **Step 3:** Simulating $\hat\beta_{X1}$ and $\hat\beta_{Y1}$ using the simulated values of $\beta_{X1}$ and $\beta_{Y1}$ and the appropriate variance-covariance matrix

<br>

Firstly, in **Step 1**, in order to generate appropriate values for $\beta_{X1}$, we will take a similar approach to that described in the supplementary material of [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546). We assume a set of independent SNPs in which the true effect sizes for an exposure, $X$ follow a normal distribution. $N$ is the total number of SNPs and it is fixed at $N = 1,000,000$ for our simulation study. 

A value is provided for $\pi$, $\pi \in \{0.01,0.001\}$, the proportion of the total SNPs which are truly associated with the exposure. This determines the number of effect SNPs $K = \pi \cdot N, 1 \leq K \leq N$, forming a polygenic background. A minor allele frequency is attained for SNP $i$ using the uniform distribution $\text{maf}_i \sim U[0.01,0.5]$.

Assuming that the true effect sizes, $\beta_{X1_i}$ of associated SNPs follow a Gaussian distribution with mean 0, $\beta_{X1_i}$ is sampled for SNP $i, i = 1, ..., K,$ from the distribution $\beta_{X1_i} \sim N(0, 1)$. Non-effect SNP $i, i=K+1,...,N$, is simply assigned the null true effect size, $\beta{X1_i} = 0$. 

Defining the heritability $h^2$ as the proportion of phenotypic variation, $\text{var}(X)$, that is explained by all SNPs, $\text{var}(X)$ can be computed as 

$$\text{var}(X) = \frac{\sum_{i=1}^K 2 \text{maf}_i (1-\text{maf}_i) \cdot \beta_{X1_i}^2}{h^2}$$

and following this, the true effect sizes are scaled by dividing each by the square root of $\text{var}(X)$ in order to ensure a phenotype with variance 1.

Once we have $\beta_{X1}$ for each SNP, it is very easy to perform **Step 2** as we obtain $\beta_{Y1}$ by simply multiplying $\beta_{X1}$ by $\beta_{XY}$, the causal effect of the exposure on the outcome. 

In order to establish the variance-covariance matrix required in **Step 3**, we will include a derivation of the asymptotic distribution of two-sample summary statistics with overlap. Note that much of this derivation has already been included in the first section above, *"Proposed Method Derivation"*.

<br>

[$\star \;$ **Asymptotic distribution of two-sample summary statistics with overlap:**]{style="color: purple;"}

Let us assume the following structural equations model linking genotype at a given  SNP, $G$, a continuous exposure, $X$ and a continuous outcome, $Y$.
Thus, for a randomly selected individual in the population, genotype,
exposure and outcome are causally linked via the following equations.

$$X = \beta_X G + \varepsilon_X + \delta_{u,x}U$$
$$Y = \beta X + \varepsilon_Y + \delta_{u,y}U$$ 

Here, the terms $\varepsilon_X$, $\varepsilon_Y$ and $U$ are zero mean error terms with
finite variance. It can be shown that
$\text{cov}(X,Y) = \beta \cdot \text{var}(X) + \delta_{u,x}\delta_{u,y}\cdot\text{var}(U)$
and thus, the slope coefficient for the regression of $Y$ on $X$ is only
unbiased for $\beta$ when there is no confounding, i.e.
$\delta_{u,x}\delta_{u,y}\cdot\text{var}(U) = 0$.

Suppose we randomly sample $N$ individuals from the populations, with genotypes $G_1,...,G_N$ on the given SNP, with each $G_j \in {0,1,2}$ referring to individual $j$'s genotype at the SNP. We organize genotypes in a matrix:

$$\bf{G} =\begin{pmatrix} 1 & G_{1} \\ 1 & G_{2} \\ \vdots & \vdots \\ 1 & G_{N} \end{pmatrix}$$

It follows that: 

$$\bf{G}^T\bf{G} = \begin{pmatrix} N & \sum_{j=1}^{N} G_j \\ \sum_{j=1}^{N} G_j & \sum_{j=1}^{N} G_j^2  \end{pmatrix}$$

Now let $m < 0.5$ denote the allele frequency for the variant allele over the population. We assume that the SNP is in Hardy Weinburg Equilibrium. Due to independent sampling, each $G_j$ is binomially distributed, with mean $E(G_j) = 2m$ and second moment,
$E(G_j^2) = (E(G_j))^2 + \text{var}(G_j) = 4m^2 + 2m(1-m)$.

By the law of large numbers, this gives:

$$\bf{G}^T\bf{G} \sim \begin{pmatrix} N & N \cdot E(G_j)\\ N \cdot E(G_j) & N \cdot E(G_j^2)  \end{pmatrix} = \begin{pmatrix} N & N \cdot 2m \\ N \cdot 2m & N \cdot (4m^2 + 2m(1-m))  \end{pmatrix}$$

where **A** $\sim$ **B** implies as $N \rightarrow \inf, \frac{A_{ij}}{B_{ij}} \rightarrow 1$, for each element $(i,j)$ of the matrices **A** and **B**, where dependence of $A$ and $B$ on $N$ is suppressed for simplicity. 
From this, it follows that: 

$$\left(\bf{G}^T\bf{G} \right)^{-1} \sim \frac{1}{N} \begin{pmatrix} 1 & 2m \\ 2m & 4m^2 + 2m(1-m) \end{pmatrix}^{-1}$$

where

$$\textbf{C} = \begin{pmatrix} 1 & 2m \\ 2m & 4m^2 + 2m(1-m) \end{pmatrix}^{-1} = \frac{1}{2m(1-m)} \begin{pmatrix} 2m(1-m) + 4m^2 & 2m \\ 2m & 1 \end{pmatrix}.$$

Now, suppose we genotype individuals $i = 1,...,N_1,....,N_1+N_2,....,N_1+N_2+N_3$. The exposure, $X$ and the outcome, $Y$ are recorded for individuals $i = 1,...,N_1,$, $X$ but not $Y$ is recorded for $i = N_1 + 1,....,N_1+N_2,$ and $Y$ but not $X$ is recorded for individuals $i = N_1+N_2 + 1,....,N_1+N_2+N_3$. We partition the genotype matrices corresponding to the individuals with measured $X$ and measured $Y$ as follows:

$$ \bf{G_X} = \begin{pmatrix} \bf{G_1} \\ \bf{G_2} \end{pmatrix}$$
$$ \bf{G_Y} = \begin{pmatrix} \bf{G_1} \\ \bf{G_3} \end{pmatrix}$$

where $\bf{G_1}$ is an $N_1 \times 2$ matrix (its first column being 1 and the 2nd column the genotypes), $\bf{G_2}$ is $N_2 \times 2$ and $\bf{G_3}$ is $N_3 \times 2$.

Basedon these genotypes matrices, and denoting the $(N_1 + N_2) \times 1$ exposure vector by $\bf{X}$ and the $(N_1 + N_3) \times 1$ outcome vector by $\bf{Y}$, the estimated regression coefficient vectors corresponding to the SNP-exposure and the SNP-outcome regressions are:

$$\hat \beta_X = \left( \textbf{G}_\textbf{X}^T\textbf{G}_\textbf{X} \right)^{-1}\textbf{G}_\textbf{X}^T\textbf{X} \sim \frac{\textbf{C}}{N_1 + N_2} \textbf{G}_\textbf{X}^T\textbf{X}$$

and 

$$\hat \beta_Y = \left( \textbf{G}_\textbf{Y}^T\textbf{G}_\textbf{Y} \right)^{-1}\textbf{G}_\textbf{Y}^T\textbf{Y} \sim \frac{\textbf{C}}{N_1 + N_3} \textbf{G}_\textbf{Y}^T\textbf{Y}$$

It follows that 

$$\text{cov}(\hat \beta_X, \hat \beta_Y) = \text{cov}\left( \frac{\textbf{C}}{N_1 + N_2} \textbf{G}_\textbf{X}^T\textbf{X}, \frac{\textbf{C}}{N_1 + N_3} \textbf{G}_\textbf{Y}^T\textbf{Y} \right) = \frac{\textbf{C}\textbf{G}_\textbf{1}^T \text{cov}(\textbf{X}_\textbf{1}, \textbf{Y}_\textbf{1}) \textbf{G}_\textbf{1}\textbf{C}^T}{(N_1 + N_2)(N_1 + N_3)}$$

where $\bf{X_1}$ and $\bf{Y_1}$ denote the first $N_1$ elements of $X$ and $Y$. 

Finally, noting that $\text{cov}(\textbf{X}_\textbf{1}, \textbf{Y}_\textbf{1}) = \text{cov}(X,Y)\textbf{I}_{N_1}$, where from before $\text{cov}(X,Y) = \beta \text{var}(X) + \delta_{u,x}\delta_{u,y}\cdot\text{var}(U)$ and $\textbf{I}_{N_1}$ is the $N_1 \times N_1$ identity matrix, $\textbf{G}_\textbf{1}^T\textbf{G}_\textbf{1} \sim N_1 \textbf{C}^{-1}$ and $\bf{C} = \bf{C}^T$, it follows that:

$$\text{cov}(\hat \beta_X, \hat \beta_Y) \sim \frac{N_1 \text{cov}(X,Y) \textbf{C}}{(N_1 + N_2)(N_1 + N_3)}$$

The preceding matrix equation details the covariance of the coefficient vectors: $\hat\beta_X$ and $\hat\beta_Y$. However, we are in fact just interested in the second component of these vectors, i.e. the slope coefficients $\hat\beta_{X1}$ and $\hat\beta_{Y1}$ rather than the intercepts. Therefore, in order to obtain an expression for $\text{cov}(\hat\beta_{X1},\hat\beta_{Y1})$, it is required to extract the lower right element of the preceding matrix. The corresponding element of $\textbf{C}$ is $\frac{1}{2m(1-m)}$. Denoting $\rho$ as the correlation between the exposure and the outcome, $\text{cov}(X,Y)= \rho \sqrt{\text{var}(X)} \sqrt{\text{var}(Y)}$. The expression for the covariance between the slope coefficients pertaining to $X$ and $Y$ is then:

$$\text{cov}(\hat \beta_{X1}, \hat \beta_{Y1}) \sim \frac{N_1 \rho \sqrt{\text{var}(X)} \sqrt{\text{var}(Y)}}{2m(1-m)(N_1 + N_2)(N_1 + N_3)}$$

Standard statistical theory dictates that $\text{var}(\hat\beta_{X1}) \sim \frac{\text{var}(X)}{(N_1 + N_2)2m(1-m)}$ and $\text{var}(\hat\beta_{Y1}) \sim \frac{\text{var}(Y)}{(N_1 + N_3)2m(1-m)}$, indicating that the variance-covariance matrix of $(\hat \beta_{X1}, \hat \beta_{Y1})$ is:

$$\textbf{var}(\hat\beta_{X1}, \hat\beta_{Y1}) =  \begin{pmatrix} \text{var}(\hat\beta_{X1}) & \text{cov}(\hat\beta_{X1},\hat\beta_{Y1}) \\ \text{cov}(\hat\beta_{X1},\hat\beta_{Y1}) & \text{var}(\hat\beta_{Y1}) \end{pmatrix}  \sim \frac{1}{2m(1-m)} \begin{pmatrix} \frac{\text{var}(X)}{(N_1 + N_2)} & \frac{N_1 \rho \sqrt{\text{var}(X)} \sqrt{\text{var}(Y)}}{(N_1 + N_2)(N_1 + N_3)} \\ \frac{N_1 \rho \sqrt{\text{var}(X)} \sqrt{\text{var}(Y)}}{(N_1 + N_2)(N_1 + N_3)} & \frac{\text{var}(Y)}{(N_1 + N_3)} \end{pmatrix}   .$$

<br>


From the above derivation, it is easy to see how **Step 3** may be executed. Simply, for a given SNP, SNP $i$, when values for $\beta_{X1}$ and $\beta_{Y1}$ are available, values for $\hat\beta_{X1}$ and $\hat\beta_{Y1}$ can be simulated from the following distribution:

$$\begin{pmatrix} \hat\beta_{X1} \\ \hat\beta_{Y1} \end{pmatrix} \sim N \left( \begin{pmatrix} \beta_{X1} \\ \beta_{Y1} \end{pmatrix},
\frac{1}{2\text{maf}_i(1-\text{maf}_i)} \begin{pmatrix} \frac{1}{N_X} & \frac{N_\text{overlap} \rho }{N_X N_Y} \\ \frac{N_\text{overlap} \rho}{N_X N_Y} & \frac{1}{N_Y} \end{pmatrix}  \right) $$

where we assume $\text{maf}_i$ is the minor allele frequency of SNP $i$, $N_X$ is the number of individuals with exposure information, $N_Y$ is the number of individuals with recorded outcomes, $N_\text{overlap}$ is the number of individuals who have both exposure and outcome information available and $\rho$ is the correlation between the exposure, $X$ and the outcome, $Y$. Note that we also assume that the variance of both the exposure and outcome are equal to 1, i.e. $\text{var}(X) = \text{var}(Y) = 1$. 


<br>

[$\star$]{style="color: blue;"} **Note:** Even though our data-generating model outlined above assumes that confounding exists which is captured by $\rho_{XY}$ taking a *different* value to $\beta_{XY}$, it also assumes that there are **no direct genetic effects on the outcome**. This is clearly seen in Step 2 as $\beta_{Y1} = \beta_{XY} \cdot\beta_{X1}$. Naturally, we are aware that this is a limitation of our simulation study as it is likely with real data that direct genetic effects on the outcome will exist. However, we note that in the simulation study executed in [*"Bias correction for inverse variance weighting Mendelian randomization"*](https://onlinelibrary.wiley.com/doi/epdf/10.1002/gepi.22522), a similar approach was taken as they mention that "For simplicity, we assumed that there were no direct genetic effects on the outcome". 

[**Question:**]{style="color: purple;"} *Is it possible to introduce balanced and/or unbalanced direct genetic effects on the outcome into our model? Is it advised to do so in order to reduce limitations of our study or is it acceptable to omit it as this is something our method does not consider, i.e. the purpose of our study is to show how our method deals with Winner's Curse, weak instrument bias and sample overlap?* 


<br>

#### Choice of parameters

The discussion of the data-generating model above provided an indication as to what parameters need to be specified for our simulation study. In the function `sim_mr_stats`, we can see that there are 8 arguments required. Firstly, we will choose to fix the number of independent SNPs at 1,000,000, `n_snps = 10^6` and also, we will fix the **causal effect** of the exposure on the outcome at 0.3, `beta_xy =0.3`. 

Both the **heritability**, `h2` and the **proportion of effect SNPs**, `prop_effect` essentially work together in determining the genetic architecture of the exposure. This is important to explore in terms of our study here as according to [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546), "The extent of *Winner’s Curse* bias will partially depend on the true effect size distribution. This true effect size distribution is dependent on a combination of factors such as polygenicity, heritability and allele frequency distribution, with all of these features relating to power...". Furthermore, this paper also mentions that "...the presence of *Winner’s Curse* bias in the estimated effect sizes of significant SNPs should be of a greater concern when investigating traits with lower heritability or traits which have a larger proportion of effect SNPs." Similar to the simulation study detailed in this paper, we will include two values for heritability, `h2 = {0.3,0.7}` and polygenicity, `prop_effect = {0.01,0.001}` in our factorial design. Therefore, given the above, we anticipate that *Winner's Curse* bias will be greatest in the SNP-exposure effect size estimates and the number of significant SNPs or instruments will be lowest in the scenario in which `h2 = 0.3` and `prop_effect = 0.01`. 

With respect to weak instrument bias, it is stated in [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546), that "In the case that the exposure and outcome effects are estimated in a single (i.e.
fully overlapping) sample, the bias will be in the direction of the (confounded) observational
association. When SNP-exposure and SNP-outcome estimates are obtained from two nonoverlapping samples, the bias is in the direction of the null. Partial sample overlap will lead
to an estimate that lies between these two extremes." Therefore, varying both the the **correlation** between the exposure and the outcome, `cor_xy` as well as the **fraction of overlap** between the two samples, `frac_overlap`, will allow us to witness this behaviour. We choose to include the following values for the correlation, `cor_xy = {-0.1,0.1,0.3,0.5}` and the fraction of overlap, `frac_overlap = {0,0.25,0.5,0.75,1}`. For example, when `cor_xy = 0.5` and `frac_overlap = 0`, in methods which do not take into account weak instrument bias, we expect that our causal effect estimates will be underestimated and suffer from bias toward the null. When we increase the fraction of overlap to `frac_overlap = 1` for this value of correlation, we then expect to see that our estimates will be upward biased towards 0.5 for these methods. 

Finally, as we have already included several different choices of parameters which will result in a total of $2 \times 2 \times 2 \times 4 \times 5 = 80$ different scenarios, we will just choose one reasonable value for the **sample size** of the exposure and outcome GWASs. We assume that both GWASs are of the same sample size and we first set `n_x = n_y = 200000`. This is arguably somewhat reflective of the sample size of typical GWASs as most GWASs are performed using hundreds of thousands of individuals. However, as the extent of *Winner's Curse* bias is known to be dependent on sample size, we hope to extend our simulation study to sample sizes of 50,000 and 500,000, `n_x = n_y = {50000,500000}`, in order to see how changes in sample size can affect our causal effect estimate. 

<br>

### Code 

The code for our simulation study is included below. These simulations were run on the HPC cluster at University of Galway. 

```{r, eval=FALSE}
library(parallel)
library(winnerscurse)
library(TwoSampleMR)
library(mr.simss)
library(mr.raps)
library(mr.divw)


## Required Functions sim_mr_stats (as defined with matrix multiplication above), mr_ivw_EB:
source("MRSimSS_sims_funs.R")


## Total number of simulations:
tot_sim <- 100
n_snps <- 10^6
beta_xy <- 0.3

sim_params <- expand.grid(
   sim = c(1:tot_sim),
   h2 = c(0.3,0.7),
   prop_effect = c(0.01,0.001),
   cor_xy = c(-0.1,0.1,0.3,0.5),
   frac_overlap = c(0, 0.25, 0.5, 0.75, 1),
   n_x = c(200000)
)


set.seed(1998)


run_sim <- function(h2,prop_effect,cor_xy,frac_overlap,n_x,sim){

  data <- sim_mr_stats(n_snps, prop_effect, h2, frac_overlap, n_x, n_x, cor_xy, beta_xy)

  ## MRSimSS-2-IVW
  res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=n_x,n.outcome=n_x,n.overlap=frac_overlap*n_x,cor.xy=cor_xy,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary

  ## MRSimSS-2-RAPS
  res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=n_x,n.outcome=n_x,n.overlap=frac_overlap*n_x,cor.xy=cor_xy,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary

  ## MRSimSS-3-IVW
  res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=n_x,n.outcome=n_x,n.overlap=frac_overlap*n_x,cor.xy=cor_xy,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary

  ## MRSimSS-3-RAPS
  res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,n.exposure=n_x,n.outcome=n_x,n.overlap=frac_overlap*n_x,cor.xy=cor_xy,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
  
  ## IVW
  data_mr <- tibble::tibble(
    SNP = data$SNP,
    id.exposure="X",
    id.outcome="Y",
    exposure="X",
    outcome="Y",
    beta.exposure = data$beta.exposure,
    beta.outcome = data$beta.outcome,
    se.exposure = data$se.exposure,
    se.outcome = data$se.outcome,
    mr_keep=TRUE
  )

  data_mr_sig <- data_mr %>% dplyr::filter(2*(stats::pnorm(abs(data_mr$beta.exposure/data_mr$se.exposure), lower.tail=FALSE)) < 5e-8)
  res.ivw <- TwoSampleMR::mr(data_mr_sig,method_list=c("mr_ivw"))[,5:9]

  ## MR-RAPS
  data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
  res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
  res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)

  ## IVW-EB
  res.ivw.EB <- mr_ivw_EB(data)

  ## dIVW
  res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
  res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))

  ## compile results
  results <- list(params = data.frame(sim=sim,h2=h2,prop_effect=prop_effect,cor_xy=cor_xy,frac_overlap=frac_overlap,n_x=n_x), res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.divw)
  return(results)
}

res <- mclapply(1:nrow(sim_params), function(i){do.call(run_sim, args=as.list(sim_params[i,]))}, mc.cores=1) 

## Organise results:
total_res <- data.frame(sim=c(),h2=c(),prop_effect=c(),cor_xy=c(),frac_overlap=c(),n_x=c(),method=c(),nsnp=c(),b=c(),se=c(),pval=c())

for(i in 1:length(res)){
  for(j in 2:length(res[[1]])){
    res1 <- cbind(data.frame(res[[i]][1]$params),res[[i]][j][[1]])
    if(j == 2 | j == 3 | j == 4 | j == 5){res1$method <- paste("MRSimSS", res1$method, sep = "-")
    res1 <- res1[,c(1:8,10:12)]}
    total_res <- rbind(total_res,res1)
  }
}

## export total_res to csv file 
write.table(total_res,args[1],quote=FALSE,row.names=FALSE)

```

<br>

## Simulation study results 

After performing the detailed simulation study, we now aim to visualise and appropriately interpret the results. 

As we have considered a factorial design with 80 different scenarios, it is difficult to visualise all in one plot. Thus, we will first consider plotting our results collapsed over `h2`, heritability and `prop_effect`, proportion of effect SNPs, as shown below. 

[**Comments:**]{style="color: purple;"}

- `divw` seems to be only suitable in the case of zero overlap and thus, there seems to be a real danger in using `divw` to obtain an estimate of the causal effect if any degree of overlap is present between the two samples. However, even if it does appear to perhaps have greater standard deviation than the other approaches when there is zero overlap, it also appears that it is unbiased.

- In terms of **consistently being unbiased** in all scenarios, it is evident that there is one clear winner - **`SimSS3_raps`**. Most encouragingly, in the case where there is full overlap and `cor_xy=0.5`, this method still seems to generate unbiased causal effect estimates while all other methods, except `SimSS3_ivw`, are biased upwards towards the observational association. 

- `ivw_EB` is essentially the IVW method which uses SNP-exposure effect estimates which have been corrected for *Winner's Curse* bias using the empirical Bayes approach. It seems to be performing very well when there is zero overlap. However, as this fraction of overlap increases, especially when `cor_xy = {0.3,0.5}`, the causal effect estimates obtained with this method seem to suffer from much greater standard deviation and become clearly upward biased when there is full overlap. 

- We note that even though `SimSS2_ivw` and `SimSS3_ivw` have removed *Winner's Curse* bias, it is clear to see that weak instrument bias is still very much present. This is especially clear to see in `SimSS3_ivw` as it simulates splitting the original sample in 3 and therefore, we see that no matter what fraction of overlap may exist, this method demonstrates greater weak instrument bias toward the null in all cases. In the 2-split approach of our method, the weak instrument bias will be toward the observational association or correlation. 

- Lastly both `ivw` and `raps` have *Winner's Curse* bias present, with `ivw` also suffering from weak instrument bias. We note that MR-RAPS is a method known to alleviate weak instrument bias. When there is no overlap, both of these approaches have greater variance and are biased towards the null. When there is full overlap, their performance varies depending on the correlation between the exposure and outcome. 

 



<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_all.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_all.png?raw=true" width="100%"> </a>
</p>


```{r,echo=FALSE}
results <- read.table("C:/Users/GenDataSci025/Downloads/MRSimSS_res_test.txt",header=TRUE)

results$method_name <- rep(c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"),length(results)/8)
results$method_name <- factor(results$method_name, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"))
results$methodA <- rep(c("A","B","C","D","E","F","G","H"),length(results)/8)

results$mse <- (results$b - 0.3)^2
results <- results[is.na(results$se) == FALSE,]

ave.b <- c(mean(results$b[results$methodA=="A"]),mean(results$b[results$methodA=="B"]),mean(results$b[results$methodA=="C"]),mean(results$b[results$methodA=="D"]),mean(results$b[results$methodA=="E"]),mean(results$b[results$methodA=="F"]),mean(results$b[results$methodA=="G"]),mean(results$b[results$methodA=="H"]))
rmse <- c(sqrt(mean(results$mse[results$methodA=="A"])),sqrt(mean(results$mse[results$methodA=="B"])),sqrt(mean(results$mse[results$methodA=="C"])),sqrt(mean(results$mse[results$methodA=="D"])),sqrt(mean(results$mse[results$methodA=="E"])),sqrt(mean(results$mse[results$methodA=="F"])),sqrt(mean(results$mse[results$methodA=="G"])),sqrt(mean(results$mse[results$methodA=="H"])))
ave.se <- c(mean(results$se[results$methodA=="A"]),mean(results$se[results$methodA=="B"]),mean(results$se[results$methodA=="C"]),mean(results$se[results$methodA=="D"]),mean(results$se[results$methodA=="E"]),mean(results$se[results$methodA=="F"]),mean(results$se[results$methodA=="G"]),mean(results$se[results$methodA=="H"]))
n.IV <- c(mean(results$nsnp[results$methodA=="A"]),mean(results$nsnp[results$methodA=="B"]),mean(results$nsnp[results$methodA=="C"]),mean(results$nsnp[results$methodA=="D"]),mean(results$nsnp[results$methodA=="E"]),mean(results$nsnp[results$methodA=="F"]),mean(results$nsnp[results$methodA=="G"]),mean(results$nsnp[results$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results$b[results$methodA==x]-mean(results$b[results$methodA==x]))^2))/sum(results$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results$b[results$methodA==x] + 1.96*results$se[results$methodA==x])) & (0.3 >(results$b[results$methodA==x] - 1.96*results$se[results$methodA==x]))))/sum(results$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results_summary <- data.frame(method = c(results$method[1:8]), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results_summary
```


<br>

We will now break down our results further and look at obtaining similar boxplots but for each fraction of overlap, with the results for different values of heritability and polygenicity visible. 


[**Zero overlap:**]{style="color: purple;"}

```{r,include=FALSE,eval=FALSE}
library(patchwork)
library(ggpubr)
library("RColorBrewer")
col <- brewer.pal(8,"Dark2")
col1 <- brewer.pal(11,"RdYlBu")
col2 <- brewer.pal(11,"PRGn")
results0 <- results[results$frac_overlap==0,]

results0A <- results0[results0$cor_xy==-0.1,]
results0B <- results0[results0$cor_xy==0.1,]
results0C <- results0[results0$cor_xy==0.3,]
results0D <- results0[results0$cor_xy==0.5,]

plotA <- ggplot(results0A, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = -0.1')


plotB <- ggplot(results0B, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.1')


plotC <- ggplot(results0C, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.3')


plotD <- ggplot(results0D, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.5')

figure <- plotA + plotB + plotC + plotD
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))


## save as image and include 
```


<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_0_overlap.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_0_overlap.png?raw=true" width="80%"> </a>
</p>


```{r,echo=FALSE}
results0 <- results[results$frac_overlap==0,]
results0$mse <- (results0$b - 0.3)^2

ave.b <- c(mean(results0$b[results0$methodA=="A"]),mean(results0$b[results0$methodA=="B"]),mean(results0$b[results0$methodA=="C"]),mean(results0$b[results0$methodA=="D"]),mean(results0$b[results0$methodA=="E"]),mean(results0$b[results0$methodA=="F"]),mean(results0$b[results0$methodA=="G"]),mean(results0$b[results0$methodA=="H"]))
rmse <- c(sqrt(mean(results0$mse[results0$methodA=="A"])),sqrt(mean(results0$mse[results0$methodA=="B"])),sqrt(mean(results0$mse[results0$methodA=="C"])),sqrt(mean(results0$mse[results0$methodA=="D"])),sqrt(mean(results0$mse[results0$methodA=="E"])),sqrt(mean(results0$mse[results0$methodA=="F"])),sqrt(mean(results0$mse[results0$methodA=="G"])),sqrt(mean(results0$mse[results0$methodA=="H"])))
ave.se <- c(mean(results0$se[results0$methodA=="A"]),mean(results0$se[results0$methodA=="B"]),mean(results0$se[results0$methodA=="C"]),mean(results0$se[results0$methodA=="D"]),mean(results0$se[results0$methodA=="E"]),mean(results0$se[results0$methodA=="F"]),mean(results0$se[results0$methodA=="G"]),mean(results0$se[results0$methodA=="H"]))
n.IV <- c(mean(results0$nsnp[results0$methodA=="A"]),mean(results0$nsnp[results0$methodA=="B"]),mean(results0$nsnp[results0$methodA=="C"]),mean(results0$nsnp[results0$methodA=="D"]),mean(results0$nsnp[results0$methodA=="E"]),mean(results0$nsnp[results0$methodA=="F"]),mean(results0$nsnp[results0$methodA=="G"]),mean(results0$nsnp[results0$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results0$b[results0$methodA==x]-mean(results0$b[results0$methodA==x]))^2))/sum(results0$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results0$b[results0$methodA==x] + 1.96*results0$se[results0$methodA==x])) & (0.3 >(results0$b[results0$methodA==x] - 1.96*results0$se[results0$methodA==x]))))/sum(results0$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results0_summary <- data.frame(method = c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results0_summary
```


[$\star$]{style="color: blue;"} **Comments:**

- In terms of bias, RMSE, standard deviation and coverage probability, **`SimSS2_raps` and `SimSS3_raps` perform very well** here across all combinations of heritability, polygenicity and correlation. Both approaches **reduce RMSE by about 57%** when compared with the original `raps` method. Given our description of our approach above, in the case of zero overlap, there is no real need to implement the 3-split form of our method as it brings no extra benefit. However, we see here by comparing `SimSS2_raps` with `SimSS3_raps` that the results given by both methods are very similar. `SimSS2_raps` demonstrates only very small improvements in terms of RMSE and coverage probability when compared with `SimSS3_raps`. Therefore, this perhaps provides evidence that we should recommend the researcher to only use `SimSS2_raps` if they know for certain that there is zero overlap between their exposure and outcome samples, but if there potentially could be overlap between the two samples, then `SimSS3_raps` should be used. 

- Interestingly, **`ivw_EB` has the smallest value for RMSE** and standard deviation here, with a reasonably unbiased average causal effect. Its average standard error is also closer to that of `ivw` and `raps`, which is somewhat lower than the competing simulated sample splitting methods.

- `divw` behaves well producing a competitive average causal estimate as well as good coverage probability. Notably, its average standard error is quite high compared to the other methods, which most likely has played a part in its values for RMSE and standard deviation. However, as we witnessed above, this is the only fraction of overlap in which `divw` performs competitively, and therefore, it is advised that the researcher demonstrates caution if using the `divw` method with two GWASs that may have overlapping samples. 

- Note that the **coverage probabilities for `ivw` and `raps` are both less than 50%**, which clearly provides evidence that some form of bias exists in their causal effect estimates.

<br>

[**25% overlap:**]{style="color: purple;"}

```{r, include=FALSE,eval=FALSE}
results.25 <- results[results$frac_overlap==0.25,]

results.25B <- results.25[results.25$cor_xy==-0.1,]
results.25B <- results.25[results.25$cor_xy==0.1,]
results.25C <- results.25[results.25$cor_xy==0.3,]
results.25D <- results.25[results.25$cor_xy==0.5,]

plotA <- ggplot(results.25A, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = -0.1')


plotB <- ggplot(results.25B, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.1')


plotC <- ggplot(results.25C, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.3')


plotD <- ggplot(results.25D, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.5')

figure <- plotA + plotB + plotC + plotD
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))


## save as image and include 
```


<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_25_overlap.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_25_overlap.png?raw=true" width="80%"> </a>
</p>


```{r,echo=FALSE}
results.25 <- results[results$frac_overlap==0.25,]
results.25$mse <- (results.25$b - 0.3)^2

ave.b <- c(mean(results.25$b[results.25$methodA=="A"]),mean(results.25$b[results.25$methodA=="B"]),mean(results.25$b[results.25$methodA=="C"]),mean(results.25$b[results.25$methodA=="D"]),mean(results.25$b[results.25$methodA=="E"]),mean(results.25$b[results.25$methodA=="F"]),mean(results.25$b[results.25$methodA=="G"]),mean(results.25$b[results.25$methodA=="H"]))
rmse <- c(sqrt(mean(results.25$mse[results.25$methodA=="A"])),sqrt(mean(results.25$mse[results.25$methodA=="B"])),sqrt(mean(results.25$mse[results.25$methodA=="C"])),sqrt(mean(results.25$mse[results.25$methodA=="D"])),sqrt(mean(results.25$mse[results.25$methodA=="E"])),sqrt(mean(results.25$mse[results.25$methodA=="F"])),sqrt(mean(results.25$mse[results.25$methodA=="G"])),sqrt(mean(results.25$mse[results.25$methodA=="H"])))
ave.se <- c(mean(results.25$se[results.25$methodA=="A"]),mean(results.25$se[results.25$methodA=="B"]),mean(results.25$se[results.25$methodA=="C"]),mean(results.25$se[results.25$methodA=="D"]),mean(results.25$se[results.25$methodA=="E"]),mean(results.25$se[results.25$methodA=="F"]),mean(results.25$se[results.25$methodA=="G"]),mean(results.25$se[results.25$methodA=="H"]))
n.IV <- c(mean(results.25$nsnp[results.25$methodA=="A"]),mean(results.25$nsnp[results.25$methodA=="B"]),mean(results.25$nsnp[results.25$methodA=="C"]),mean(results.25$nsnp[results.25$methodA=="D"]),mean(results.25$nsnp[results.25$methodA=="E"]),mean(results.25$nsnp[results.25$methodA=="F"]),mean(results.25$nsnp[results.25$methodA=="G"]),mean(results.25$nsnp[results.25$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results.25$b[results.25$methodA==x]-mean(results.25$b[results.25$methodA==x]))^2))/sum(results.25$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results.25$b[results.25$methodA==x] + 1.96*results.25$se[results.25$methodA==x])) & (0.3 >(results.25$b[results.25$methodA==x] - 1.96*results.25$se[results.25$methodA==x]))))/sum(results.25$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results.25_summary <- data.frame(method = c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results.25_summary
```

[$\star$]{style="color: blue;"} **Comments:**

- With a fraction of overlap of 25%, `divw` has already begun to severely break down, while `ivw` and `raps` still suffer from general downward bias and higher RMSE. 

- `SimSS2_raps`, `SimSS3_raps` and `ivw_EB` continue to be the best performing methods with average causal effect estimates extremely close to 0.3, low RMSE values and high coverage probabilities. However, note that in terms of coverage probability, the value for `ivw_EB` is notably lower compared to the other two. 

- `SimSS3_ivw` is behaving as expected, demonstrating bias towards the null. Even though the sample splitting process removes *Winner's Curse*, using the approach in combination with the IVW method shows an increase in weak instrument bias, in comparison with the regular IVW method, as both the SNP-exposure and SNP-outcome estimates used to determine the causal effect estimate at each iteration have greater variance. No matter what fraction of overlap may exist, in the 3 split approach with IVW, this weak instrument bias will always be towards the null as the SNP-exposure and SNP-outcome estimates are derived from non-overlapping simulated splits. 


<br>

[**50% overlap:**]{style="color: purple;"}

```{r, include=FALSE,eval=FALSE}
results.5 <- results[results$frac_overlap==0.5,]

results.5A <- results.5[results.5$cor_xy==-0.1,]
results.5B <- results.5[results.5$cor_xy==0.1,]
results.5C <- results.5[results.5$cor_xy==0.3,]
results.5D <- results.5[results.5$cor_xy==0.5,]

plotA <- ggplot(results.5A, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = -0.1')


plotB <- ggplot(results.5B, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.1')


plotC <- ggplot(results.5C, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.3')


plotD <- ggplot(results.5D, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.5')

figure <- plotA + plotB + plotC + plotD
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))


## save as image and include 
```

<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_50_overlap.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_50_overlap.png?raw=true" width="80%"> </a>
</p>


```{r,echo=FALSE}
results.5 <- results[results$frac_overlap==0.5,]
results.5$mse <- (results.5$b - 0.3)^2

ave.b <- c(mean(results.5$b[results.5$methodA=="A"]),mean(results.5$b[results.5$methodA=="B"]),mean(results.5$b[results.5$methodA=="C"]),mean(results.5$b[results.5$methodA=="D"]),mean(results.5$b[results.5$methodA=="E"]),mean(results.5$b[results.5$methodA=="F"]),mean(results.5$b[results.5$methodA=="G"]),mean(results.5$b[results.5$methodA=="H"]))
rmse <- c(sqrt(mean(results.5$mse[results.5$methodA=="A"])),sqrt(mean(results.5$mse[results.5$methodA=="B"])),sqrt(mean(results.5$mse[results.5$methodA=="C"])),sqrt(mean(results.5$mse[results.5$methodA=="D"])),sqrt(mean(results.5$mse[results.5$methodA=="E"])),sqrt(mean(results.5$mse[results.5$methodA=="F"])),sqrt(mean(results.5$mse[results.5$methodA=="G"])),sqrt(mean(results.5$mse[results.5$methodA=="H"])))
ave.se <- c(mean(results.5$se[results.5$methodA=="A"]),mean(results.5$se[results.5$methodA=="B"]),mean(results.5$se[results.5$methodA=="C"]),mean(results.5$se[results.5$methodA=="D"]),mean(results.5$se[results.5$methodA=="E"]),mean(results.5$se[results.5$methodA=="F"]),mean(results.5$se[results.5$methodA=="G"]),mean(results.5$se[results.5$methodA=="H"]))
n.IV <- c(mean(results.5$nsnp[results.5$methodA=="A"]),mean(results.5$nsnp[results.5$methodA=="B"]),mean(results.5$nsnp[results.5$methodA=="C"]),mean(results.5$nsnp[results.5$methodA=="D"]),mean(results.5$nsnp[results.5$methodA=="E"]),mean(results.5$nsnp[results.5$methodA=="F"]),mean(results.5$nsnp[results.5$methodA=="G"]),mean(results.5$nsnp[results.5$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results.5$b[results.5$methodA==x]-mean(results.5$b[results.5$methodA==x]))^2))/sum(results.5$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results.5$b[results.5$methodA==x] + 1.96*results.5$se[results.5$methodA==x])) & (0.3 >(results.5$b[results.5$methodA==x] - 1.96*results.5$se[results.5$methodA==x]))))/sum(results.5$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results.5_summary <- data.frame(method = c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results.5_summary
```

[$\star$]{style="color: blue;"} **Comments:**

- In terms of all our evaluation metrics, both `SimSS2_raps` and `SimSS3_raps` are undoubtedly the most consistent methods, with coverage probabilities near 95%. `ivw_EB` is becoming less competitive with a reduced coverage probability and increased RMSE. In the plots, it can be seen that `ivw_EB` shows great upward bias when the proportion of effect SNPs is 0.01. 

<br>

[**75% overlap:**]{style="color: purple;"}

```{r, include=FALSE,eval=FALSE}
results.75 <- results[results$frac_overlap==0.75,]

results.75A <- results.75[results.75$cor_xy==-0.1,]
results.75B <- results.75[results.75$cor_xy==0.1,]
results.75C <- results.75[results.75$cor_xy==0.3,]
results.75D <- results.75[results.75$cor_xy==0.5,]

plotA <- ggplot(results.75A, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = -0.1')


plotB <- ggplot(results.75B, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.1')


plotC <- ggplot(results.75C, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.3')


plotD <- ggplot(results.75D, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.5')

figure <- plotA + plotB + plotC + plotD
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))


## save as image and include 
```

<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_75_overlap.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_75_overlap.png?raw=true" width="80%"> </a>
</p>


```{r,echo=FALSE}
results.75 <- results[results$frac_overlap==0.75,]
results.75$mse <- (results.75$b - 0.3)^2
results.75 <- results.75[is.na(results.75$se) == FALSE,]

ave.b <- c(mean(results.75$b[results.75$methodA=="A"]),mean(results.75$b[results.75$methodA=="B"]),mean(results.75$b[results.75$methodA=="C"]),mean(results.75$b[results.75$methodA=="D"]),mean(results.75$b[results.75$methodA=="E"]),mean(results.75$b[results.75$methodA=="F"]),mean(results.75$b[results.75$methodA=="G"]),mean(results.75$b[results.75$methodA=="H"]))
rmse <- c(sqrt(mean(results.75$mse[results.75$methodA=="A"])),sqrt(mean(results.75$mse[results.75$methodA=="B"])),sqrt(mean(results.75$mse[results.75$methodA=="C"])),sqrt(mean(results.75$mse[results.75$methodA=="D"])),sqrt(mean(results.75$mse[results.75$methodA=="E"])),sqrt(mean(results.75$mse[results.75$methodA=="F"])),sqrt(mean(results.75$mse[results.75$methodA=="G"])),sqrt(mean(results.75$mse[results.75$methodA=="H"])))
ave.se <- c(mean(results.75$se[results.75$methodA=="A"]),mean(results.75$se[results.75$methodA=="B"]),mean(results.75$se[results.75$methodA=="C"]),mean(results.75$se[results.75$methodA=="D"]),mean(results.75$se[results.75$methodA=="E"]),mean(results.75$se[results.75$methodA=="F"]),mean(results.75$se[results.75$methodA=="G"]),mean(results.75$se[results.75$methodA=="H"]))
n.IV <- c(mean(results.75$nsnp[results.75$methodA=="A"]),mean(results.75$nsnp[results.75$methodA=="B"]),mean(results.75$nsnp[results.75$methodA=="C"]),mean(results.75$nsnp[results.75$methodA=="D"]),mean(results.75$nsnp[results.75$methodA=="E"]),mean(results.75$nsnp[results.75$methodA=="F"]),mean(results.75$nsnp[results.75$methodA=="G"]),mean(results.75$nsnp[results.75$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results.75$b[results.75$methodA==x]-mean(results.75$b[results.75$methodA==x]))^2))/sum(results.75$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results.75$b[results.75$methodA==x] + 1.96*results.75$se[results.75$methodA==x])) & (0.3 >(results.75$b[results.75$methodA==x] - 1.96*results.75$se[results.75$methodA==x]))))/sum(results.75$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results.75_summary <- data.frame(method = c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results.75_summary
```

[$\star$]{style="color: blue;"} **Comments:**

- The results for 75% overlap simply reinforce all the points we have previously made. We do note however that the average causal effect estimates for `ivw` and `raps` seem to have increased closer to 0.3. However, this seems to be caused by the fact that at greater fractions of overlap, the weak instrument bias is directed towards the observational association. Therefore, when the correlation is 0.5, both `ivw` and `raps` demonstrate some upward bias while for correlation values such as -0.1 and 0.1, the bias is still in the downward direction. 

<br>

[**100% overlap:**]{style="color: purple;"}

```{r, include=FALSE,eval=FALSE}
results1 <- results[results$frac_overlap==1,]

results1A <- results1[results1$cor_xy==-0.1,]
results1B <- results1[results1$cor_xy==0.1,]
results1C <- results1[results1$cor_xy==0.3,]
results1D <- results1[results1$cor_xy==0.5,]

plotA <- ggplot(results1A, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = -0.1')


plotB <- ggplot(results1B, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.1')


plotC <- ggplot(results1C, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.3')


plotD <- ggplot(results1D, aes(x=method_name, y=b,color=as.factor(method_name))) + geom_boxplot(size=0.7,aes(fill=method_name, color=method_name, alpha=0.2)) + facet_grid(h2~prop_effect, labeller="label_both")+ ylab("Causal Effect") + xlab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  geom_hline(aes(yintercept = 0.3), linetype=1, size=0.5) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8])) +
  ylim(0.2, 0.4) +
  guides(color = guide_legend(title = "Method")) +  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1),text = element_text(size=12), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=12)) + 
  ggtitle('cor_xy = 0.5')

figure <- plotA + plotB + plotC + plotD
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))


## save as image and include 
```


<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_100_overlap.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_100_overlap.png?raw=true" width="80%"> </a>
</p>


```{r,echo=FALSE}
results1 <- results[results$frac_overlap==1,]
results1$mse <- (results1$b - 0.3)^2
results1 <- results1[is.na(results1$se) == FALSE,]

ave.b <- c(mean(results1$b[results1$methodA=="A"]),mean(results1$b[results1$methodA=="B"]),mean(results1$b[results1$methodA=="C"]),mean(results1$b[results1$methodA=="D"]),mean(results1$b[results1$methodA=="E"]),mean(results1$b[results1$methodA=="F"]),mean(results1$b[results1$methodA=="G"]),mean(results1$b[results1$methodA=="H"]))
rmse <- c(sqrt(mean(results1$mse[results1$methodA=="A"])),sqrt(mean(results1$mse[results1$methodA=="B"])),sqrt(mean(results1$mse[results1$methodA=="C"])),sqrt(mean(results1$mse[results1$methodA=="D"])),sqrt(mean(results1$mse[results1$methodA=="E"])),sqrt(mean(results1$mse[results1$methodA=="F"])),sqrt(mean(results1$mse[results1$methodA=="G"])),sqrt(mean(results1$mse[results1$methodA=="H"])))
ave.se <- c(mean(results1$se[results1$methodA=="A"]),mean(results1$se[results1$methodA=="B"]),mean(results1$se[results1$methodA=="C"]),mean(results1$se[results1$methodA=="D"]),mean(results1$se[results1$methodA=="E"]),mean(results1$se[results1$methodA=="F"]),mean(results1$se[results1$methodA=="G"]),mean(results1$se[results1$methodA=="H"]))
n.IV <- c(mean(results1$nsnp[results1$methodA=="A"]),mean(results1$nsnp[results1$methodA=="B"]),mean(results1$nsnp[results1$methodA=="C"]),mean(results1$nsnp[results1$methodA=="D"]),mean(results1$nsnp[results1$methodA=="E"]),mean(results1$nsnp[results1$methodA=="F"]),mean(results1$nsnp[results1$methodA=="G"]),mean(results1$nsnp[results1$methodA=="H"]))

ave.sd <- function(x){sqrt((sum((results1$b[results1$methodA==x]-mean(results1$b[results1$methodA==x]))^2))/sum(results1$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))

CP <- function(x){(sum((0.3 < (results1$b[results1$methodA==x] + 1.96*results1$se[results1$methodA==x])) & (0.3 >(results1$b[results1$methodA==x] - 1.96*results1$se[results1$methodA==x]))))/sum(results1$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))

results1_summary <- data.frame(method = c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)
results1_summary
```

```{r, include=FALSE,eval=FALSE}
results <- read.table("C:/Users/GenDataSci025/Downloads/MRSimSS_res_test.txt",header=TRUE)

results$method_name <- rep(c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"),length(results)/8)
results$method_name <- factor(results$method_name, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","divw"))
results$methodA <- rep(c("A","B","C","D","E","F","G","H"),length(results)/8)
results1 <- results[results$frac_overlap==1,]
results1$mse <- (results1$b - 0.3)^2


results1A <- results1[results1$cor_xy==-0.1,]
results1B <- results1[results1$cor_xy==0.1,]
results1C <- results1[results1$cor_xy==0.3,]
results1D <- results1[results1$cor_xy==0.5,]


ave.b <- c(mean(results1A$b[results1A$methodA=="A"]),mean(results1A$b[results1A$methodA=="B"]),mean(results1A$b[results1A$methodA=="C"]),mean(results1A$b[results1A$methodA=="D"]),mean(results1A$b[results1A$methodA=="E"]),mean(results1A$b[results1A$methodA=="F"]),mean(results1A$b[results1A$methodA=="G"]),mean(results1A$b[results1A$methodA=="H"]))
rmse <- c(sqrt(mean(results1A$mse[results1A$methodA=="A"])),sqrt(mean(results1A$mse[results1A$methodA=="B"])),sqrt(mean(results1A$mse[results1A$methodA=="C"])),sqrt(mean(results1A$mse[results1A$methodA=="D"])),sqrt(mean(results1A$mse[results1A$methodA=="E"])),sqrt(mean(results1A$mse[results1A$methodA=="F"])),sqrt(mean(results1A$mse[results1A$methodA=="G"])),sqrt(mean(results1A$mse[results1A$methodA=="H"])))
ave.se <- c(mean(results1A$se[results1A$methodA=="A"]),mean(results1A$se[results1A$methodA=="B"]),mean(results1A$se[results1A$methodA=="C"]),mean(results1A$se[results1A$methodA=="D"]),mean(results1A$se[results1A$methodA=="E"]),mean(results1A$se[results1A$methodA=="F"]),mean(results1A$se[results1A$methodA=="G"]),mean(results1A$se[results1A$methodA=="H"]))
n.IV <- c(mean(results1A$nsnp[results1A$methodA=="A"]),mean(results1A$nsnp[results1A$methodA=="B"]),mean(results1A$nsnp[results1A$methodA=="C"]),mean(results1A$nsnp[results1A$methodA=="D"]),mean(results1A$nsnp[results1A$methodA=="E"]),mean(results1A$nsnp[results1A$methodA=="F"]),mean(results1A$nsnp[results1A$methodA=="G"]),mean(results1A$nsnp[results1A$methodA=="H"]))
ave.sd <- function(x){sqrt((sum((results1A$b[results1A$methodA==x]-mean(results1A$b[results1A$methodA==x]))^2))/sum(results1A$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))
CP <- function(x){(sum((0.3 < (results1A$b[results1A$methodA==x] + 1.96*results1A$se[results1A$methodA==x])) & (0.3 >(results1A$b[results1A$methodA==x] - 1.96*results1A$se[results1A$methodA==x]))))/sum(results1A$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))
results1A_summary <- data.frame(method = c(results1A$method[1:8]), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)


ave.b <- c(mean(results1B$b[results1B$methodA=="A"]),mean(results1B$b[results1B$methodA=="B"]),mean(results1B$b[results1B$methodA=="C"]),mean(results1B$b[results1B$methodA=="D"]),mean(results1B$b[results1B$methodA=="E"]),mean(results1B$b[results1B$methodA=="F"]),mean(results1B$b[results1B$methodA=="G"]),mean(results1B$b[results1B$methodA=="H"]))
rmse <- c(sqrt(mean(results1B$mse[results1B$methodA=="A"])),sqrt(mean(results1B$mse[results1B$methodA=="B"])),sqrt(mean(results1B$mse[results1B$methodA=="C"])),sqrt(mean(results1B$mse[results1B$methodA=="D"])),sqrt(mean(results1B$mse[results1B$methodA=="E"])),sqrt(mean(results1B$mse[results1B$methodA=="F"])),sqrt(mean(results1B$mse[results1B$methodA=="G"])),sqrt(mean(results1B$mse[results1B$methodA=="H"])))
ave.se <- c(mean(results1B$se[results1B$methodA=="A"]),mean(results1B$se[results1B$methodA=="B"]),mean(results1B$se[results1B$methodA=="C"]),mean(results1B$se[results1B$methodA=="D"]),mean(results1B$se[results1B$methodA=="E"]),mean(results1B$se[results1B$methodA=="F"]),mean(results1B$se[results1B$methodA=="G"]),mean(results1B$se[results1B$methodA=="H"]))
n.IV <- c(mean(results1B$nsnp[results1B$methodA=="A"]),mean(results1B$nsnp[results1B$methodA=="B"]),mean(results1B$nsnp[results1B$methodA=="C"]),mean(results1B$nsnp[results1B$methodA=="D"]),mean(results1B$nsnp[results1B$methodA=="E"]),mean(results1B$nsnp[results1B$methodA=="F"]),mean(results1B$nsnp[results1B$methodA=="G"]),mean(results1B$nsnp[results1B$methodA=="H"]))
ave.sd <- function(x){sqrt((sum((results1B$b[results1B$methodA==x]-mean(results1B$b[results1B$methodA==x]))^2))/sum(results1B$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))
CP <- function(x){(sum((0.3 < (results1B$b[results1B$methodA==x] + 1.96*results1B$se[results1B$methodA==x])) & (0.3 >(results1B$b[results1B$methodA==x] - 1.96*results1B$se[results1B$methodA==x]))))/sum(results1B$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))
results1B_summary <- data.frame(method = c(results1B$method[1:8]), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)


ave.b <- c(mean(results1C$b[results1C$methodA=="A"]),mean(results1C$b[results1C$methodA=="B"]),mean(results1C$b[results1C$methodA=="C"]),mean(results1C$b[results1C$methodA=="D"]),mean(results1C$b[results1C$methodA=="E"]),mean(results1C$b[results1C$methodA=="F"]),mean(results1C$b[results1C$methodA=="G"]),mean(results1C$b[results1C$methodA=="H"]))
rmse <- c(sqrt(mean(results1C$mse[results1C$methodA=="A"])),sqrt(mean(results1C$mse[results1C$methodA=="B"])),sqrt(mean(results1C$mse[results1C$methodA=="C"])),sqrt(mean(results1C$mse[results1C$methodA=="D"])),sqrt(mean(results1C$mse[results1C$methodA=="E"])),sqrt(mean(results1C$mse[results1C$methodA=="F"])),sqrt(mean(results1C$mse[results1C$methodA=="G"])),sqrt(mean(results1C$mse[results1C$methodA=="H"])))
ave.se <- c(mean(results1C$se[results1C$methodA=="A"]),mean(results1C$se[results1C$methodA=="B"]),mean(results1C$se[results1C$methodA=="C"]),mean(results1C$se[results1C$methodA=="D"]),mean(results1C$se[results1C$methodA=="E"]),mean(results1C$se[results1C$methodA=="F"]),mean(results1C$se[results1C$methodA=="G"]),mean(results1C$se[results1C$methodA=="H"]))
n.IV <- c(mean(results1C$nsnp[results1C$methodA=="A"]),mean(results1C$nsnp[results1C$methodA=="B"]),mean(results1C$nsnp[results1C$methodA=="C"]),mean(results1C$nsnp[results1C$methodA=="D"]),mean(results1C$nsnp[results1C$methodA=="E"]),mean(results1C$nsnp[results1C$methodA=="F"]),mean(results1C$nsnp[results1C$methodA=="G"]),mean(results1C$nsnp[results1C$methodA=="H"]))
ave.sd <- function(x){sqrt((sum((results1C$b[results1C$methodA==x]-mean(results1C$b[results1C$methodA==x]))^2))/sum(results1C$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))
CP <- function(x){(sum((0.3 < (results1C$b[results1C$methodA==x] + 1.96*results1C$se[results1C$methodA==x])) & (0.3 >(results1C$b[results1C$methodA==x] - 1.96*results1C$se[results1C$methodA==x]))))/sum(results1C$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))
results1C_summary <- data.frame(method = c(results1C$method[1:8]), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)

ave.b <- c(mean(results1D$b[results1D$methodA=="A"]),mean(results1D$b[results1D$methodA=="B"]),mean(results1D$b[results1D$methodA=="C"]),mean(results1D$b[results1D$methodA=="D"]),mean(results1D$b[results1D$methodA=="E"]),mean(results1D$b[results1D$methodA=="F"]),mean(results1D$b[results1D$methodA=="G"]),mean(results1D$b[results1D$methodA=="H"]))
rmse <- c(sqrt(mean(results1D$mse[results1D$methodA=="A"])),sqrt(mean(results1D$mse[results1D$methodA=="B"])),sqrt(mean(results1D$mse[results1D$methodA=="C"])),sqrt(mean(results1D$mse[results1D$methodA=="D"])),sqrt(mean(results1D$mse[results1D$methodA=="E"])),sqrt(mean(results1D$mse[results1D$methodA=="F"])),sqrt(mean(results1D$mse[results1D$methodA=="G"])),sqrt(mean(results1D$mse[results1D$methodA=="H"])))
ave.se <- c(mean(results1D$se[results1D$methodA=="A"]),mean(results1D$se[results1D$methodA=="B"]),mean(results1D$se[results1D$methodA=="C"]),mean(results1D$se[results1D$methodA=="D"]),mean(results1D$se[results1D$methodA=="E"]),mean(results1D$se[results1D$methodA=="F"]),mean(results1D$se[results1D$methodA=="G"]),mean(results1D$se[results1D$methodA=="H"]))
n.IV <- c(mean(results1D$nsnp[results1D$methodA=="A"]),mean(results1D$nsnp[results1D$methodA=="B"]),mean(results1D$nsnp[results1D$methodA=="C"]),mean(results1D$nsnp[results1D$methodA=="D"]),mean(results1D$nsnp[results1D$methodA=="E"]),mean(results1D$nsnp[results1D$methodA=="F"]),mean(results1D$nsnp[results1D$methodA=="G"]),mean(results1D$nsnp[results1D$methodA=="H"]))
ave.sd <- function(x){sqrt((sum((results1D$b[results1D$methodA==x]-mean(results1D$b[results1D$methodA==x]))^2))/sum(results1D$methodA==x))}
monte.sd <- c(ave.sd("A"),ave.sd("B"),ave.sd("C"),ave.sd("D"),ave.sd("E"),ave.sd("F"),ave.sd("G"),ave.sd("H"))
CP <- function(x){(sum((0.3 < (results1D$b[results1D$methodA==x] + 1.96*results1D$se[results1D$methodA==x])) & (0.3 >(results1D$b[results1D$methodA==x] - 1.96*results1D$se[results1D$methodA==x]))))/sum(results1D$methodA==x)}
CP.res <- c(CP("A"),CP("B"),CP("C"),CP("D"),CP("E"),CP("F"),CP("G"),CP("H"))
results1D_summary <- data.frame(method = c(results1D$method[1:8]), ave.b=ave.b, rmse=rmse, sd = monte.sd, ave.se = ave.se, CP = CP.res, n.IVs = n.IV)

results1A_summary
results1B_summary
results1C_summary
results1D_summary

print(results_height_2)
```


[$\star$]{style="color: blue;"} **Comments:**

- Finally, we look at the situation in which there is full sample overlap. This is potentially the instance where our proposed method, **MRSimSS** will be the most useful and beneficial for researchers. The form of our method which is best designed to deal with full overlap is **`SimSS3_raps`**. From the results and the plots above, we can see clearly that it seems to be the least biased and that it has the lowest RMSE and standard deviation values as well as the greatest coverage probability, close to 95%. This will provide researchers with the confidence that by using `SimSS3_raps` with their fully overlapping sample, their causal effect estimate should be void of *Winner's Curse* bias **as well as** weak instrument bias acting in the direction of the observational association. 


<br>


## Same-trait analyses 

We now have a look at comparing our proposed approach, **MRSimSS**, to other methods using real data. We will adopt a similar strategy to that detailed in  [*"Breaking the Winner's Curse in Mendelian Randomization: Rerandomized Inverse Variance Weighted Estimator"*](https://arxiv.org/pdf/2302.10470v1.pdf) and [*"Incorporating discovery and replication GWAS into summary data Mendelian randomization studies: A review of current methods and a simple, general and powerful alternative"*](https://www.biorxiv.org/content/10.1101/2023.01.12.523708v2.full.pdf), namely **same-trait analyses**. The idea here is that we will use these MR methods to estimate the causal effect of body mass index (BMI) on itself and the causal effect of height on itself, with the knowledge that the true causal effect is 1, in both instances.

In our previous paper, [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546), we performed two *independent* GWAS for both BMI and height using UK Biobank data sets and PLINK 2.0. Thus, in the BMI-BMI analysis, we use summary statistics from the first UKBB BMI GWAS [sample size 166,286] and summary statistics from the second UKBB BMI GWAS [sample size 166,332], denoted by BMI-1 and BMI-2, respectively. Similarly, in the height-height analysis, we use summary statistics from the first UKBB height GWAS [sample size 166,250] and summary statistics from the second UKBB BMI GWAS [sample size 166,687], denoted by Height-1 and Height-2, respectively.

[$\star$]{style="color: blue;"} **Note:** Further information regarding how these GWASs were orchestrated and the summary statistics were obtained can be found in [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546), with the code available at [https://github.com/amandaforde/winnerscurseGWAS](https://github.com/amandaforde/winnerscurseGWAS).


The above GWASs resulted in the availability of summary statistics for 7,915,560 SNPs. Thus, our next task was to select independent SNPs using the `clump_data()` function from the `twoSampleMR` R package, with R-squared < 0.001 and an extension of 10,000 Kb in the genome. Note that these are the same two parameter values as used by the two papers mentioned above. The code to do so for BMI-1 is as follows, with the same process repeated for BMI-2, Height-1 and Height-2:

```{r, eval=FALSE}
library(TwoSampleMR)
data <- read.table("summary_data_bmi_1.txt",header=TRUE)
data <- data.frame(chr=data$chr,pos=data$pos,rsid=data$rsid, pval=2*(pnorm(abs(data$beta/data$se), lower.tail=FALSE)))
clumped_SNPs <- ld_clump(dat=data,clump_kb=10000,clump_r2=0.001)$rsid 
write.csv(clumped_SNPs,"clumped_SNPs_bmi_1.txt")
```


This clumping procedure resulted in sets of 2448, 2471, 2435 and 2360 independent SNPs for BMI-1, BMI-2, Height-1 and Height-2, respectively.

<br>

[**BMI-1-BMI-2:**]{style="color: Purple;"}

We now consider estimating the causal effect of BMI on BMI using BMI-1 as the exposure data set and BMI-2 as the outcome data set. Recall that these two data sets are completely non-overlapping. 

[$\star$]{style="color: blue;"} **Note:** As it is only summary statistics that are available, in this application of `mr_simss()`, we could make use of the `est_lambda()` function and thus, information regarding overlap or correlation between exposure and outcome would not be required. However, as we do know that the data sets are independent, we know that the true value of `lambda.val` should be equal to zero as `lambda.val`$= \frac{N_{\text{overlap}}\rho}{\sqrt{N_X N_Y}}$. Therefore, in the `mr.simss()` function we can simply set `est.lambda=TRUE` and `lambda.val=0`.

The code for estimating the causal effect using these methods is shown below, with a table of results produced. 


```{r,echo=FALSE}
mr_ivw_EB <- function(data, threshold=5e-8){
  ## obtain adjusted estimate
  data.exp <- data.frame(rsid=data$SNP,beta=data$beta.exposure,se=data$se.exposure)
  data.exp.EB <- empirical_bayes(data.exp)
  data <- dplyr::arrange(data,dplyr::desc(abs(data$beta.exposure/data$se.exposure)))
  data$beta.exposure.EB <- data.exp.EB$beta_EB
  ## subset data set
  data_sig <- data[2*(pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < threshold,]
  if(nrow(data_sig) < 3){return(NULL)}else{
    ivw.res <- summary(stats::lm(data_sig$beta.outcome ~ -1 + data_sig$beta.exposure.EB, weights = 1/data_sig$se.outcome^2))
    b <- ivw.res$coef[1,1]
    se <- ivw.res$coef[1,2]/min(1,ivw.res$sigma)
    pval <- 2 * stats::pnorm(abs(b/se), lower.tail=FALSE)
    return(data.frame(method="mr_ivw_EB", nsnp=nrow(data_sig), b=b, se=se, pval=pval))
  }
}



## IVW
mr.ivw <- function(data, threshold=5e-8){
  ## subset data set
  data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < threshold)
  if(nrow(data_sig) < 3){return(NULL)}else{
    ivw.res <- summary(stats::lm(data_sig$beta.outcome ~ -1 + data_sig$beta.exposure, weights = 1/data_sig$se.outcome^2))
    b <- ivw.res$coef[1,1]
    se <- ivw.res$coef[1,2]/min(1,ivw.res$sigma)
    pval <- 2 * stats::pnorm(abs(b/se), lower.tail=FALSE)
    return(data.frame(method="mr_ivw", nsnp=nrow(data_sig), b=b, se=se, pval=pval))
  }
}

## IVW Bootstrap
mr_ivw_boot <- function(data, threshold=5e-8){
  ## obtain adjusted estimate
  data.exp <- data.frame(rsid=data$SNP,beta=data$beta.exposure,se=data$se.exposure)
  data.exp.boot <- BR_ss(data.exp)
  data <- dplyr::arrange(data,dplyr::desc(abs(data$beta.exposure/data$se.exposure)))
  data$beta.exposure.boot <- data.exp.boot$beta_BR_ss
  ## subset data set
  data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < threshold)
  if(nrow(data_sig) < 3){return(NULL)}else{
    ivw.res <- summary(stats::lm(data_sig$beta.outcome ~ -1 + data_sig$beta.exposure.boot, weights = 1/data_sig$se.outcome^2))
    b <- ivw.res$coef[1,1]
    se <- ivw.res$coef[1,2]/min(1,ivw.res$sigma)
    pval <- 2 * stats::pnorm(abs(b/se), lower.tail=FALSE)
    return(data.frame(method="mr_ivw_boot", nsnp=nrow(data_sig), b=b, se=se, pval=pval))
  }
}

```


```{r}
set.seed(1996)

clumped_SNPs <- read.csv("clumped_SNPs_bmi_1.txt",header=TRUE)
summary_data_bmi_1 <- read.table("C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_1.txt",header=TRUE)
clumped_bmi_1 <- summary_data_bmi_1[summary_data_bmi_1$rsid %in% clumped_SNPs$x,]
summary_data_bmi_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_2.txt',header=TRUE)
clumped_bmi_2 <- summary_data_bmi_2[summary_data_bmi_2$rsid %in% clumped_SNPs$x,]

## real data
data <- data.frame(SNP=clumped_bmi_1$rsid,beta.exposure=clumped_bmi_1$beta,beta.outcome=clumped_bmi_2$beta,se.exposure=clumped_bmi_1$se,se.outcome=clumped_bmi_2$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr.ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_bmi_1 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_bmi_1[[i]]$nsnp}
b <- function(i){results_bmi_1[[i]]$b}
se <- function(i){results_bmi_1[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_bmi_1_clump <- total_res
results_bmi_1_clump
```


<br>

[**BMI-2-BMI-1:**]{style="color: Purple;"}

Using the same set of MR methods, the causal effect of BMI on BMI is estimated again using BMI-2 as the exposure data set and BMI-1 as the outcome data set. 

```{r,  echo=FALSE}
set.seed(1996)

clumped_SNPs <- read.csv("clumped_SNPs_bmi_2.txt",header=TRUE)
summary_data_bmi_1 <- read.table("C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_1.txt",header=TRUE)
clumped_bmi_1 <- summary_data_bmi_1[summary_data_bmi_1$rsid %in% clumped_SNPs$x,]
summary_data_bmi_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_2.txt',header=TRUE)
clumped_bmi_2 <- summary_data_bmi_2[summary_data_bmi_2$rsid %in% clumped_SNPs$x,]

## real data
data <- data.frame(SNP=clumped_bmi_2$rsid,beta.exposure=clumped_bmi_2$beta,beta.outcome=clumped_bmi_1$beta,se.exposure=clumped_bmi_2$se,se.outcome=clumped_bmi_1$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr_ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_bmi_2 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_bmi_2[[i]]$nsnp}
b <- function(i){results_bmi_2[[i]]$b}
se <- function(i){results_bmi_2[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_bmi_2_clump <- total_res
results_bmi_2_clump
```


<br>

[**Height-1-Height-2:**]{style="color: Purple;"}

Here, the causal effect of height on itself is estimated by using Height-1 as the exposure data set and Height-2 as the outcome data set.

```{r,  echo=FALSE}
set.seed(1996)

clumped_SNPs <- read.csv("clumped_SNPs_height_1.txt",header=TRUE)
summary_data_height_1 <- read.table("C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_1.txt",header=TRUE)
clumped_height_1 <- summary_data_height_1[summary_data_height_1$rsid %in% clumped_SNPs$x,]
summary_data_height_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_2.txt',header=TRUE)
clumped_height_2 <- summary_data_height_2[summary_data_height_2$rsid %in% clumped_SNPs$x,]

## real data
data <- data.frame(SNP=clumped_height_1$rsid,beta.exposure=clumped_height_1$beta,beta.outcome=clumped_height_2$beta,se.exposure=clumped_height_1$se,se.outcome=clumped_height_2$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr_ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_height_1 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_height_1[[i]]$nsnp}
b <- function(i){results_height_1[[i]]$b}
se <- function(i){results_height_1[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))
results_height_1_clump <- total_res
results_height_1_clump
```


<br>

[**Height-2-Height-1:**]{style="color: Purple;"}

Lastly, the causal effect of height on itself is estimated again, using Height-2 as the exposure data set and Height-1 as the outcome data set. 

```{r, echo=FALSE}
set.seed(1996)

clumped_SNPs <- read.csv("clumped_SNPs_height_2.txt",header=TRUE)
summary_data_height_1 <- read.table("C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_1.txt",header=TRUE)
clumped_height_1 <- summary_data_height_1[summary_data_height_1$rsid %in% clumped_SNPs$x,]
summary_data_height_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_2.txt',header=TRUE)
clumped_height_2 <- summary_data_height_2[summary_data_height_2$rsid %in% clumped_SNPs$x,]

## real data
data <- data.frame(SNP=clumped_height_2$rsid,beta.exposure=clumped_height_2$beta,beta.outcome=clumped_height_1$beta,se.exposure=clumped_height_2$se,se.outcome=clumped_height_1$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr_ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_height_2 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_height_2[[i]]$nsnp}
b <- function(i){results_height_2[[i]]$b}
se <- function(i){results_height_2[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_height_2_clump <- total_res
results_height_2_clump
```




<br>

We can depict a summary of the above results for each scenario as follows.


```{r, eval=FALSE,echo=FALSE}
library(ggplot2)
library(RColorBrewer)
col <- brewer.pal(8,"Dark2")
col1 <- brewer.pal(11,"RdYlBu")

results_bmi_1_clump$method <- factor(results_bmi_1_clump$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_bmi_2_clump$method <- factor(results_bmi_2_clump$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height_1_clump$method <- factor(results_height_1_clump$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height_2_clump$method <- factor(results_height_2_clump$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))

plot_A <- ggplot(results_bmi_1_clump, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-1-BMI-2')
  
plot_B<- ggplot(results_bmi_2_clump, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-2-BMI-1')
  
plot_C <- ggplot(results_height_1_clump, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-1-Height-2')

plot_D <- ggplot(results_height_2_clump, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-2-Height-1')

figure <- plot_A + plot_B + plot_C + plot_D

```

```{r,eval=FALSE,echo=FALSE}
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))

```


<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_real_data.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_real_data.png?raw=true" width="100%"> </a>
</p>


<br>

[**Comments:**]{style="color: purple;"} 

- ***Question:*** *Why is dIVW performing so poorly in comparison with the other methods?*

- It it is known that the presence of *Winner's Curse* in the exposure estimates will lead to a deflation in the causal effect estimate while weak instrument bias also results in a bias towards the null in this instance of non-overlapping samples. Interestingly, it can be seen that, apart from dIVW, the naive IVW method is the most biased towards the null. This is quite likely due to the fact that both of these aforementioned biases are affecting its estimate. MR-RAPS aims to alleviate weak instrument bias. However, the presence of *Winner's Curse* is clear here for the RAPS estimate as its 95% confidence interval lies below 1 for each scenario. 

- Both IVW-EB and IVW-boot aim to correct for *Winner's Curse* by using adjusted exposure effect sizes in the IVW method. It seems that this plug-in process seems to be working to some degree as IVW-EB and IVW-boot estimates are consistently closer to 1 than their IVW counterparts. 

- In the case of MR-SimSS, it is true that as it is known that there is no overlap between the two data sets in each case, then it is perhaps better to focus on the 2-split version, as there is no real need for 3 splits. As expected in this case, weak instrument bias is increased in `SimSS3_ivw` compared with `SimSS2_ivw`, due to the smaller simulated sample sizes for the exposure and outcome data sets. Indeed, it can be seen that in most cases `SimSS3_raps` has larger standard error than `SimSS2_raps`. That said, the estimates are still very similar between these two approaches. It is very encouraging to see that **in all instances MR-SimSS, using RAPS, produces the least biased estimate**. Furthermore, in 3 out of 4 cases, its 95% confidence interval includes the true causal effect of 1.

- However, given all of this, some evidence of bias still persists as we can see that `SimSS2_raps` and `SimSS3_raps` still tend to underestimate slightly. We hypothesise that this could potentially be due to the nature of clumping as it retains the most strongly associated SNPs in each region based on their $p$-values. This is referenced in the article [*"Breaking the Winner’s Curse in Mendelian Randomization:
Rerandomized Inverse Variance Weighted Estimator"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546) in which they mention that "...standard clumping, which is based on p-value
comparisons, introduces a different type of selection bias..." and explore alternative forms of clumping. This leads us to investigate if using a pruned, rather than clumped, set of SNPs, will improve the causal effect estimates of our method. However, in order to accurately compare, we will need to obtain a set of pruned SNPs which have a similar number of significant SNPs to the clumped sets above. 


<br>


### Using pruned SNPs

Due to the possible issue with clumping mentioned above, we now have a look at the performance of our methods with respect to pruned data sets. Similar to above, we investigate estimating the causal effect of both BMI on itself and height on itself. To do so, we will first use a pruned set of SNPs similar to that which was obtained in [*"Review and further developments in statistical corrections for Winner’s Curse in genetic association studies"*](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1010546). In the supplementary file for this article, it is stated that "PLINK 2.0 (4) was used to prune the original set of SNPs. The command ‘--indep-pairwise 50 5 0.5’ was employed for pruning. This meant that
pruning occurred by first calculating LD between each pair of SNPs in a window of 50 SNPs. If an LD value greater than 0.5 was observed, then one SNP out of this pair was removed. The window was shifted 5 SNPs forward and the process was repeated. 1,589,295 SNPs remained after this procedure, a data set about 20% of the size of the original." 

However, in order to fairly compare our results when using clumped SNPs vs pruned SNPs, it is desirable that we obtain a pruned set of SNPs with a *roughly* similar number of significant SNPs, as mentioned above. Using the 1,589,295 SNPs obtained with `--indep-pairwise 50 5 0.5` provides 439, 465, 5859 and 5994 independent significant SNPs for BMI-1, BMI-2, Height-1 and Height-2, respectively. These figures are clearly much larger than those above and therefore, we will adjust the `--indep-pairwise` parameters for each trait in order to give more similar numbers of significant SNPs. 

For BMI, using `--indep-pairwise 100 10 0.001` provides a set of 46,566 independent SNPs which gives 83 and 86 significant SNPs for BMI-1 and BMI-2, respectively. 

For height, using `--indep-pairwise 175 10 0.001` provides a set of 26,869 independent SNPs which gives 379 and 362 significant SNPs for Height-1 and Height-2, respectively. 


[**BMI-1-BMI-2:**]{style="color: Purple;"}

Similar to the clumped scenario, we first consider estimating the causal effect of BMI on BMI using BMI-1 as the exposure data set and BMI-2 as the outcome data set. The code for doing so is very similar to that included above. 

```{r, echo=FALSE}
set.seed(1996)

pruned_SNPs <- read.table('C:/Users/GenDataSci025/Downloads/pruned_SNPs_height_001_100.txt',header=TRUE)

summary_data_bmi_1 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_1.txt',header=TRUE)
pruned_bmi_1 <- summary_data_bmi_1[summary_data_bmi_1$rsid %in% pruned_SNPs$V1,]

summary_data_bmi_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_bmi_2.txt',header=TRUE)
pruned_bmi_2 <- summary_data_bmi_2[summary_data_bmi_2$rsid %in% pruned_SNPs$V1,]

## real data
data <- data.frame(SNP=pruned_bmi_1$rsid,beta.exposure=pruned_bmi_1$beta,beta.outcome=pruned_bmi_2$beta,se.exposure=pruned_bmi_1$se,se.outcome=pruned_bmi_2$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr.ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_bmi_1 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_bmi_1[[i]]$nsnp}
b <- function(i){results_bmi_1[[i]]$b}
se <- function(i){results_bmi_1[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_bmi_1_prune <- total_res
results_bmi_1_prune
```


<br>

[**BMI-2-BMI-1:**]{style="color: Purple;"}

Using the same set of MR methods, the causal effect of BMI on BMI is estimated again using BMI-2 as the exposure data set and BMI-1 as the outcome data set. 

```{r,  echo=FALSE}
set.seed(1996)

## real data
data <- data.frame(SNP=pruned_bmi_2$rsid,beta.exposure=pruned_bmi_2$beta,beta.outcome=pruned_bmi_1$beta,se.exposure=pruned_bmi_2$se,se.outcome=pruned_bmi_1$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr.ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_bmi_2 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_bmi_2[[i]]$nsnp}
b <- function(i){results_bmi_2[[i]]$b}
se <- function(i){results_bmi_2[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_bmi_2_prune <- total_res
results_bmi_2_prune
```


<br>

[**Height-1-Height-2:**]{style="color: Purple;"}

Here, the causal effect of height on itself is estimated by using Height-1 as the exposure data set and Height-2 as the outcome data set.

```{r,  echo=FALSE}
set.seed(1996)

pruned_SNPs <- read.table('C:/Users/GenDataSci025/Downloads/pruned_SNPs_height_001_175.txt',header=TRUE)

summary_data_height_1 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_1.txt',header=TRUE)
pruned_height_1 <- summary_data_height_1[summary_data_height_1$rsid %in% pruned_SNPs$V1,]

summary_data_height_2 <-  read.table('C:/Users/GenDataSci025/winnerscurse_realdata/data/summary_data_height_2.txt',header=TRUE)
pruned_height_2 <- summary_data_height_2[summary_data_height_2$rsid %in% pruned_SNPs$V1,]


## real data
data <- data.frame(SNP=pruned_height_1$rsid,beta.exposure=pruned_height_1$beta,beta.outcome=pruned_height_2$beta,se.exposure=pruned_height_1$se,se.outcome=pruned_height_2$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr.ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_height_1 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_height_1[[i]]$nsnp}
b <- function(i){results_height_1[[i]]$b}
se <- function(i){results_height_1[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))
results_height_1_prune <- total_res
results_height_1_prune
```



<br>

[**Height-2-Height-1:**]{style="color: Purple;"}

Lastly, the causal effect of height on itself is estimated again, using Height-2 as the exposure data set and Height-1 as the outcome data set. 


```{r, echo=FALSE}
set.seed(1996)

## real data
data <- data.frame(SNP=pruned_height_2$rsid,beta.exposure=pruned_height_2$beta,beta.outcome=pruned_height_1$beta,se.exposure=pruned_height_2$se,se.outcome=pruned_height_1$se)

## MRSimSS-2-IVW
res.sim.2.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-2-RAPS
res.sim.2.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=2,mr_method = "mr_raps",parallel=TRUE)$summary
## MRSimSS-3-IVW
res.sim.3.ivw <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_ivw",parallel=TRUE)$summary
## MRSimSS-3-RAPS
res.sim.3.raps <- mr.simss::mr_simss(data,subset=TRUE,sub.cut=0.05,est.lambda=TRUE,lambda.val=0,n.iter=1000,splits=3,mr_method = "mr_raps",parallel=TRUE)$summary
## IVW
res.ivw <- mr.ivw(data)
## MR-RAPS
data_sig <- data %>% dplyr::filter(2*(stats::pnorm(abs(data$beta.exposure/data$se.exposure), lower.tail=FALSE)) < 5e-8)
res.raps <- mr.raps::mr.raps(data_sig$beta.exposure,data_sig$beta.outcome,data_sig$se.exposure,data_sig$se.outcome)
res.raps <- data.frame(method="mr_raps", nsnp=nrow(data_sig), b=res.raps$beta.hat, se=res.raps$beta.se, pval=res.raps$beta.p.value)
## IVW-EB
res.ivw.EB <- mr_ivw_EB(data)
## IVW-boot
res.ivw.boot <- mr_ivw_boot(data)
## dIVW
res.divw <- mr.divw::mr.divw(data$beta.exposure, data$beta.outcome, data$se.exposure, data$se.outcome, diagnostics=FALSE)
res.divw <- data.frame(method="mr_divw", nsnp=res.divw$n.IV, b=res.divw$beta.hat, se=res.divw$beta.se, pval=2*(stats::pnorm(abs(res.divw$beta.hat/res.divw$beta.se), lower.tail=FALSE)))
## compile results
results_height_2 <- list(res.sim.2.ivw, res.sim.2.raps, res.sim.3.ivw, res.sim.3.raps, res.ivw, res.raps, res.ivw.EB, res.ivw.boot,res.divw)

total_res <- data.frame(method=c(rep("0",9)))
total_res$method <- c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw")
snp <- function(i){results_height_2[[i]]$nsnp}
b <- function(i){results_height_2[[i]]$b}
se <- function(i){results_height_2[[i]]$se}
total_res$b <- c(b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8),b(9))
total_res$se <- c(se(1),se(2),se(3),se(4),se(5),se(6),se(7),se(8),se(9))
total_res$CI.lower <- total_res$b - 1.96*total_res$se
total_res$CI.upper <- total_res$b + 1.96*total_res$se
total_res$n.IV <- c(snp(1),snp(2),snp(3),snp(4),snp(5),snp(6),snp(7),snp(8),snp(9))

results_height_2_prune <- total_res
results_height_2_prune
```


<br>


```{r, eval=FALSE,echo=FALSE}
library(ggplot2)
library(RColorBrewer)
col <- brewer.pal(8,"Dark2")
col1 <- brewer.pal(11,"RdYlBu")

results_bmi_1_prune$method <- factor(results_bmi_1_prune$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_bmi_2_prune$method <- factor(results_bmi_2_prune$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height_1_prune$method <- factor(results_height_1_prune$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height_2_prune$method <- factor(results_height_2_prune$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))

plot_A <- ggplot(results_bmi_1_prune, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-1-BMI-2')
  
plot_B<- ggplot(results_bmi_2_prune, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-2-BMI-1')
  
plot_C <- ggplot(results_height_1_prune, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-1-Height-2')

plot_D <- ggplot(results_height_2_prune, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method))) + geom_point(size=2,aes(fill=method, color=method)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  geom_errorbarh(height=.2)+
  geom_vline(aes(xintercept = 1), linetype=1, size=0.5,linetype="dashed") + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) +
  guides(color = guide_legend(title = "Method")) +  theme(text = element_text(size=8), legend.position="none",strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-2-Height-1')

figure <- plot_A + plot_B + plot_C + plot_D

```


```{r,eval=FALSE,echo=FALSE}
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))

```


```{r, eval=FALSE,echo=FALSE}

results_bmi_1_clump$set <- c(rep("clump",9))
results_bmi_2_clump$set <- c(rep("clump",9))
results_height_1_clump$set <- c(rep("clump",9))
results_height_2_clump$set <- c(rep("clump",9))

results_bmi_1_prune$set <- c(rep("prune",9))
results_bmi_2_prune$set <- c(rep("prune",9))
results_height_1_prune$set <- c(rep("prune",9))
results_height_2_prune$set <- c(rep("prune",9))

results_bmi1_cp <- rbind(results_bmi_1_clump,results_bmi_1_prune)
results_bmi2_cp <- rbind(results_bmi_2_clump,results_bmi_2_prune)
results_height1_cp <- rbind(results_height_1_clump,results_height_1_prune)
results_height2_cp <- rbind(results_height_2_clump,results_height_2_prune)

results_bmi1_cp$method <- factor(results_bmi1_cp$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_bmi2_cp$method <- factor(results_bmi2_cp$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height1_cp$method <- factor(results_height1_cp$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))
results_height2_cp$method <- factor(results_height2_cp$method, levels=c("SimSS2_ivw","SimSS2_raps","SimSS3_ivw","SimSS3_raps","ivw","raps","ivw_EB","ivw_boot","divw"))


plot_A <- ggplot(results_bmi1_cp, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method),group=set)) + geom_point(size=2,aes(fill=method, color=method,shape=set),position=position_dodge(width = 0.5)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + scale_shape_manual(values=c(19,1)) + geom_errorbarh(height=.3,position=position_dodge(width = 0.5),aes(linetype=set)) + scale_linetype_manual(values = c("dotted", "solid")) +
  geom_vline(aes(xintercept = 1), size=0.5,linetype=1) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + theme(text = element_text(size=8),strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-1-BMI-2') + guides(color = FALSE, fill = FALSE, group = TRUE) +
  theme(legend.title=element_blank())
  
plot_B<- ggplot(results_bmi2_cp, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method),group=set)) + geom_point(size=2,aes(fill=method, color=method,shape=set),position=position_dodge(width = 0.5)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + scale_shape_manual(values=c(19,1)) + geom_errorbarh(height=.3,position=position_dodge(width = 0.5),aes(linetype=set)) + scale_linetype_manual(values = c("dotted", "solid")) +
  geom_vline(aes(xintercept = 1), size=0.5,linetype=1) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + theme(text = element_text(size=8),strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('BMI-2-BMI-1') + guides(color = FALSE, fill = FALSE, group = TRUE) +
  theme(legend.title=element_blank())
  
plot_C <- ggplot(results_height1_cp, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method),group=set)) + geom_point(size=2,aes(fill=method, color=method,shape=set),position=position_dodge(width = 0.5)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + scale_shape_manual(values=c(19,1)) + geom_errorbarh(height=.3,position=position_dodge(width = 0.5),aes(linetype=set)) + scale_linetype_manual(values = c("dotted", "solid")) +
  geom_vline(aes(xintercept = 1), size=0.5,linetype=1) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + theme(text = element_text(size=8),strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-1-Height-2') + guides(color = FALSE, fill = FALSE, group = TRUE) +
  theme(legend.title=element_blank())

plot_D <- ggplot(results_height2_cp, aes(y=method, x=b, xmin=CI.lower, xmax=CI.upper,color=as.factor(method),group=set)) + geom_point(size=2,aes(fill=method, color=method,shape=set),position=position_dodge(width = 0.5)) + xlab("Estimated Causal Effect") + ylab("Method") + scale_color_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + scale_shape_manual(values=c(19,1)) + geom_errorbarh(height=.3,position=position_dodge(width = 0.5),aes(linetype=set)) + scale_linetype_manual(values = c("dotted", "solid")) +
  geom_vline(aes(xintercept = 1), size=0.5,linetype=1) + scale_fill_manual(values=c(col[1],col[2],col[3],col[4],col[5],col[6],col[7],col[8],col1[1])) + theme(text = element_text(size=8),strip.text = element_text(face="italic"), plot.title = element_text(size=10)) + 
  ggtitle('Height-2-Height-1') + guides(color = FALSE, fill = FALSE, group = TRUE) +
  theme(legend.title=element_blank())

figure <- plot_A + plot_B + plot_C + plot_D

```


```{r,eval=FALSE,echo=FALSE}
figure + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A') &
  theme(plot.tag = element_text(face = "bold"))

```


We can now combine the results obtained by using both clumped and pruned sets of SNPs and visualise in one plot as follows. Note that the *solid points with dotted error bars* represent causal effect estimates obtained using **clumped** sets of SNPs while the *hollow circles with solid error bars* represent those obtained using **pruned** sets of SNPs.


<p align="center">
<a href="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_clump_prune.png?raw=true"> 
<img src="https://github.com/amandaforde/winnerscurse_MR/blob/main/res_plots/MRSimSS_clump_prune.png?raw=true" width="100%"> </a>
</p>


<br>

[**Comments:**]{style="color: purple;"} 

- Firstly, we see that `divw` has greatly improved in comparison with using the clumped set of SNPs. As `divw` uses the entire set of SNPs and not just those that are significant, this observation is most likely due to the fact that the number of SNPs in the entire set of pruned SNPs for both BMI and height are approximately 19 and 11 times larger, respectively, than their clumped counterparts. We see that `divw` has smaller standard errors than the other methods. However, in all four scenarios, the true value of 1 is not contained in its 95% confidence interval. 

- Using pruned SNPs seems to show improvements for the *Winner's Curse* corrected variants of `ivw`, `ivw_boot` and `ivw_EB`. This could potentially be due to the fact that both methods use the entire data set, which is now bigger as noted above, to make adjustments to the SNP-exposure estimates. However, we also see that the **causal effect estimates of `ivw` and `raps` have also moved closer to 1** by using the pruned set. As these two methods only use significant SNPs, this result provides *evidence that using clumping induces a form of selection bias* and that bias propagates to the causal effect estimate. 

- Even though using pruned sets has increased the standard error of our `SimSS3_raps` causal effect estimates, especially for BMI, the estimates do now seem to be less biased with all four confidence intervals including 1. The increase in standard error visible for BMI is due to the fact that less instruments are significant on each iteration. Most importantly, for Height-2-Height-1, we see that our causal effect estimates have moved much closer to 1 and in fact, **`SimSS3_raps` and `SimSS2_raps` are the only methods which include 1 in their 95% confidence intervals**. 

<br>
